from pennylane import numpy as np
import pennylane as qml
from pennylane.optimize import NesterovMomentumOptimizer
import matplotlib.pyplot as plt
from joblib import Parallel, delayed

TOTAL_WIRES = 4
TRAINABLE_WIRES = 2

class Model:
    dev4 = qml.device("default.qubit", wires=4)
    dev2 = qml.device("default.qubit", wires=2)
    def __init__(self, wires, batch_size):
        '''
        4 + 2 qubit system
        '''
        self.weights = 3.14 * np.random.rand(18, requires_grad=True)
        self.bias = np.array(0.0, requires_grad=True)
        self.optimizer = NesterovMomentumOptimizer(0.5)
        self.batch_size = batch_size
    

    @qml.qnode(dev4)
    def ckt1(x, theta):
        data = [0, 1, 2, 3]
        qml.AmplitudeEmbedding(x, wires=data, normalize=True)

        for i in data: qml.Hadamard(i)
        qml.RX(theta[0], wires=[0])
        qml.CNOT([0, 2])
        qml.RZ(theta[1], wires=[1])
        qml.CNOT([1, 3])
        qml.RX(theta[2], wires=[2])
        qml.CNOT([2, 3])
        qml.RX(theta[3], wires=[3])
        qml.CNOT([0, 3])

        return [qml.expval(qml.PauliZ(i)) for i in range(4)]

    @qml.qnode(dev2)
    def ckt2(x1, x2, y1, y2, theta):
        qml.RY(np.arccos(x1), wires=0)
        qml.RY(np.arccos(x2), wires=1)

        qml.RZ(np.arcsin(y1), wires=0)
        qml.RZ(np.arcsin(y2), wires=1)

        # variational part
        qml.Rot(theta[4], theta[5], theta[6], wires=[0])
        qml.CNOT([0, 1])
        qml.Rot(theta[7], theta[8], theta[9], wires=[1])
        qml.CNOT([1, 0])
        
        return qml.expval(qml.PauliZ(1))

    def circuit(x, theta):

        x1, x2, x3, x4 = Model.ckt1(x, theta)

        # synthetic superpose
        # sqrt((1 + x1) / 2) = abs(a1)
        xx1 = np.cos(theta[10] * np.sqrt((1 + x1) / 2) + theta[11] * np.sqrt((1 + x3) / 2))
        xx2 = np.cos(theta[12] * np.sqrt((1 + x2) / 2) + theta[13] * np.sqrt((1 + x4) / 2))

        yy1 = np.sin(theta[14] * np.sqrt((1 - x1) / 2) + theta[15] * np.sqrt((1 - x3) / 2))
        yy2 = np.sin(theta[17] * np.sqrt((1 - x2) / 2) + theta[16] * np.sqrt((1 - x4) / 2))

        return Model.ckt2(xx1, xx2, yy1, yy2, theta)

    def draw(self):
        qml.draw_mpl(Model.circuit)(np.ndarray((64)), np.ndarray((9, 3)))
        plt.show()

    def classif(self, weights, bias, x):
        return ((Model.circuit(x, weights) + bias) + 1) / 2


    def loss(labels, prediction):
        return np.mean((labels - qml.math.stack(prediction))**2)


    def accuracy(labels, prediction):
        tr = lambda x: 1 if x>0.5 else 0
        return np.sum(tr(p) == l for l, p in zip(labels, prediction)) / len(labels)


    def cost(self, weights, bias, X, Y):
        # prediction = list(Parallel(n_jobs=-1)(delayed(self.classif)(weights, bias, x) for x in X))
        prediction = [self.classif(weights, bias, x) for x in X]
        return Model.loss(Y, prediction)


    def train(self, X, Y, epochs=10):
        weights, bias = self.weights, self.bias
        for it in range(epochs):
            batch_index = np.random.randint(0, len(X), (self.batch_size,))
            X_batch = X[batch_index]
            Y_batch = Y[batch_index]
            weights = self.optimizer.step(lambda w: self.cost(w, bias, X_batch, Y_batch), weights)

            predictions = [self.classif(weights, bias, x) for x in X]

            current_cost = self.cost(weights, bias, X, Y)
            acc = Model.accuracy(Y, predictions)
            print(f"Iter: {it+1:4d} | Cost: {current_cost:0.7f} | acc: {acc:0.7f}", flush=True)

----------------------------------------------------------------------------------------------------

size:  12665
Iter:    1 | Cost: 0.2630724 | acc: 0.5323332
Iter:    2 | Cost: 0.2414780 | acc: 0.5323332
Iter:    3 | Cost: 0.2342962 | acc: 0.5323332
Iter:    4 | Cost: 0.2182487 | acc: 0.5323332
Iter:    5 | Cost: 0.2107181 | acc: 0.6182392
Iter:    6 | Cost: 0.2061488 | acc: 0.7104619
Iter:    7 | Cost: 0.2027189 | acc: 0.7460719
Iter:    8 | Cost: 0.2014975 | acc: 0.7673115
Iter:    9 | Cost: 0.2009631 | acc: 0.7760758
Iter:   10 | Cost: 0.2005628 | acc: 0.7832610
Iter:   11 | Cost: 0.1996756 | acc: 0.7935255
Iter:   12 | Cost: 0.1981439 | acc: 0.8070272
Iter:   13 | Cost: 0.1962621 | acc: 0.8173707
Iter:   14 | Cost: 0.1938994 | acc: 0.8234505
Iter:   15 | Cost: 0.1913373 | acc: 0.8311883
Iter:   16 | Cost: 0.1894543 | acc: 0.8230557
Iter:   17 | Cost: 0.1877622 | acc: 0.8109751
Iter:   18 | Cost: 0.1873828 | acc: 0.7828662
Iter:   19 | Cost: 0.1867463 | acc: 0.7650217
Iter:   20 | Cost: 0.1828354 | acc: 0.7971575
Iter:   21 | Cost: 0.1797276 | acc: 0.8192657
Iter:   22 | Cost: 0.1774719 | acc: 0.8358468
Iter:   23 | Cost: 0.1755948 | acc: 0.8390051
Iter:   24 | Cost: 0.1738149 | acc: 0.8435847
Iter:   25 | Cost: 0.1724005 | acc: 0.8455586
Iter:   26 | Cost: 0.1710058 | acc: 0.8455586
Iter:   27 | Cost: 0.1696618 | acc: 0.8481642
Iter:   28 | Cost: 0.1684333 | acc: 0.8485590
Iter:   29 | Cost: 0.1672401 | acc: 0.8501382
Iter:   30 | Cost: 0.1667478 | acc: 0.8441374
