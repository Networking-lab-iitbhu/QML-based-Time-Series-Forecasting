os.getpid()=46196
args.num_latent=3
args.num_trash=7

 Training Encoder...

Encoder Loss: 0.167 Iteration: 1
Encoder Loss: 0.111 Iteration: 2
Encoder Loss: 0.077 Iteration: 3
Encoder Loss: 0.067 Iteration: 4
Encoder Loss: 0.057 Iteration: 5
Encoder Loss: 0.059 Iteration: 6
Encoder Loss: 0.053 Iteration: 7
Encoder Loss: 0.055 Iteration: 8
Encoder Loss: 0.056 Iteration: 9
Encoder Loss: 0.058 Iteration: 10
Encoder Loss: 0.055 Iteration: 11
Encoder Loss: 0.057 Iteration: 12
Encoder Loss: 0.053 Iteration: 13
Encoder Loss: 0.055 Iteration: 14
Encoder Loss: 0.055 Iteration: 15
Encoder Loss: 0.055 Iteration: 16
Encoder Loss: 0.057 Iteration: 17
Encoder Loss: 0.054 Iteration: 18
Encoder Loss: 0.054 Iteration: 19
Encoder Loss: 0.054 Iteration: 20
Encoder Loss: 0.055 Iteration: 21
Encoder Loss: 0.053 Iteration: 22
Encoder Loss: 0.061 Iteration: 23
Encoder Loss: 0.051 Iteration: 24
Encoder Loss: 0.061 Iteration: 25
Encoder Loss: 0.054 Iteration: 26
Encoder Loss: 0.055 Iteration: 27
Encoder Loss: 0.052 Iteration: 28
Encoder Loss: 0.059 Iteration: 29
Encoder Loss: 0.056 Iteration: 30
Training Started... 
0: 0.14717638492584229
Training Epoch 0
train_metrics: 
R2: -13.02704906463623
MSE: 963902.375
MAPE: 0.4775414728781198
test metrics:
R2: -20.37855339050293
MSE: 1055303.625
MAPE: 0.561297686781335
before val features
MSE diff_p 0
----------
1: 0.07082850486040115
Training Epoch 1
train_metrics: 
R2: -202.13731384277344
MSE: 463877.1875
MAPE: 0.4611642331830502
test metrics:
R2: -353.53179931640625
MSE: 594090.0
MAPE: 0.5478405540188511
MSE diff_p 1
----------
2: 0.056912634521722794
Training Epoch 2
train_metrics: 
R2: -73.85742950439453
MSE: 372737.9375
MAPE: 0.42844514485513285
test metrics:
R2: -124.74678039550781
MSE: 474407.03125
MAPE: 0.5307096844629708
MSE diff_p 2
----------
3: 0.039394717663526535
Training Epoch 3
train_metrics: 
R2: -10.89570426940918
MSE: 258007.84375
MAPE: 0.35448610643322176
test metrics:
R2: -15.850818634033203
MSE: 360972.59375
MAPE: 0.45811630611498877
MSE diff_p 3
----------
4: 0.032479919493198395
Training Epoch 4
train_metrics: 
R2: -4.5609612464904785
MSE: 212720.734375
MAPE: 0.33501347138061255
test metrics:
R2: -9.561441421508789
MSE: 323191.375
MAPE: 0.4622414888831529
MSE diff_p 4
----------
5: 0.028453897684812546
Training Epoch 5
train_metrics: 
R2: -2.4425160884857178
MSE: 186353.15625
MAPE: 0.3066751360573749
test metrics:
R2: -3.89886474609375
MSE: 262650.375
MAPE: 0.41023959023636797
MSE diff_p 5
----------
6: 0.026440512388944626
Training Epoch 6
train_metrics: 
R2: -2.129157543182373
MSE: 173166.875
MAPE: 0.3143408265271086
test metrics:
R2: -4.649153709411621
MSE: 278517.1875
MAPE: 0.4319362238425498
MSE diff_p 6
----------
7: 0.024630937725305557
Training Epoch 7
train_metrics: 
R2: -2.023885726928711
MSE: 161315.421875
MAPE: 0.29508855741346385
test metrics:
R2: -3.1912789344787598
MSE: 247266.34375
MAPE: 0.3998091153075547
MSE diff_p 7
----------
8: 0.024509068578481674
Training Epoch 8
train_metrics: 
R2: -1.205193042755127
MSE: 160517.265625
MAPE: 0.28523870050530986
test metrics:
R2: -2.9336130619049072
MSE: 254058.75
MAPE: 0.41864679773722907
MSE diff_p 8
----------
9: 0.027905773371458054
Training Epoch 9
train_metrics: 
R2: -1.35483717918396
MSE: 182763.3125
MAPE: 0.3138618959849516
test metrics:
R2: -1.7261650562286377
MSE: 214501.234375
MAPE: 0.3716699279553753
MSE diff_p 9
----------
10: 0.0247205663472414
Training Epoch 10
train_metrics: 
R2: -0.9474596977233887
MSE: 161902.421875
MAPE: 0.3043212223702668
test metrics:
R2: -2.673778772354126
MSE: 255147.359375
MAPE: 0.41459385466538096
MSE diff_p 10
----------
11: 0.023615678772330284
Training Epoch 11
train_metrics: 
R2: -0.8322871923446655
MSE: 154666.1875
MAPE: 0.30512262559105946
test metrics:
R2: -1.2181439399719238
MSE: 197849.78125
MAPE: 0.3591715920987994
MSE diff_p 11
----------
12: 0.01934944838285446
Training Epoch 12
train_metrics: 
R2: -0.23488402366638184
MSE: 126725.359375
MAPE: 0.26711405457804593
test metrics:
R2: -1.1772785186767578
MSE: 204406.09375
MAPE: 0.378917206161712
MSE diff_p 12
----------
13: 0.018740128725767136
Training Epoch 13
train_metrics: 
R2: -0.10277104377746582
MSE: 122734.75
MAPE: 0.25562972967065917
test metrics:
R2: -0.6788045167922974
MSE: 176303.765625
MAPE: 0.3438461356239719
MSE diff_p 13
----------
14: 0.01749105378985405
Training Epoch 14
train_metrics: 
R2: 0.02825707197189331
MSE: 114554.171875
MAPE: 0.25976118888620037
test metrics:
R2: -0.6824488639831543
MSE: 183827.125
MAPE: 0.3597624084056154
MSE diff_p 14
----------
15: 0.01836445927619934
Training Epoch 15
train_metrics: 
R2: -0.044600725173950195
MSE: 120274.3515625
MAPE: 0.2414251369330402
test metrics:
R2: -0.46380090713500977
MSE: 166084.453125
MAPE: 0.33703145426374015
MSE diff_p 15
----------
16: 0.01726028136909008
Training Epoch 16
train_metrics: 
R2: 0.1403104066848755
MSE: 113042.78125
MAPE: 0.2615474940592911
test metrics:
R2: -0.3866034746170044
MSE: 168398.5
MAPE: 0.3468517689585076
MSE diff_p 16
----------
17: 0.015728212893009186
Training Epoch 17
train_metrics: 
R2: 0.16154038906097412
MSE: 103008.796875
MAPE: 0.23815193184127964
test metrics:
R2: -0.20035302639007568
MSE: 151880.03125
MAPE: 0.32594361715136266
MSE diff_p 17
----------
18: 0.014115671627223492
Training Epoch 18
train_metrics: 
R2: 0.3102028965950012
MSE: 92447.7734375
MAPE: 0.22739380289687955
test metrics:
R2: -0.2504456043243408
MSE: 160695.859375
MAPE: 0.34240125369565805
MSE diff_p 18
----------
19: 0.013994742184877396
Training Epoch 19
train_metrics: 
R2: 0.2737610340118408
MSE: 91655.78125
MAPE: 0.21346580950273084
test metrics:
R2: -0.030022740364074707
MSE: 141798.21875
MAPE: 0.3154415274429593
MSE diff_p 19
----------
20: 0.01495087705552578
Training Epoch 20
train_metrics: 
R2: 0.3344578146934509
MSE: 97917.796875
MAPE: 0.2552926637282233
test metrics:
R2: -0.012565135955810547
MSE: 146489.765625
MAPE: 0.32864118255992786
MSE diff_p 20
----------
21: 0.01455838605761528
Training Epoch 21
train_metrics: 
R2: 0.36312025785446167
MSE: 95347.2578125
MAPE: 0.23074620532180715
test metrics:
R2: 0.0810423493385315
MSE: 133794.84375
MAPE: 0.3037526164354322
MSE diff_p 21
----------
22: 0.014143834821879864
Training Epoch 22
train_metrics: 
R2: 0.3558886647224426
MSE: 92632.2265625
MAPE: 0.25397325594472336
test metrics:
R2: 0.0019873380661010742
MSE: 146872.40625
MAPE: 0.3311870501432448
MSE diff_p 22
----------
23: 0.01504124142229557
Training Epoch 23
train_metrics: 
R2: 0.3335966467857361
MSE: 98509.6171875
MAPE: 0.22367417940232887
test metrics:
R2: 0.038263916969299316
MSE: 137275.96875
MAPE: 0.3046876453126174
MSE diff_p 23
----------
24: 0.011439153924584389
Training Epoch 24
train_metrics: 
R2: 0.5136677622795105
MSE: 74918.453125
MAPE: 0.20772664745716674
test metrics:
R2: 0.06860947608947754
MSE: 141891.625
MAPE: 0.32568492260334403
MSE diff_p 24
----------
25: 0.0112474849447608
Training Epoch 25
train_metrics: 
R2: 0.5050953030586243
MSE: 73663.171875
MAPE: 0.19686637113996802
test metrics:
R2: 0.28623735904693604
MSE: 118515.5703125
MAPE: 0.28935921719540386
MSE diff_p 25
----------
26: 0.013728408142924309
Training Epoch 26
train_metrics: 
R2: 0.4901912808418274
MSE: 89911.46875
MAPE: 0.22343187565018421
test metrics:
R2: 0.2479751706123352
MSE: 127516.3203125
MAPE: 0.3143907153981107
MSE diff_p 26
----------
27: 0.011253096163272858
Training Epoch 27
train_metrics: 
R2: 0.5369720458984375
MSE: 73699.90625
MAPE: 0.21579804144010045
test metrics:
R2: 0.3564170002937317
MSE: 111748.40625
MAPE: 0.2828151576059893
MSE diff_p 27
----------
28: 0.009774090722203255
Training Epoch 28
train_metrics: 
R2: 0.6415018439292908
MSE: 64013.4609375
MAPE: 0.19292462562880547
test metrics:
R2: 0.34738898277282715
MSE: 117111.0703125
MAPE: 0.3042187863931043
MSE diff_p 28
----------
29: 0.01034175232052803
Training Epoch 29
train_metrics: 
R2: 0.612257719039917
MSE: 67731.25
MAPE: 0.19752775707362397
test metrics:
R2: 0.4475892186164856
MSE: 102719.359375
MAPE: 0.2734087669248982
MSE diff_p 29
----------
30: 0.00966896302998066
Training Epoch 30
train_metrics: 
R2: 0.6547324061393738
MSE: 63324.9375
MAPE: 0.21197645615515293
test metrics:
R2: 0.4072290062904358
MSE: 111653.109375
MAPE: 0.3001646339434997
MSE diff_p 30
----------
31: 0.011213166639208794
Training Epoch 31
train_metrics: 
R2: 0.6191811561584473
MSE: 73438.3984375
MAPE: 0.22120901901184187
test metrics:
R2: 0.49430596828460693
MSE: 97684.53125
MAPE: 0.264502815986648
MSE diff_p 31
----------
32: 0.011572902090847492
Training Epoch 32
train_metrics: 
R2: 0.6185826063156128
MSE: 75794.40625
MAPE: 0.23089536723960533
test metrics:
R2: 0.37026888132095337
MSE: 118799.9453125
MAPE: 0.3127135339029117
MSE diff_p 32
----------
33: 0.009551705792546272
Training Epoch 33
train_metrics: 
R2: 0.6380124092102051
MSE: 62556.9921875
MAPE: 0.20832176225516025
test metrics:
R2: 0.5189878940582275
MSE: 95057.5625
MAPE: 0.2612666615547471
MSE diff_p 33
----------
34: 0.011608744971454144
Training Epoch 34
train_metrics: 
R2: 0.6104140281677246
MSE: 76029.15625
MAPE: 0.23257756809542796
test metrics:
R2: 0.424207866191864
MSE: 112817.28125
MAPE: 0.30765836678296066
MSE diff_p 34
----------
35: 0.007526976987719536
Training Epoch 35
train_metrics: 
R2: 0.7350331544876099
MSE: 49296.4375
MAPE: 0.17294716618790457
test metrics:
R2: 0.5695382952690125
MSE: 88707.3828125
MAPE: 0.2547175549869601
MSE diff_p 35
----------
36: 0.007180971093475819
Training Epoch 36
train_metrics: 
R2: 0.7731865048408508
MSE: 47030.3359375
MAPE: 0.18220780964176903
test metrics:
R2: 0.5597044229507446
MSE: 94130.0703125
MAPE: 0.2832054728285153
MSE diff_p 36
----------
37: 0.006600190419703722
Training Epoch 37
train_metrics: 
R2: 0.7951498031616211
MSE: 43226.63671875
MAPE: 0.16768534186870232
test metrics:
R2: 0.6474355459213257
MSE: 78947.984375
MAPE: 0.24339394846784893
MSE diff_p 37
----------
38: 0.008384321816265583
Training Epoch 38
train_metrics: 
R2: 0.7734352350234985
MSE: 54911.44140625
MAPE: 0.202320966574225
test metrics:
R2: 0.6217916011810303
MSE: 86309.984375
MAPE: 0.27297641735166167
MSE diff_p 38
----------
39: 0.007115798536688089
Training Epoch 39
train_metrics: 
R2: 0.7964404821395874
MSE: 46603.5078125
MAPE: 0.18422955367124788
test metrics:
R2: 0.6878365278244019
MSE: 73525.359375
MAPE: 0.23388857950333578
MSE diff_p 39
----------
40: 0.007308821193873882
Training Epoch 40
train_metrics: 
R2: 0.7821389436721802
MSE: 47867.6640625
MAPE: 0.1782984043266546
test metrics:
R2: 0.6388049721717834
MSE: 84935.75
MAPE: 0.27434292634405494
MSE diff_p 40
----------
41: 0.008258186280727386
Training Epoch 41
train_metrics: 
R2: 0.7528425455093384
MSE: 54085.34375
MAPE: 0.2311490562379934
test metrics:
R2: 0.7101597785949707
MSE: 70854.375
MAPE: 0.23140383808928164
MSE diff_p 41
----------
42: 0.007895140908658504
Training Epoch 42
train_metrics: 
R2: 0.7675886154174805
MSE: 51707.6484375
MAPE: 0.19771612438124134
test metrics:
R2: 0.6128361225128174
MSE: 90144.453125
MAPE: 0.2852948739844965
MSE diff_p 42
----------
43: 0.008759265765547752
Training Epoch 43
train_metrics: 
R2: 0.7758686542510986
MSE: 57367.06640625
MAPE: 0.22621860186832088
test metrics:
R2: 0.7271229028701782
MSE: 68621.703125
MAPE: 0.22929089527960722
MSE diff_p 43
----------
44: 0.00864540133625269
Training Epoch 44
train_metrics: 
R2: 0.7395073771476746
MSE: 56621.3359375
MAPE: 0.20656716708976777
test metrics:
R2: 0.6019021272659302
MSE: 93895.34375
MAPE: 0.291296795913638
MSE diff_p 44
----------
45: 0.009283168241381645
Training Epoch 45
train_metrics: 
R2: 0.7492865324020386
MSE: 60798.25390625
MAPE: 0.23299305935939196
test metrics:
R2: 0.7119600176811218
MSE: 70994.703125
MAPE: 0.23515525153835862
MSE diff_p 45
----------
46: 0.008811946026980877
Training Epoch 46
train_metrics: 
R2: 0.7722798585891724
MSE: 57712.0859375
MAPE: 0.19643890245105872
test metrics:
R2: 0.651496946811676
MSE: 85398.25
MAPE: 0.2794750459294468
MSE diff_p 46
----------
47: 0.007288418244570494
Training Epoch 47
train_metrics: 
R2: 0.8103989362716675
MSE: 47734.04296875
MAPE: 0.2035093777376866
test metrics:
R2: 0.7732448577880859
MSE: 60547.9609375
MAPE: 0.21971241184616608
MSE diff_p 47
----------
48: 0.005367308389395475
Training Epoch 48
train_metrics: 
R2: 0.8606283664703369
MSE: 35152.1171875
MAPE: 0.16335089715050266
test metrics:
R2: 0.7490473985671997
MSE: 67425.8828125
MAPE: 0.250678602756559
MSE diff_p 48
----------
49: 0.005103337112814188
Training Epoch 49
train_metrics: 
R2: 0.8705670833587646
MSE: 33423.29296875
MAPE: 0.16513472765848564
test metrics:
R2: 0.8043129444122314
MSE: 54764.78125
MAPE: 0.20727321558717943
MSE diff_p 49
----------
50: 0.004874543286859989
Training Epoch 50
train_metrics: 
R2: 0.8845037817955017
MSE: 31924.84765625
MAPE: 0.15661531283490945
test metrics:
R2: 0.7854650020599365
MSE: 60187.46484375
MAPE: 0.23410364165204509
MSE diff_p 50
----------
51: 0.004598731175065041
Training Epoch 51
train_metrics: 
R2: 0.8880659341812134
MSE: 30118.47265625
MAPE: 0.14515642724797487
test metrics:
R2: 0.8282442688941956
MSE: 50456.9765625
MAPE: 0.2001177487018747
MSE diff_p 51
----------
52: 0.004715188406407833
Training Epoch 52
train_metrics: 
R2: 0.8995715379714966
MSE: 30881.189453125
MAPE: 0.14491224839021521
test metrics:
R2: 0.8088977336883545
MSE: 55554.55078125
MAPE: 0.22410135827481464
MSE diff_p 52
----------
53: 0.004786065313965082
Training Epoch 53
train_metrics: 
R2: 0.8887108564376831
MSE: 31345.380859375
MAPE: 0.17373500978831122
test metrics:
R2: 0.8423988819122314
MSE: 47549.34765625
MAPE: 0.19607056873046635
MSE diff_p 53
----------
54: 0.005694969091564417
Training Epoch 54
train_metrics: 
R2: 0.8752573728561401
MSE: 37298.06640625
MAPE: 0.18316646554397947
test metrics:
R2: 0.8054329752922058
MSE: 57590.60546875
MAPE: 0.23541983470708114
MSE diff_p 54
----------
55: 0.004941053222864866
Training Epoch 55
train_metrics: 
R2: 0.8901984691619873
MSE: 32360.447265625
MAPE: 0.16680291672496125
test metrics:
R2: 0.847637951374054
MSE: 46731.60546875
MAPE: 0.19772375591402744
MSE diff_p 55
----------
56: 0.005527695175260305
Training Epoch 56
train_metrics: 
R2: 0.8793118000030518
MSE: 36202.53125
MAPE: 0.17290703959163486
test metrics:
R2: 0.7823863625526428
MSE: 64376.5078125
MAPE: 0.25268012128382505
MSE diff_p 56
----------
57: 0.006818726658821106
Training Epoch 57
train_metrics: 
R2: 0.8445225954055786
MSE: 44657.88671875
MAPE: 0.23833533769484377
test metrics:
R2: 0.8502203226089478
MSE: 46844.4765625
MAPE: 0.2057125427724593
MSE diff_p 57
----------
58: 0.006066010799258947
Training Epoch 58
train_metrics: 
R2: 0.8607093691825867
MSE: 39728.1328125
MAPE: 0.17327218771552305
test metrics:
R2: 0.7681381702423096
MSE: 67583.890625
MAPE: 0.26068722120113214
MSE diff_p 58
----------
59: 0.005409670993685722
Training Epoch 59
train_metrics: 
R2: 0.8778334856033325
MSE: 35429.5625
MAPE: 0.21036014422527055
test metrics:
R2: 0.8540250062942505
MSE: 45680.96484375
MAPE: 0.20102063753789237
MSE diff_p 59
----------
60: 0.005254698451608419
Training Epoch 60
train_metrics: 
R2: 0.8650329113006592
MSE: 34414.60546875
MAPE: 0.16554002460446643
test metrics:
R2: 0.7593769431114197
MSE: 69286.5703125
MAPE: 0.2639411036013201
MSE diff_p 60
----------
61: 0.00544326938688755
Training Epoch 61
train_metrics: 
R2: 0.8776394724845886
MSE: 35649.609375
MAPE: 0.19939963111039272
test metrics:
R2: 0.8571168184280396
MSE: 44897.1015625
MAPE: 0.1990711378311247
MSE diff_p 61
----------
62: 0.005170980468392372
Training Epoch 62
train_metrics: 
R2: 0.8826342225074768
MSE: 33866.3046875
MAPE: 0.15716633296442217
test metrics:
R2: 0.8251788020133972
MSE: 53110.1796875
MAPE: 0.23083731826772771
MSE diff_p 62
----------
63: 0.003826047061011195
Training Epoch 63
train_metrics: 
R2: 0.9176419377326965
MSE: 25057.93359375
MAPE: 0.12611184914052068
test metrics:
R2: 0.876065194606781
MSE: 39938.87109375
MAPE: 0.18337960555401933
MSE diff_p 63
----------
64: 0.0034708138555288315
Training Epoch 64
train_metrics: 
R2: 0.9284830093383789
MSE: 22731.40234375
MAPE: 0.12623653268142843
test metrics:
R2: 0.8458371162414551
MSE: 48963.66015625
MAPE: 0.22269770929140112
MSE diff_p 64
----------
65: 0.004132600035518408
Training Epoch 65
train_metrics: 
R2: 0.9093806743621826
MSE: 27065.638671875
MAPE: 0.17108653659204323
test metrics:
R2: 0.882483720779419
MSE: 38555.72265625
MAPE: 0.18533190522249238
MSE diff_p 65
----------
66: 0.003909952938556671
Training Epoch 66
train_metrics: 
R2: 0.9156704545021057
MSE: 25607.4609375
MAPE: 0.140492528055126
test metrics:
R2: 0.8390929698944092
MSE: 50645.8125
MAPE: 0.22944397912179496
MSE diff_p 66
----------
67: 0.004519944079220295
Training Epoch 67
train_metrics: 
R2: 0.9079452753067017
MSE: 29602.478515625
MAPE: 0.17664777360307454
test metrics:
R2: 0.8881072402000427
MSE: 37207.38671875
MAPE: 0.1816203888236648
MSE diff_p 67
----------
68: 0.0038620992563664913
Training Epoch 68
train_metrics: 
R2: 0.9163373112678528
MSE: 25294.05078125
MAPE: 0.1473202121116757
test metrics:
R2: 0.8546494245529175
MSE: 47318.69921875
MAPE: 0.22160707958875273
MSE diff_p 68
----------
69: 0.004299793858081102
Training Epoch 69
train_metrics: 
R2: 0.911085307598114
MSE: 28160.642578125
MAPE: 0.18465712012730282
test metrics:
R2: 0.894012987613678
MSE: 35798.30859375
MAPE: 0.17906369825278362
MSE diff_p 69
----------
70: 0.0035934699699282646
Training Epoch 70
train_metrics: 
R2: 0.9247004985809326
MSE: 23534.71484375
MAPE: 0.13491396724387486
test metrics:
R2: 0.8428707122802734
MSE: 50540.4765625
MAPE: 0.2322421555656521
MSE diff_p 70
----------
71: 0.005377808585762978
Training Epoch 71
train_metrics: 
R2: 0.8878664970397949
MSE: 35220.87890625
MAPE: 0.20375496020423345
test metrics:
R2: 0.8885452151298523
MSE: 37420.76953125
MAPE: 0.18626220447376027
MSE diff_p 71
----------
72: 0.004968428518623114
Training Epoch 72
train_metrics: 
R2: 0.885391354560852
MSE: 32539.732421875
MAPE: 0.16306035573999578
test metrics:
R2: 0.84488844871521
MSE: 49741.8515625
MAPE: 0.23111901779863775
MSE diff_p 72
----------
73: 0.005016176961362362
Training Epoch 73
train_metrics: 
R2: 0.8959760069847107
MSE: 32852.453125
MAPE: 0.16933027485649904
test metrics:
R2: 0.895778477191925
MSE: 35457.140625
MAPE: 0.1793272858381577
MSE diff_p 73
----------
74: 0.005551563575863838
Training Epoch 74
train_metrics: 
R2: 0.8731637001037598
MSE: 36358.859375
MAPE: 0.1705149383883086
test metrics:
R2: 0.8266944885253906
MSE: 55163.8828125
MAPE: 0.244244458010705
MSE diff_p 74
----------
75: 0.005501406732946634
Training Epoch 75
train_metrics: 
R2: 0.8851566314697266
MSE: 36030.3671875
MAPE: 0.19133959025079658
test metrics:
R2: 0.8912838697433472
MSE: 37083.86328125
MAPE: 0.18995568548602512
MSE diff_p 75
----------
76: 0.0035919740330427885
Training Epoch 76
train_metrics: 
R2: 0.9225305318832397
MSE: 23524.91796875
MAPE: 0.1512324271446939
test metrics:
R2: 0.8667422533035278
MSE: 43973.80078125
MAPE: 0.21685343693307174
MSE diff_p 76
----------
77: 0.0031563513912260532
Training Epoch 77
train_metrics: 
R2: 0.9286605715751648
MSE: 20671.89453125
MAPE: 0.1528325691298899
test metrics:
R2: 0.9050931930541992
MSE: 32876.96484375
MAPE: 0.17160211420906932
MSE diff_p 77
----------
78: 0.003244520165026188
Training Epoch 78
train_metrics: 
R2: 0.9345958232879639
MSE: 21249.33984375
MAPE: 0.1389419402878897
test metrics:
R2: 0.8825163245201111
MSE: 39289.57421875
MAPE: 0.20052159161579042
MSE diff_p 78
----------
79: 0.0033357914071530104
Training Epoch 79
train_metrics: 
R2: 0.9309198260307312
MSE: 21847.1015625
MAPE: 0.1501627895602562
test metrics:
R2: 0.907952606678009
MSE: 32016.466796875
MAPE: 0.1675132402504448
MSE diff_p 79
----------
80: 0.0036544837057590485
Training Epoch 80
train_metrics: 
R2: 0.9239058494567871
MSE: 23934.3125
MAPE: 0.13450839635912065
test metrics:
R2: 0.8821747303009033
MSE: 39739.45703125
MAPE: 0.2059243553671118
MSE diff_p 80
----------
81: 0.00350787490606308
Training Epoch 81
train_metrics: 
R2: 0.9301331043243408
MSE: 22974.126953125
MAPE: 0.14948067232656342
test metrics:
R2: 0.9053124189376831
MSE: 32719.5
MAPE: 0.17223139471380794
MSE diff_p 81
----------
82: 0.003330062609165907
Training Epoch 82
train_metrics: 
R2: 0.9338430166244507
MSE: 21809.58203125
MAPE: 0.13542270785811325
test metrics:
R2: 0.8784325122833252
MSE: 40922.69140625
MAPE: 0.2102724477797052
MSE diff_p 82
----------
83: 0.002855859696865082
Training Epoch 83
train_metrics: 
R2: 0.9428198337554932
MSE: 18703.8828125
MAPE: 0.1536267463929402
test metrics:
R2: 0.9139799475669861
MSE: 30560.640625
MAPE: 0.16785301003677594
MSE diff_p 83
----------
84: 0.003033457789570093
Training Epoch 84
train_metrics: 
R2: 0.9420754313468933
MSE: 19867.02734375
MAPE: 0.12709137217497365
test metrics:
R2: 0.8854852318763733
MSE: 39154.30078125
MAPE: 0.20561197106081044
MSE diff_p 84
----------
85: 0.003928169142454863
Training Epoch 85
train_metrics: 
R2: 0.9188397526741028
MSE: 25726.76171875
MAPE: 0.15223148274428638
test metrics:
R2: 0.9127559065818787
MSE: 30652.759765625
MAPE: 0.16680587026132027
MSE diff_p 85
----------
86: 0.0031718588434159756
Training Epoch 86
train_metrics: 
R2: 0.9392730593681335
MSE: 20773.458984375
MAPE: 0.14298800903745595
test metrics:
R2: 0.8832788467407227
MSE: 39991.0625
MAPE: 0.20969773404050465
MSE diff_p 86
----------
87: 0.0034931222908198833
Training Epoch 87
train_metrics: 
R2: 0.9328901171684265
MSE: 22877.50390625
MAPE: 0.15627616623250767
test metrics:
R2: 0.9150839447975159
MSE: 30375.0625
MAPE: 0.1678068650180289
MSE diff_p 87
----------
88: 0.003635711967945099
Training Epoch 88
train_metrics: 
R2: 0.9202260971069336
MSE: 23811.37109375
MAPE: 0.14595370255605405
test metrics:
R2: 0.8749926090240479
MSE: 42552.78515625
MAPE: 0.21865970867662005
MSE diff_p 88
----------
89: 0.003628869540989399
Training Epoch 89
train_metrics: 
R2: 0.9303274154663086
MSE: 23766.560546875
MAPE: 0.1503748303634851
test metrics:
R2: 0.9183358550071716
MSE: 29496.513671875
MAPE: 0.1681256417971981
MSE diff_p 89
----------
90: 0.003137354739010334
Training Epoch 90
train_metrics: 
R2: 0.9373558163642883
MSE: 20547.48046875
MAPE: 0.15339651872883864
test metrics:
R2: 0.8823010325431824
MSE: 40606.65625
MAPE: 0.2146825534490327
MSE diff_p 90
----------
91: 0.0034292342606931925
Training Epoch 91
train_metrics: 
R2: 0.9372940063476562
MSE: 22459.083984375
MAPE: 0.15749008548008486
test metrics:
R2: 0.9185459613800049
MSE: 29308.439453125
MAPE: 0.16569763212280839
MSE diff_p 91
----------
92: 0.003319964511319995
Training Epoch 92
train_metrics: 
R2: 0.9338027238845825
MSE: 21743.4453125
MAPE: 0.13904140085214753
test metrics:
R2: 0.892785370349884
MSE: 37767.93359375
MAPE: 0.20400791375499366
MSE diff_p 92
----------
93: 0.002749808831140399
Training Epoch 93
train_metrics: 
R2: 0.9474950432777405
MSE: 18009.3203125
MAPE: 0.14259359829793597
test metrics:
R2: 0.9251953363418579
MSE: 27575.3515625
MAPE: 0.16292708996058275
MSE diff_p 93
----------
94: 0.00306050106883049
Training Epoch 94
train_metrics: 
R2: 0.9371494054794312
MSE: 20044.142578125
MAPE: 0.13115885694919935
test metrics:
R2: 0.8939480185508728
MSE: 37423.640625
MAPE: 0.20588329071126493
MSE diff_p 94
----------
95: 0.0035631912760436535
Training Epoch 95
train_metrics: 
R2: 0.9357731938362122
MSE: 23336.412109375
MAPE: 0.1536988473152684
test metrics:
R2: 0.9229306578636169
MSE: 28046.703125
MAPE: 0.1648232573963414
MSE diff_p 95
----------
96: 0.0034755005035549402
Training Epoch 96
train_metrics: 
R2: 0.9351394176483154
MSE: 22762.09765625
MAPE: 0.15086082856222605
test metrics:
R2: 0.8850768208503723
MSE: 40301.0703125
MAPE: 0.21594301599295587
MSE diff_p 96
----------
97: 0.003465354209765792
Training Epoch 97
train_metrics: 
R2: 0.9298006296157837
MSE: 22695.6484375
MAPE: 0.18219209177149703
test metrics:
R2: 0.9257047176361084
MSE: 27372.345703125
MAPE: 0.16491422773291792
MSE diff_p 97
----------
98: 0.003569340333342552
Training Epoch 98
train_metrics: 
R2: 0.9347836375236511
MSE: 23376.68359375
MAPE: 0.15441663619450496
test metrics:
R2: 0.8995322585105896
MSE: 35522.17578125
MAPE: 0.2010031917622007
MSE diff_p 98
----------
99: 0.0036218822933733463
Training Epoch 99
train_metrics: 
R2: 0.9294993877410889
MSE: 23720.796875
MAPE: 0.15824274217231232
test metrics:
R2: 0.928299069404602
MSE: 26631.939453125
MAPE: 0.16117491506496523
MSE diff_p 99
----------
100: 0.004120590165257454
Training Epoch 100
train_metrics: 
R2: 0.9177477955818176
MSE: 26986.98046875
MAPE: 0.13548440795570482
test metrics:
R2: 0.8675877451896667
MSE: 45948.43359375
MAPE: 0.231538756802589
MSE diff_p 100
----------
101: 0.003043379634618759
Training Epoch 101
train_metrics: 
R2: 0.9324014186859131
MSE: 19932.0078125
MAPE: 0.15216708160621273
test metrics:
R2: 0.9199720621109009
MSE: 28753.56640625
MAPE: 0.17025438300905207
MSE diff_p 101
----------
102: 0.0038733151741325855
Training Epoch 102
train_metrics: 
R2: 0.9227350950241089
MSE: 25367.505859375
MAPE: 0.14915055531105095
test metrics:
R2: 0.8787538409233093
MSE: 41546.46484375
MAPE: 0.22142511177223534
MSE diff_p 102
----------
103: 0.0038092208560556173
Training Epoch 103
train_metrics: 
R2: 0.9349769949913025
MSE: 24947.734375
MAPE: 0.15704240565000707
test metrics:
R2: 0.9231320023536682
MSE: 27707.828125
MAPE: 0.16305395722100663
MSE diff_p 103
----------
104: 0.0030592349357903004
Training Epoch 104
train_metrics: 
R2: 0.9357393383979797
MSE: 20035.84765625
MAPE: 0.1318912694403828
test metrics:
R2: 0.8988596200942993
MSE: 36034.09375
MAPE: 0.2056105518053453
MSE diff_p 104
----------
105: 0.003359483554959297
Training Epoch 105
train_metrics: 
R2: 0.9362267851829529
MSE: 22002.265625
MAPE: 0.1507354153268064
test metrics:
R2: 0.9295200705528259
MSE: 25967.888671875
MAPE: 0.16233234177357264
MSE diff_p 105
----------
106: 0.0031708204187452793
Training Epoch 106
train_metrics: 
R2: 0.9332231879234314
MSE: 20766.65625
MAPE: 0.13226664555230366
test metrics:
R2: 0.9033621549606323
MSE: 34969.46484375
MAPE: 0.20211189927999995
MSE diff_p 106
----------
107: 0.0029751176480203867
Training Epoch 107
train_metrics: 
R2: 0.9392321109771729
MSE: 19484.94140625
MAPE: 0.146956556568102
test metrics:
R2: 0.9348509311676025
MSE: 24542.083984375
MAPE: 0.1570520821424868
MSE diff_p 107
----------
108: 0.0035819332115352154
Training Epoch 108
train_metrics: 
R2: 0.9265051484107971
MSE: 23459.16015625
MAPE: 0.13564580027245288
test metrics:
R2: 0.9047710299491882
MSE: 33963.1875
MAPE: 0.2004160195128542
MSE diff_p 108
----------
109: 0.002814822131767869
Training Epoch 109
train_metrics: 
R2: 0.9454112648963928
MSE: 18435.1171875
MAPE: 0.13345148295523518
test metrics:
R2: 0.9318375587463379
MSE: 25131.09765625
MAPE: 0.1566479222524034
MSE diff_p 109
----------
110: 0.0020625803153961897
Training Epoch 110
train_metrics: 
R2: 0.964176595211029
MSE: 13508.458984375
MAPE: 0.11551356711910347
test metrics:
R2: 0.9158497452735901
MSE: 30409.52734375
MAPE: 0.1866050087112628
MSE diff_p 110
----------
111: 0.002456155838444829
Training Epoch 111
train_metrics: 
R2: 0.9556151032447815
MSE: 16086.103515625
MAPE: 0.12390968148742654
test metrics:
R2: 0.9340660572052002
MSE: 24565.0703125
MAPE: 0.15636200178115803
MSE diff_p 111
----------
112: 0.0022537866607308388
Training Epoch 112
train_metrics: 
R2: 0.9563949108123779
MSE: 14760.7275390625
MAPE: 0.11707860661846353
test metrics:
R2: 0.9250867962837219
MSE: 27787.529296875
MAPE: 0.174252918987656
MSE diff_p 112
----------
113: 0.001975970808416605
Training Epoch 113
train_metrics: 
R2: 0.9623758792877197
MSE: 12941.228515625
MAPE: 0.11644504905152187
test metrics:
R2: 0.9358255863189697
MSE: 24110.490234375
MAPE: 0.15581751410683917
MSE diff_p 113
----------
114: 0.002247444586828351
Training Epoch 114
train_metrics: 
R2: 0.9570635557174683
MSE: 14719.19140625
MAPE: 0.1047256255557485
test metrics:
R2: 0.922308087348938
MSE: 28830.740234375
MAPE: 0.18035885949252486
MSE diff_p 114
----------
115: 0.0029966661240905523
Training Epoch 115
train_metrics: 
R2: 0.9471644759178162
MSE: 19626.06640625
MAPE: 0.13444807727811486
test metrics:
R2: 0.936942994594574
MSE: 23653.6015625
MAPE: 0.15433528828796064
MSE diff_p 115
----------
116: 0.003563918173313141
Training Epoch 116
train_metrics: 
R2: 0.9352104663848877
MSE: 23341.171875
MAPE: 0.1420413666479685
test metrics:
R2: 0.9024695754051208
MSE: 36221.25
MAPE: 0.20844262682486067
MSE diff_p 116
----------
117: 0.003143608570098877
Training Epoch 117
train_metrics: 
R2: 0.9371010065078735
MSE: 20588.435546875
MAPE: 0.16404988173685375
test metrics:
R2: 0.9376128315925598
MSE: 23769.75
MAPE: 0.15810767044687096
MSE diff_p 117
----------
118: 0.0032310010865330696
Training Epoch 118
train_metrics: 
R2: 0.9340413212776184
MSE: 21160.796875
MAPE: 0.13548941674193668
test metrics:
R2: 0.8890519142150879
MSE: 39725.0859375
MAPE: 0.22024691213899625
MSE diff_p 118
----------
119: 0.003576243296265602
Training Epoch 119
train_metrics: 
R2: 0.9309684634208679
MSE: 23421.890625
MAPE: 0.17156172698966027
test metrics:
R2: 0.9258636236190796
MSE: 26973.146484375
MAPE: 0.16544407047033274
MSE diff_p 119
----------
120: 0.003931192681193352
Training Epoch 120
train_metrics: 
R2: 0.9239051938056946
MSE: 25746.564453125
MAPE: 0.14937108360048054
test metrics:
R2: 0.8860893845558167
MSE: 40654.71875
MAPE: 0.22126626771696054
MSE diff_p 120
----------
121: 0.003264403436332941
Training Epoch 121
train_metrics: 
R2: 0.9372750520706177
MSE: 21379.55859375
MAPE: 0.15225426568925338
test metrics:
R2: 0.9341805577278137
MSE: 24802.58984375
MAPE: 0.1615400115991984
MSE diff_p 121
----------
122: 0.002642954932525754
Training Epoch 122
train_metrics: 
R2: 0.9480694532394409
MSE: 17309.5078125
MAPE: 0.12201300640510404
test metrics:
R2: 0.9190258383750916
MSE: 30079.52734375
MAPE: 0.1878467552952094
MSE diff_p 122
----------
123: 0.002081523183733225
Training Epoch 123
train_metrics: 
R2: 0.9618478417396545
MSE: 13632.5205078125
MAPE: 0.12129581257441914
test metrics:
R2: 0.9404906034469604
MSE: 22712.568359375
MAPE: 0.15083375903600266
MSE diff_p 123
----------
124: 0.002020598156377673
Training Epoch 124
train_metrics: 
R2: 0.9623451232910156
MSE: 13233.50390625
MAPE: 0.11837540840376198
test metrics:
R2: 0.9263663291931152
MSE: 27717.14453125
MAPE: 0.17702641107562694
MSE diff_p 124
----------
125: 0.002129649044945836
Training Epoch 125
train_metrics: 
R2: 0.9635295867919922
MSE: 13947.7099609375
MAPE: 0.11815487610443848
test metrics:
R2: 0.9409688115119934
MSE: 22511.373046875
MAPE: 0.1503017066872868
MSE diff_p 125
----------
126: 0.0021564867347478867
Training Epoch 126
train_metrics: 
R2: 0.9583784341812134
MSE: 14123.48046875
MAPE: 0.12327637297557326
test metrics:
R2: 0.9262910485267639
MSE: 27816.29296875
MAPE: 0.17923018111364178
MSE diff_p 126
----------
127: 0.0023877506610006094
Training Epoch 127
train_metrics: 
R2: 0.9516465663909912
MSE: 15638.09765625
MAPE: 0.1242886978123998
test metrics:
R2: 0.9414273500442505
MSE: 22311.31640625
MAPE: 0.15028461146474148
MSE diff_p 127
----------
128: 0.0022663988638669252
Training Epoch 128
train_metrics: 
R2: 0.9562416076660156
MSE: 14843.328125
MAPE: 0.1278569848295498
test metrics:
R2: 0.9170339107513428
MSE: 30960.599609375
MAPE: 0.19350450162442503
MSE diff_p 128
----------
129: 0.0029492396861314774
Training Epoch 129
train_metrics: 
R2: 0.9475054144859314
MSE: 19315.45703125
MAPE: 0.1608847710111646
test metrics:
R2: 0.9386420249938965
MSE: 23300.404296875
MAPE: 0.15373584546186742
MSE diff_p 129
----------
130: 0.0030876267701387405
Training Epoch 130
train_metrics: 
R2: 0.9429848194122314
MSE: 20221.796875
MAPE: 0.14466244446109633
test metrics:
R2: 0.9087551236152649
MSE: 34084.19921875
MAPE: 0.20263877976236885
MSE diff_p 130
----------
131: 0.0029269219376146793
Training Epoch 131
train_metrics: 
R2: 0.9384106993675232
MSE: 19169.29296875
MAPE: 0.13856639417499864
test metrics:
R2: 0.9422944188117981
MSE: 22332.103515625
MAPE: 0.1511622998833163
MSE diff_p 131
----------
132: 0.002719751326367259
Training Epoch 132
train_metrics: 
R2: 0.9450586438179016
MSE: 17812.46875
MAPE: 0.13666022010307638
test metrics:
R2: 0.9089223146438599
MSE: 33730.7421875
MAPE: 0.20283931855062085
MSE diff_p 132
----------
133: 0.0031634680926799774
Training Epoch 133
train_metrics: 
R2: 0.9424351453781128
MSE: 20718.5
MAPE: 0.1585814912343413
test metrics:
R2: 0.9420371055603027
MSE: 22310.845703125
MAPE: 0.14801071653571513
MSE diff_p 133
----------
134: 0.002601468004286289
Training Epoch 134
train_metrics: 
R2: 0.9531046748161316
MSE: 17037.796875
MAPE: 0.13071829865679746
test metrics:
R2: 0.9181185960769653
MSE: 30464.220703125
MAPE: 0.19051522335771176
MSE diff_p 134
----------
135: 0.002866505179554224
Training Epoch 135
train_metrics: 
R2: 0.9462718367576599
MSE: 18773.60546875
MAPE: 0.14106479389577847
test metrics:
R2: 0.9446187615394592
MSE: 21573.892578125
MAPE: 0.1479473387627249
MSE diff_p 135
----------
136: 0.0028828682843595743
Training Epoch 136
train_metrics: 
R2: 0.9448487162590027
MSE: 18880.7734375
MAPE: 0.12202573649804242
test metrics:
R2: 0.9123800992965698
MSE: 32909.7265625
MAPE: 0.20059899729494365
MSE diff_p 136
----------
137: 0.0023258482106029987
Training Epoch 137
train_metrics: 
R2: 0.9563724994659424
MSE: 15232.6806640625
MAPE: 0.138683758670228
test metrics:
R2: 0.9445284008979797
MSE: 21607.44921875
MAPE: 0.1508979622619924
MSE diff_p 137
----------
138: 0.0029095092322677374
Training Epoch 138
train_metrics: 
R2: 0.9420335292816162
MSE: 19055.248046875
MAPE: 0.14170121704957478
test metrics:
R2: 0.9159283638000488
MSE: 31290.8359375
MAPE: 0.19702144577877898
MSE diff_p 138
----------
139: 0.0025851596146821976
Training Epoch 139
train_metrics: 
R2: 0.9467372298240662
MSE: 16930.98828125
MAPE: 0.1429647720124743
test metrics:
R2: 0.9435829520225525
MSE: 21814.900390625
MAPE: 0.15068335404132224
MSE diff_p 139
----------
140: 0.002673311624675989
Training Epoch 140
train_metrics: 
R2: 0.947196364402771
MSE: 17508.3203125
MAPE: 0.13698693795319378
test metrics:
R2: 0.9020572304725647
MSE: 36031.390625
MAPE: 0.21084766571830546
MSE diff_p 140
----------
141: 0.003139460226520896
Training Epoch 141
train_metrics: 
R2: 0.940341591835022
MSE: 20561.26953125
MAPE: 0.1430056348597741
test metrics:
R2: 0.9428513646125793
MSE: 22052.462890625
MAPE: 0.1519667776186476
MSE diff_p 141
----------
142: 0.003991448786109686
Training Epoch 142
train_metrics: 
R2: 0.9210019707679749
MSE: 26141.197265625
MAPE: 0.1605623948699344
test metrics:
R2: 0.9005149006843567
MSE: 36830.90625
MAPE: 0.21357219370468036
MSE diff_p 142
----------
143: 0.003412014339119196
Training Epoch 143
train_metrics: 
R2: 0.9309343099594116
MSE: 22346.30859375
MAPE: 0.16310064644354777
test metrics:
R2: 0.9374860525131226
MSE: 23816.29296875
MAPE: 0.1582305585607601
MSE diff_p 143
----------
144: 0.0029516946524381638
Training Epoch 144
train_metrics: 
R2: 0.9418207406997681
MSE: 19331.533203125
MAPE: 0.1322182164181146
test metrics:
R2: 0.8965327739715576
MSE: 37286.8984375
MAPE: 0.2139678519050174
MSE diff_p 144
----------
145: 0.001946969423443079
Training Epoch 145
train_metrics: 
R2: 0.9641013145446777
MSE: 12751.287109375
MAPE: 0.12623121470645224
test metrics:
R2: 0.9424103498458862
MSE: 21882.078125
MAPE: 0.14750586955778094
MSE diff_p 145
----------
146: 0.0022414762061089277
Training Epoch 146
train_metrics: 
R2: 0.9555150866508484
MSE: 14680.1005859375
MAPE: 0.12794069328930352
test metrics:
R2: 0.9252789616584778
MSE: 27737.017578125
MAPE: 0.18303659638817543
MSE diff_p 146
----------
147: 0.002172773936763406
Training Epoch 147
train_metrics: 
R2: 0.9590954184532166
MSE: 14230.1494140625
MAPE: 0.1327608642360625
test metrics:
R2: 0.9447959661483765
MSE: 21284.826171875
MAPE: 0.1461577561532158
MSE diff_p 147
----------
148: 0.002202012576162815
Training Epoch 148
train_metrics: 
R2: 0.9608718752861023
MSE: 14421.64453125
MAPE: 0.12322187185419209
test metrics:
R2: 0.9310916662216187
MSE: 26205.787109375
MAPE: 0.17482553325376568
MSE diff_p 148
----------
149: 0.002194048371165991
Training Epoch 149
train_metrics: 
R2: 0.96016925573349
MSE: 14369.484375
MAPE: 0.12113222197501092
test metrics:
R2: 0.9463687539100647
MSE: 20718.142578125
MAPE: 0.14555659433393822
MSE diff_p 149
----------
150: 0.002069526817649603
Training Epoch 150
train_metrics: 
R2: 0.96031254529953
MSE: 13553.9541015625
MAPE: 0.11419254010594183
test metrics:
R2: 0.9279887080192566
MSE: 27795.365234375
MAPE: 0.18338393924692112
MSE diff_p 150
----------
151: 0.0016955842729657888
Training Epoch 151
train_metrics: 
R2: 0.9681793451309204
MSE: 11104.8916015625
MAPE: 0.11929972043059042
test metrics:
R2: 0.9463111162185669
MSE: 20680.380859375
MAPE: 0.14665544954996743
MSE diff_p 151
----------
152: 0.002064943080767989
Training Epoch 152
train_metrics: 
R2: 0.9576374292373657
MSE: 13523.9326171875
MAPE: 0.09758299112132307
test metrics:
R2: 0.9369944930076599
MSE: 24275.5078125
MAPE: 0.16794174164792325
MSE diff_p 152
----------
153: 0.0015496659325435758
Training Epoch 153
train_metrics: 
R2: 0.9721375107765198
MSE: 10149.2275390625
MAPE: 0.10254176032800025
test metrics:
R2: 0.9462027549743652
MSE: 21051.93359375
MAPE: 0.14971036180876154
MSE diff_p 153
----------
154: 0.0017712893895804882
Training Epoch 154
train_metrics: 
R2: 0.9654442667961121
MSE: 11600.70703125
MAPE: 0.0969604610196386
test metrics:
R2: 0.945107638835907
MSE: 21384.07421875
MAPE: 0.15186512804884164
MSE diff_p 154
----------
155: 0.002245716517791152
Training Epoch 155
train_metrics: 
R2: 0.950317919254303
MSE: 14707.8720703125
MAPE: 0.10581734424886677
test metrics:
R2: 0.9419117569923401
MSE: 22532.48828125
MAPE: 0.15942393036687458
MSE diff_p 155
----------
156: 0.0015397045062854886
Training Epoch 156
train_metrics: 
R2: 0.9718946814537048
MSE: 10083.98828125
MAPE: 0.09017562674256135
test metrics:
R2: 0.9471115469932556
MSE: 20712.7734375
MAPE: 0.1485303859711577
MSE diff_p 156
----------
157: 0.0024043801240622997
Training Epoch 157
train_metrics: 
R2: 0.960918664932251
MSE: 15747.0068359375
MAPE: 0.11246714366320323
test metrics:
R2: 0.9447514414787292
MSE: 21638.30078125
MAPE: 0.15442320862751538
MSE diff_p 157
----------
158: 0.0013585527194663882
Training Epoch 158
train_metrics: 
R2: 0.9745452404022217
MSE: 8897.5693359375
MAPE: 0.09807190385106312
test metrics:
R2: 0.9488078951835632
MSE: 20237.0859375
MAPE: 0.14752870345071453
MSE diff_p 158
----------
159: 0.002117576776072383
Training Epoch 159
train_metrics: 
R2: 0.9627878665924072
MSE: 13868.6484375
MAPE: 0.12310880285425135
test metrics:
R2: 0.9488934278488159
MSE: 20321.919921875
MAPE: 0.14760364068757303
MSE diff_p 159
----------
160: 0.001868514227680862
Training Epoch 160
train_metrics: 
R2: 0.9646844267845154
MSE: 12237.462890625
MAPE: 0.1230908326949329
test metrics:
R2: 0.9506388902664185
MSE: 19654.646484375
MAPE: 0.14501954309869325
MSE diff_p 160
----------
161: 0.0018978409934788942
Training Epoch 161
train_metrics: 
R2: 0.9657469987869263
MSE: 12429.533203125
MAPE: 0.09781069451050771
test metrics:
R2: 0.9483659267425537
MSE: 20511.578125
MAPE: 0.14950423773724295
MSE diff_p 161
----------
162: 0.0017012510215863585
Training Epoch 162
train_metrics: 
R2: 0.9685407876968384
MSE: 11142.0068359375
MAPE: 0.10684747192890268
test metrics:
R2: 0.9471150636672974
MSE: 21011.166015625
MAPE: 0.1533745212668531
MSE diff_p 162
----------
163: 0.0014874819898977876
Training Epoch 163
train_metrics: 
R2: 0.9743908047676086
MSE: 9741.966796875
MAPE: 0.0957741252929308
test metrics:
R2: 0.9464768767356873
MSE: 21217.2265625
MAPE: 0.1545348789976512
MSE diff_p 163
----------
164: 0.0017999124247580767
Training Epoch 164
train_metrics: 
R2: 0.9680788516998291
MSE: 11788.1689453125
MAPE: 0.10518234394771794
test metrics:
R2: 0.9484896063804626
MSE: 20505.90625
MAPE: 0.15025474239703906
MSE diff_p 164
----------
165: 0.001592700951732695
Training Epoch 165
train_metrics: 
R2: 0.9723023772239685
MSE: 10431.0771484375
MAPE: 0.09609725981256928
test metrics:
R2: 0.9478890895843506
MSE: 20767.8359375
MAPE: 0.15237417365962688
MSE diff_p 165
----------
166: 0.0019048599060624838
Training Epoch 166
train_metrics: 
R2: 0.9665439128875732
MSE: 12475.5009765625
MAPE: 0.12112687375071599
test metrics:
R2: 0.9505482316017151
MSE: 19697.7421875
MAPE: 0.14657018994755916
MSE diff_p 166
----------
167: 0.0018095622071996331
Training Epoch 167
train_metrics: 
R2: 0.9654145240783691
MSE: 11851.365234375
MAPE: 0.10777849034712855
test metrics:
R2: 0.9489945769309998
MSE: 20120.53515625
MAPE: 0.14962964502018153
MSE diff_p 167
----------
168: 0.0016170635353773832
Training Epoch 168
train_metrics: 
R2: 0.9701749086380005
MSE: 10590.6337890625
MAPE: 0.10342601021223771
test metrics:
R2: 0.9523383378982544
MSE: 19051.7734375
MAPE: 0.14365227936320982
MSE diff_p 168
----------
169: 0.001775708282366395
Training Epoch 169
train_metrics: 
R2: 0.9681487679481506
MSE: 11629.646484375
MAPE: 0.10409468587875807
test metrics:
R2: 0.9427915215492249
MSE: 22972.630859375
MAPE: 0.16616728258075572
MSE diff_p 169
----------
170: 0.001833491143770516
Training Epoch 170
train_metrics: 
R2: 0.9651840329170227
MSE: 12008.0859375
MAPE: 0.12353941774275626
test metrics:
R2: 0.9542024731636047
MSE: 18248.771484375
MAPE: 0.1400367019870147
MSE diff_p 170
----------
171: 0.0022820469457656145
Training Epoch 171
train_metrics: 
R2: 0.9601643085479736
MSE: 14945.8125
MAPE: 0.11640877892184023
test metrics:
R2: 0.9352445602416992
MSE: 25627.349609375
MAPE: 0.18011892021245038
MSE diff_p 171
----------
172: 0.002326216548681259
Training Epoch 172
train_metrics: 
R2: 0.9610264897346497
MSE: 15235.091796875
MAPE: 0.13217998271097053
test metrics:
R2: 0.9555233716964722
MSE: 17889.197265625
MAPE: 0.1380985454075226
MSE diff_p 172
----------
173: 0.002956457668915391
Training Epoch 173
train_metrics: 
R2: 0.9449957013130188
MSE: 19362.728515625
MAPE: 0.14092537600253144
test metrics:
R2: 0.9182432293891907
MSE: 32153.7109375
MAPE: 0.20366586370708306
MSE diff_p 173
----------
174: 0.004800640046596527
Training Epoch 174
train_metrics: 
R2: 0.9054344892501831
MSE: 31440.8359375
MAPE: 0.19548942890569104
test metrics:
R2: 0.9398375749588013
MSE: 23657.552734375
MAPE: 0.16546680777126274
MSE diff_p 174
----------
175: 0.006782091688364744
Training Epoch 175
train_metrics: 
R2: 0.8570773005485535
MSE: 44417.95703125
MAPE: 0.1912924203552463
test metrics:
R2: 0.8351646661758423
MSE: 59389.2265625
MAPE: 0.26380751640673217
MSE diff_p 175
----------
176: 0.007119044661521912
Training Epoch 176
train_metrics: 
R2: 0.8346835374832153
MSE: 46624.76171875
MAPE: 0.23557137762797312
test metrics:
R2: 0.8990038633346558
MSE: 35913.03515625
MAPE: 0.1987952042418946
MSE diff_p 176
----------
177: 0.005421384237706661
Training Epoch 177
train_metrics: 
R2: 0.888719379901886
MSE: 35506.2734375
MAPE: 0.18897183331070413
test metrics:
R2: 0.7885347604751587
MSE: 64919.59375
MAPE: 0.2690404609215204
MSE diff_p 177
----------
178: 0.003495660610496998
Training Epoch 178
train_metrics: 
R2: 0.9063964486122131
MSE: 22894.1328125
MAPE: 0.13852021639011441
test metrics:
R2: 0.898740828037262
MSE: 32172.7890625
MAPE: 0.18339085093075302
MSE diff_p 178
----------
179: 0.0020444418769329786
Training Epoch 179
train_metrics: 
R2: 0.9597156047821045
MSE: 13389.6650390625
MAPE: 0.10390121546110268
test metrics:
R2: 0.9416868686676025
MSE: 22420.767578125
MAPE: 0.15094894340033838
MSE diff_p 179
----------
180: 0.0017814618768170476
Training Epoch 180
train_metrics: 
R2: 0.9639183878898621
MSE: 11667.328125
MAPE: 0.09569172693429033
test metrics:
R2: 0.9460720419883728
MSE: 21286.771484375
MAPE: 0.15313540587555388
MSE diff_p 180
----------
181: 0.0017844067187979817
Training Epoch 181
train_metrics: 
R2: 0.9702979326248169
MSE: 11686.615234375
MAPE: 0.10707329047122148
test metrics:
R2: 0.9516820907592773
MSE: 19388.94921875
MAPE: 0.1448241047181552
MSE diff_p 181
----------
182: 0.0019083679653704166
Training Epoch 182
train_metrics: 
R2: 0.9640583395957947
MSE: 12498.474609375
MAPE: 0.1052007573078508
test metrics:
R2: 0.9537394642829895
MSE: 18761.638671875
MAPE: 0.14134872338144214
MSE diff_p 182
----------
183: 0.0023457705974578857
Training Epoch 183
train_metrics: 
R2: 0.9587797522544861
MSE: 15363.1572265625
MAPE: 0.11327895591889661
test metrics:
R2: 0.9469820261001587
MSE: 21543.6796875
MAPE: 0.15672967564695606
MSE diff_p 183
----------
184: 0.0023697521537542343
Training Epoch 184
train_metrics: 
R2: 0.9603999257087708
MSE: 15520.220703125
MAPE: 0.1276513992977027
test metrics:
R2: 0.9568268656730652
MSE: 17598.50390625
MAPE: 0.13697432402589457
MSE diff_p 184
----------
185: 0.0014508916065096855
Training Epoch 185
train_metrics: 
R2: 0.9718685150146484
MSE: 9502.3251953125
MAPE: 0.09013601957181276
test metrics:
R2: 0.9454910755157471
MSE: 21803.869140625
MAPE: 0.16261642924935205
MSE diff_p 185
----------
186: 0.002055322751402855
Training Epoch 186
train_metrics: 
R2: 0.9599605798721313
MSE: 13460.92578125
MAPE: 0.12019931226437641
test metrics:
R2: 0.9561731219291687
MSE: 17773.8359375
MAPE: 0.1390160279944086
MSE diff_p 186
----------
187: 0.0018515168922021985
Training Epoch 187
train_metrics: 
R2: 0.968020498752594
MSE: 12126.142578125
MAPE: 0.10246903000010404
test metrics:
R2: 0.9502285122871399
MSE: 20015.53515625
MAPE: 0.15190777212568762
MSE diff_p 187
----------
188: 0.0017793320585042238
Training Epoch 188
train_metrics: 
R2: 0.9697047472000122
MSE: 11653.380859375
MAPE: 0.10572355445850296
test metrics:
R2: 0.9572601914405823
MSE: 17469.212890625
MAPE: 0.13743774005306492
MSE diff_p 188
----------
189: 0.0018509695073589683
Training Epoch 189
train_metrics: 
R2: 0.9666388630867004
MSE: 12122.5537109375
MAPE: 0.10673511089680739
test metrics:
R2: 0.9502118229866028
MSE: 20461.763671875
MAPE: 0.1541536859673629
MSE diff_p 189
----------
190: 0.0019877057056874037
Training Epoch 190
train_metrics: 
R2: 0.9645069241523743
MSE: 13018.0830078125
MAPE: 0.10517954968756404
test metrics:
R2: 0.9578471779823303
MSE: 17152.79296875
MAPE: 0.1365035489359598
MSE diff_p 190
----------
191: 0.0019681034609675407
Training Epoch 191
train_metrics: 
R2: 0.9679017663002014
MSE: 12889.703125
MAPE: 0.12120710129543462
test metrics:
R2: 0.9474003911018372
MSE: 21565.1875
MAPE: 0.16151608974464643
MSE diff_p 191
----------
192: 0.0020680942106992006
Training Epoch 192
train_metrics: 
R2: 0.9622606635093689
MSE: 13544.57421875
MAPE: 0.12267509550820488
test metrics:
R2: 0.9578108787536621
MSE: 17227.42578125
MAPE: 0.1380807493551005
MSE diff_p 192
----------
193: 0.001621695002540946
Training Epoch 193
train_metrics: 
R2: 0.9715427160263062
MSE: 10620.966796875
MAPE: 0.10594935443903447
test metrics:
R2: 0.9541515111923218
MSE: 18711.6953125
MAPE: 0.146158126728966
MSE diff_p 193
----------
194: 0.0018287606071680784
Training Epoch 194
train_metrics: 
R2: 0.965070366859436
MSE: 11977.103515625
MAPE: 0.10054813459892162
test metrics:
R2: 0.9533563852310181
MSE: 18809.986328125
MAPE: 0.14734054299971075
MSE diff_p 194
----------
195: 0.0018818266689777374
Training Epoch 195
train_metrics: 
R2: 0.9673799276351929
MSE: 12324.6484375
MAPE: 0.1100736160780015
test metrics:
R2: 0.9560971856117249
MSE: 17953.94140625
MAPE: 0.1429388001991383
MSE diff_p 195
----------
196: 0.0017125223530456424
Training Epoch 196
train_metrics: 
R2: 0.9692104458808899
MSE: 11215.82421875
MAPE: 0.09257211935712478
test metrics:
R2: 0.954079806804657
MSE: 18696.876953125
MAPE: 0.14732915153861684
MSE diff_p 196
----------
197: 0.001764051616191864
Training Epoch 197
train_metrics: 
R2: 0.9688971042633057
MSE: 11553.3046875
MAPE: 0.10360221545119165
test metrics:
R2: 0.9579208493232727
MSE: 17341.212890625
MAPE: 0.1397613862911407
MSE diff_p 197
----------
198: 0.001993304817005992
Training Epoch 198
train_metrics: 
R2: 0.9649080038070679
MSE: 13054.75390625
MAPE: 0.11109804054056843
test metrics:
R2: 0.951278030872345
MSE: 20111.43359375
MAPE: 0.15568241335569827
MSE diff_p 198
----------
199: 0.0017812169389799237
Training Epoch 199
train_metrics: 
R2: 0.9667746424674988
MSE: 11665.72265625
MAPE: 0.09881245562560334
test metrics:
R2: 0.9577244520187378
MSE: 17185.435546875
MAPE: 0.13954685528366362
MSE diff_p 199
----------
