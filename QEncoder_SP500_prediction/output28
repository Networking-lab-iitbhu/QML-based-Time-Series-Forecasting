os.getpid()=46197
args.num_latent=2
args.num_trash=8

 Training Encoder...

Encoder Loss: 0.172 Iteration: 1
Encoder Loss: 0.099 Iteration: 2
Encoder Loss: 0.081 Iteration: 3
Encoder Loss: 0.06 Iteration: 4
Encoder Loss: 0.054 Iteration: 5
Encoder Loss: 0.055 Iteration: 6
Encoder Loss: 0.055 Iteration: 7
Encoder Loss: 0.056 Iteration: 8
Encoder Loss: 0.064 Iteration: 9
Encoder Loss: 0.049 Iteration: 10
Encoder Loss: 0.057 Iteration: 11
Encoder Loss: 0.056 Iteration: 12
Encoder Loss: 0.055 Iteration: 13
Encoder Loss: 0.056 Iteration: 14
Encoder Loss: 0.06 Iteration: 15
Encoder Loss: 0.063 Iteration: 16
Encoder Loss: 0.053 Iteration: 17
Encoder Loss: 0.056 Iteration: 18
Encoder Loss: 0.053 Iteration: 19
Encoder Loss: 0.057 Iteration: 20
Encoder Loss: 0.052 Iteration: 21
Encoder Loss: 0.055 Iteration: 22
Encoder Loss: 0.055 Iteration: 23
Encoder Loss: 0.059 Iteration: 24
Encoder Loss: 0.06 Iteration: 25
Encoder Loss: 0.055 Iteration: 26
Encoder Loss: 0.052 Iteration: 27
Encoder Loss: 0.057 Iteration: 28
Encoder Loss: 0.053 Iteration: 29
Encoder Loss: 0.055 Iteration: 30
Training Started... 
0: 0.1555282324552536
Training Epoch 0
train_metrics: 
R2: -12.42342472076416
MSE: 1018601.125
MAPE: 0.4667631090942015
test metrics:
R2: -20.76663589477539
MSE: 1176880.375
MAPE: 0.5652060034072183
before val features
MSE diff_p 0
----------
1: 0.06534919142723083
Training Epoch 1
train_metrics: 
R2: -357.9722595214844
MSE: 427991.5
MAPE: 0.42547738717935885
test metrics:
R2: -580.9468383789062
MSE: 592328.5625
MAPE: 0.5400199830470838
MSE diff_p 1
----------
2: 0.05775311961770058
Training Epoch 2
train_metrics: 
R2: -171.72817993164062
MSE: 378242.5625
MAPE: 0.42234513057628353
test metrics:
R2: -273.9250793457031
MSE: 508407.90625
MAPE: 0.5208391740034602
MSE diff_p 2
----------
3: 0.046886347234249115
Training Epoch 3
train_metrics: 
R2: -25.759750366210938
MSE: 307072.8125
MAPE: 0.37590936601977765
test metrics:
R2: -42.15717315673828
MSE: 437625.0625
MAPE: 0.48216036958764164
MSE diff_p 3
----------
4: 0.04950057715177536
Training Epoch 4
train_metrics: 
R2: -23.725610733032227
MSE: 324194.1875
MAPE: 0.37814268751537616
test metrics:
R2: -33.434627532958984
MSE: 448631.375
MAPE: 0.46662198907634056
MSE diff_p 4
----------
5: 0.04697601869702339
Training Epoch 5
train_metrics: 
R2: -12.642173767089844
MSE: 307660.125
MAPE: 0.373603652784109
test metrics:
R2: -18.719785690307617
MSE: 390070.46875
MAPE: 0.4565222459918338
MSE diff_p 5
----------
6: 0.03293425962328911
Training Epoch 6
train_metrics: 
R2: -4.3233418464660645
MSE: 215696.375
MAPE: 0.3228953297365648
test metrics:
R2: -8.09638500213623
MSE: 331431.53125
MAPE: 0.4270738495673907
MSE diff_p 6
----------
7: 0.027339830994606018
Training Epoch 7
train_metrics: 
R2: -3.031062602996826
MSE: 179056.78125
MAPE: 0.294171295811606
test metrics:
R2: -4.569936275482178
MSE: 286682.25
MAPE: 0.40860083587108326
MSE diff_p 7
----------
8: 0.028319088742136955
Training Epoch 8
train_metrics: 
R2: -2.1622347831726074
MSE: 185470.234375
MAPE: 0.30166070454670996
test metrics:
R2: -4.185328960418701
MSE: 280063.84375
MAPE: 0.4028923347954327
MSE diff_p 8
----------
9: 0.024542780593037605
Training Epoch 9
train_metrics: 
R2: -1.4050483703613281
MSE: 160738.03125
MAPE: 0.2791837505984389
test metrics:
R2: -2.592655658721924
MSE: 248247.046875
MAPE: 0.3899801223766303
MSE diff_p 9
----------
10: 0.024115003645420074
Training Epoch 10
train_metrics: 
R2: -1.106818437576294
MSE: 157936.40625
MAPE: 0.272125832900197
test metrics:
R2: -2.4679670333862305
MSE: 244233.859375
MAPE: 0.3842483140078745
MSE diff_p 10
----------
11: 0.022949881851673126
Training Epoch 11
train_metrics: 
R2: -0.7980372905731201
MSE: 150305.6875
MAPE: 0.2816686567930499
test metrics:
R2: -1.7013144493103027
MSE: 224385.359375
MAPE: 0.3745907593024363
MSE diff_p 11
----------
12: 0.020373428240418434
Training Epoch 12
train_metrics: 
R2: -0.6058839559555054
MSE: 133431.703125
MAPE: 0.2641700572675086
test metrics:
R2: -1.6902945041656494
MSE: 222269.1875
MAPE: 0.37352789591440416
MSE diff_p 12
----------
13: 0.020422600209712982
Training Epoch 13
train_metrics: 
R2: -0.5811793804168701
MSE: 133753.75
MAPE: 0.2600465049121554
test metrics:
R2: -1.3587183952331543
MSE: 210433.875
MAPE: 0.3644690350156743
MSE diff_p 13
----------
14: 0.01888444274663925
Training Epoch 14
train_metrics: 
R2: -0.42364227771759033
MSE: 123679.890625
MAPE: 0.24266497293363792
test metrics:
R2: -1.3387162685394287
MSE: 211526.078125
MAPE: 0.36817104410604
MSE diff_p 14
----------
15: 0.0172699186950922
Training Epoch 15
train_metrics: 
R2: -0.255570650100708
MSE: 113105.890625
MAPE: 0.2346186988009937
test metrics:
R2: -1.1230769157409668
MSE: 201066.875
MAPE: 0.3569738344280013
MSE diff_p 15
----------
16: 0.018943380564451218
Training Epoch 16
train_metrics: 
R2: -0.27262771129608154
MSE: 124065.8828125
MAPE: 0.2536679965095481
test metrics:
R2: -1.0683948993682861
MSE: 202166.328125
MAPE: 0.3608742574371853
MSE diff_p 16
----------
17: 0.017756808549165726
Training Epoch 17
train_metrics: 
R2: -0.31041479110717773
MSE: 116294.6875
MAPE: 0.23838278384710493
test metrics:
R2: -0.9085675477981567
MSE: 192596.828125
MAPE: 0.3516359578357446
MSE diff_p 17
----------
18: 0.018641561269760132
Training Epoch 18
train_metrics: 
R2: -0.1397852897644043
MSE: 122089.2109375
MAPE: 0.2390545880037737
test metrics:
R2: -0.8228099346160889
MSE: 190446.578125
MAPE: 0.3529177788357354
MSE diff_p 18
----------
19: 0.01629878766834736
Training Epoch 19
train_metrics: 
R2: -0.0009416341781616211
MSE: 106745.65625
MAPE: 0.23561091139158602
test metrics:
R2: -0.7183393239974976
MSE: 184985.84375
MAPE: 0.34611430951415173
MSE diff_p 19
----------
20: 0.017456427216529846
Training Epoch 20
train_metrics: 
R2: 0.00996619462966919
MSE: 114327.390625
MAPE: 0.25310350245817304
test metrics:
R2: -0.6515003442764282
MSE: 182568.171875
MAPE: 0.3450050498103835
MSE diff_p 20
----------
21: 0.01644897274672985
Training Epoch 21
train_metrics: 
R2: 0.048378944396972656
MSE: 107729.265625
MAPE: 0.229792971351019
test metrics:
R2: -0.5340039730072021
MSE: 176180.265625
MAPE: 0.3427051113983263
MSE diff_p 21
----------
22: 0.01631530001759529
Training Epoch 22
train_metrics: 
R2: 0.11708855628967285
MSE: 106853.8125
MAPE: 0.24111083831584318
test metrics:
R2: -0.4525982141494751
MSE: 172335.78125
MAPE: 0.3395001400670691
MSE diff_p 22
----------
23: 0.01562228798866272
Training Epoch 23
train_metrics: 
R2: 0.19469141960144043
MSE: 102315.0625
MAPE: 0.214565411790894
test metrics:
R2: -0.3059271574020386
MSE: 162584.453125
MAPE: 0.3271352216980197
MSE diff_p 23
----------
24: 0.016191847622394562
Training Epoch 24
train_metrics: 
R2: 0.25512707233428955
MSE: 106045.28125
MAPE: 0.2430173773191254
test metrics:
R2: -0.2663334608078003
MSE: 162516.25
MAPE: 0.33141463145144656
MSE diff_p 24
----------
25: 0.014642330817878246
Training Epoch 25
train_metrics: 
R2: 0.2504626512527466
MSE: 95897.015625
MAPE: 0.21514856454057865
test metrics:
R2: -0.1736050844192505
MSE: 155424.4375
MAPE: 0.3211181587017572
MSE diff_p 25
----------
26: 0.013677685521543026
Training Epoch 26
train_metrics: 
R2: 0.359655499458313
MSE: 89579.2734375
MAPE: 0.21251101036184988
test metrics:
R2: -0.055335164070129395
MSE: 147915.453125
MAPE: 0.31675254709350265
MSE diff_p 26
----------
27: 0.010423930361866951
Training Epoch 27
train_metrics: 
R2: 0.5179333686828613
MSE: 68269.453125
MAPE: 0.19303336554170786
test metrics:
R2: -0.010678887367248535
MSE: 144898.515625
MAPE: 0.3159448204528134
MSE diff_p 27
----------
28: 0.012453397735953331
Training Epoch 28
train_metrics: 
R2: 0.47812676429748535
MSE: 81561.046875
MAPE: 0.20128318611380222
test metrics:
R2: 0.049530088901519775
MSE: 139994.0
MAPE: 0.3031053017139034
MSE diff_p 28
----------
29: 0.011137725785374641
Training Epoch 29
train_metrics: 
R2: 0.5198272466659546
MSE: 72944.3125
MAPE: 0.19955855551272828
test metrics:
R2: 0.1089637279510498
MSE: 136501.328125
MAPE: 0.31023161795753185
MSE diff_p 29
----------
30: 0.013353527523577213
Training Epoch 30
train_metrics: 
R2: 0.4625908136367798
MSE: 87456.265625
MAPE: 0.21621707993028297
test metrics:
R2: 0.17290139198303223
MSE: 130618.4140625
MAPE: 0.29714468630288826
MSE diff_p 30
----------
31: 0.010926574468612671
Training Epoch 31
train_metrics: 
R2: 0.5459946393966675
MSE: 71561.421875
MAPE: 0.21969234830189255
test metrics:
R2: 0.21960103511810303
MSE: 127639.015625
MAPE: 0.30760004087060444
MSE diff_p 31
----------
32: 0.011385288089513779
Training Epoch 32
train_metrics: 
R2: 0.5690319538116455
MSE: 74565.671875
MAPE: 0.204015722477207
test metrics:
R2: 0.2060888409614563
MSE: 128217.203125
MAPE: 0.2851720397251794
MSE diff_p 32
----------
33: 0.012100282125175
Training Epoch 33
train_metrics: 
R2: 0.4977187514305115
MSE: 79248.390625
MAPE: 0.21999215607149727
test metrics:
R2: 0.19836300611495972
MSE: 132486.234375
MAPE: 0.3212940280086072
MSE diff_p 33
----------
34: 0.013927217572927475
Training Epoch 34
train_metrics: 
R2: 0.46919405460357666
MSE: 91213.53125
MAPE: 0.239866921240913
test metrics:
R2: 0.19424384832382202
MSE: 129816.6796875
MAPE: 0.2875803723461768
MSE diff_p 34
----------
35: 0.012024559080600739
Training Epoch 35
train_metrics: 
R2: 0.5253310203552246
MSE: 78752.4375
MAPE: 0.2201879036033529
test metrics:
R2: 0.2677319645881653
MSE: 126548.1875
MAPE: 0.3188918613541903
MSE diff_p 35
----------
36: 0.011130538769066334
Training Epoch 36
train_metrics: 
R2: 0.5867794752120972
MSE: 72897.25
MAPE: 0.20526649087355076
test metrics:
R2: 0.35361218452453613
MSE: 115077.9765625
MAPE: 0.2723405729563554
MSE diff_p 36
----------
37: 0.01045819092541933
Training Epoch 37
train_metrics: 
R2: 0.6166070699691772
MSE: 68493.8359375
MAPE: 0.20351164635827607
test metrics:
R2: 0.41883397102355957
MSE: 109754.1875
MAPE: 0.2966649817528666
MSE diff_p 37
----------
38: 0.009782939217984676
Training Epoch 38
train_metrics: 
R2: 0.6605994701385498
MSE: 64071.4140625
MAPE: 0.2075852582004229
test metrics:
R2: 0.4441208839416504
MSE: 105224.40625
MAPE: 0.26441291352469753
MSE diff_p 38
----------
39: 0.008405259810388088
Training Epoch 39
train_metrics: 
R2: 0.6954922676086426
MSE: 55048.57421875
MAPE: 0.1927383196599287
test metrics:
R2: 0.4606638550758362
MSE: 104999.4921875
MAPE: 0.2926755130093883
MSE diff_p 39
----------
40: 0.006963843479752541
Training Epoch 40
train_metrics: 
R2: 0.7606237530708313
MSE: 45608.30078125
MAPE: 0.18483493070062734
test metrics:
R2: 0.5420273542404175
MSE: 94278.4140625
MAPE: 0.2516621627799311
MSE diff_p 40
----------
41: 0.010270996950566769
Training Epoch 41
train_metrics: 
R2: 0.6657218337059021
MSE: 67267.8359375
MAPE: 0.1896257210132429
test metrics:
R2: 0.5314018726348877
MSE: 96410.453125
MAPE: 0.2760058922154441
MSE diff_p 41
----------
42: 0.007625763304531574
Training Epoch 42
train_metrics: 
R2: 0.7392961978912354
MSE: 49943.4140625
MAPE: 0.1634823321009596
test metrics:
R2: 0.5849997401237488
MSE: 88564.796875
MAPE: 0.24771747797602384
MSE diff_p 42
----------
43: 0.007685541640967131
Training Epoch 43
train_metrics: 
R2: 0.733964741230011
MSE: 50334.92578125
MAPE: 0.17339233902039194
test metrics:
R2: 0.5684018135070801
MSE: 92360.2578125
MAPE: 0.27743491422762323
MSE diff_p 43
----------
44: 0.007908518426120281
Training Epoch 44
train_metrics: 
R2: 0.7652090787887573
MSE: 51795.265625
MAPE: 0.16729874411987716
test metrics:
R2: 0.6118577718734741
MSE: 85600.5859375
MAPE: 0.2398459335898617
MSE diff_p 44
----------
45: 0.007619692478328943
Training Epoch 45
train_metrics: 
R2: 0.7694499492645264
MSE: 49903.65625
MAPE: 0.19037951668052824
test metrics:
R2: 0.610249400138855
MSE: 86173.65625
MAPE: 0.26455988019627275
MSE diff_p 45
----------
46: 0.007155136205255985
Training Epoch 46
train_metrics: 
R2: 0.7772032022476196
MSE: 46861.13671875
MAPE: 0.14801984926142744
test metrics:
R2: 0.6439516544342041
MSE: 81303.6484375
MAPE: 0.23664118666873832
MSE diff_p 46
----------
47: 0.006840626709163189
Training Epoch 47
train_metrics: 
R2: 0.8050971031188965
MSE: 44801.3203125
MAPE: 0.16375745843267814
test metrics:
R2: 0.638627827167511
MSE: 82866.84375
MAPE: 0.2622661256327109
MSE diff_p 47
----------
48: 0.007453257218003273
Training Epoch 48
train_metrics: 
R2: 0.7774343490600586
MSE: 48813.625
MAPE: 0.18512031424934933
test metrics:
R2: 0.6685371398925781
MSE: 77681.25
MAPE: 0.2331572196019397
MSE diff_p 48
----------
49: 0.00641891872510314
Training Epoch 49
train_metrics: 
R2: 0.8052878379821777
MSE: 42039.4296875
MAPE: 0.16712217204696783
test metrics:
R2: 0.6682320833206177
MSE: 78608.0625
MAPE: 0.25684533032689927
MSE diff_p 49
----------
50: 0.007564149796962738
Training Epoch 50
train_metrics: 
R2: 0.79426109790802
MSE: 49539.890625
MAPE: 0.1829233419546204
test metrics:
R2: 0.6875103712081909
MSE: 75126.4375
MAPE: 0.2264078844795247
MSE diff_p 50
----------
51: 0.006088551599532366
Training Epoch 51
train_metrics: 
R2: 0.8320420980453491
MSE: 39875.7578125
MAPE: 0.15641059139925834
test metrics:
R2: 0.6783376932144165
MSE: 77579.9453125
MAPE: 0.2548323318512026
MSE diff_p 51
----------
52: 0.00569630553945899
Training Epoch 52
train_metrics: 
R2: 0.8433746099472046
MSE: 37306.8203125
MAPE: 0.14767823279635364
test metrics:
R2: 0.7132511734962463
MSE: 71143.71875
MAPE: 0.22620833681512523
MSE diff_p 52
----------
53: 0.006604594644159079
Training Epoch 53
train_metrics: 
R2: 0.7988272905349731
MSE: 43255.4765625
MAPE: 0.15703246988028502
test metrics:
R2: 0.7020677328109741
MSE: 73705.8828125
MAPE: 0.24768401894613698
MSE diff_p 53
----------
54: 0.006398714613169432
Training Epoch 54
train_metrics: 
R2: 0.8262497186660767
MSE: 41907.1015625
MAPE: 0.16626273121941168
test metrics:
R2: 0.7350096702575684
MSE: 67593.078125
MAPE: 0.22111711951278704
MSE diff_p 54
----------
55: 0.006123898085206747
Training Epoch 55
train_metrics: 
R2: 0.8407977819442749
MSE: 40107.24609375
MAPE: 0.16471434942290752
test metrics:
R2: 0.7262438535690308
MSE: 69749.828125
MAPE: 0.2414309833103114
MSE diff_p 55
----------
56: 0.005037055350840092
Training Epoch 56
train_metrics: 
R2: 0.8673259615898132
MSE: 32989.19140625
MAPE: 0.13178534676425735
test metrics:
R2: 0.7579951286315918
MSE: 63889.53515625
MAPE: 0.2155517755560777
MSE diff_p 56
----------
57: 0.0055522858165204525
Training Epoch 57
train_metrics: 
R2: 0.8547565937042236
MSE: 36363.58984375
MAPE: 0.1589378314613472
test metrics:
R2: 0.7391620874404907
MSE: 67976.2421875
MAPE: 0.2408037406191764
MSE diff_p 57
----------
58: 0.0068497867323458195
Training Epoch 58
train_metrics: 
R2: 0.8105540871620178
MSE: 44861.31640625
MAPE: 0.1394345398742989
test metrics:
R2: 0.7644119262695312
MSE: 62953.4140625
MAPE: 0.2131752886716327
MSE diff_p 58
----------
59: 0.00487172557041049
Training Epoch 59
train_metrics: 
R2: 0.8569631576538086
MSE: 31906.396484375
MAPE: 0.1428668449176666
test metrics:
R2: 0.7563530802726746
MSE: 65134.16015625
MAPE: 0.23681934120949458
MSE diff_p 59
----------
60: 0.005663358140736818
Training Epoch 60
train_metrics: 
R2: 0.8639311194419861
MSE: 37091.03515625
MAPE: 0.1620910167915827
test metrics:
R2: 0.7843145132064819
MSE: 59378.3203125
MAPE: 0.20577996127999496
MSE diff_p 60
----------
61: 0.006815411150455475
Training Epoch 61
train_metrics: 
R2: 0.8205355405807495
MSE: 44636.171875
MAPE: 0.1879513461058146
test metrics:
R2: 0.7501722574234009
MSE: 67067.109375
MAPE: 0.2474239282257008
MSE diff_p 61
----------
62: 0.007599233649671078
Training Epoch 62
train_metrics: 
R2: 0.8159209489822388
MSE: 49769.671875
MAPE: 0.20005824199230304
test metrics:
R2: 0.7841972708702087
MSE: 60161.1796875
MAPE: 0.20683502790132868
MSE diff_p 62
----------
63: 0.0058028376661241055
Training Epoch 63
train_metrics: 
R2: 0.8485941886901855
MSE: 38004.53125
MAPE: 0.17714489532511085
test metrics:
R2: 0.726939857006073
MSE: 72642.4375
MAPE: 0.2634825831909124
MSE diff_p 63
----------
64: 0.006789248436689377
Training Epoch 64
train_metrics: 
R2: 0.8291324377059937
MSE: 44464.828125
MAPE: 0.17289243869076315
test metrics:
R2: 0.7974330186843872
MSE: 57356.80078125
MAPE: 0.20146161206793944
MSE diff_p 64
----------
65: 0.004783161915838718
Training Epoch 65
train_metrics: 
R2: 0.8710500597953796
MSE: 31326.365234375
MAPE: 0.17028181105834894
test metrics:
R2: 0.7506805658340454
MSE: 67812.7734375
MAPE: 0.2527216334006434
MSE diff_p 65
----------
66: 0.006465374492108822
Training Epoch 66
train_metrics: 
R2: 0.8578179478645325
MSE: 42343.6796875
MAPE: 0.1763709149350084
test metrics:
R2: 0.8049860000610352
MSE: 56199.953125
MAPE: 0.19878120069149266
MSE diff_p 66
----------
67: 0.005927236285060644
Training Epoch 67
train_metrics: 
R2: 0.8454910516738892
MSE: 38819.25
MAPE: 0.16886916850430878
test metrics:
R2: 0.7719927430152893
MSE: 64178.2734375
MAPE: 0.24597128188285203
MSE diff_p 67
----------
68: 0.005231535993516445
Training Epoch 68
train_metrics: 
R2: 0.8775001764297485
MSE: 34262.8984375
MAPE: 0.16275188916766592
test metrics:
R2: 0.8251057863235474
MSE: 51807.078125
MAPE: 0.19298838987226324
MSE diff_p 68
----------
69: 0.005481348372995853
Training Epoch 69
train_metrics: 
R2: 0.8699339628219604
MSE: 35899.0
MAPE: 0.17180783488847434
test metrics:
R2: 0.7910855412483215
MSE: 60056.828125
MAPE: 0.23639913381930236
MSE diff_p 69
----------
70: 0.005437370389699936
Training Epoch 70
train_metrics: 
R2: 0.86696857213974
MSE: 35610.96875
MAPE: 0.1708834185353884
test metrics:
R2: 0.8376581072807312
MSE: 49388.70703125
MAPE: 0.18971417921771297
MSE diff_p 70
----------
71: 0.0039477902464568615
Training Epoch 71
train_metrics: 
R2: 0.9060219526290894
MSE: 25855.265625
MAPE: 0.13700988269095887
test metrics:
R2: 0.8087928295135498
MSE: 56602.359375
MAPE: 0.23107425068118553
MSE diff_p 71
----------
72: 0.0038910498842597008
Training Epoch 72
train_metrics: 
R2: 0.909245491027832
MSE: 25483.65625
MAPE: 0.14441837998637796
test metrics:
R2: 0.8477203845977783
MSE: 47220.47265625
MAPE: 0.18649975277604408
MSE diff_p 72
----------
73: 0.003666468197479844
Training Epoch 73
train_metrics: 
R2: 0.9105976223945618
MSE: 24012.8046875
MAPE: 0.13491836310710043
test metrics:
R2: 0.8311963677406311
MSE: 51618.98046875
MAPE: 0.21676400560662917
MSE diff_p 73
----------
74: 0.003770261537283659
Training Epoch 74
train_metrics: 
R2: 0.9057207107543945
MSE: 24692.57421875
MAPE: 0.14655191475974075
test metrics:
R2: 0.8570032119750977
MSE: 45249.89453125
MAPE: 0.18167571463107016
MSE diff_p 74
----------
75: 0.004317319020628929
Training Epoch 75
train_metrics: 
R2: 0.8970882296562195
MSE: 28275.419921875
MAPE: 0.13659829386666789
test metrics:
R2: 0.8293567299842834
MSE: 52208.58203125
MAPE: 0.2204163547639512
MSE diff_p 75
----------
76: 0.00365430093370378
Training Epoch 76
train_metrics: 
R2: 0.9127002954483032
MSE: 23933.119140625
MAPE: 0.12947685084287058
test metrics:
R2: 0.8633599877357483
MSE: 43763.58984375
MAPE: 0.18049340733554164
MSE diff_p 76
----------
77: 0.0038313756231218576
Training Epoch 77
train_metrics: 
R2: 0.9176815748214722
MSE: 25092.830078125
MAPE: 0.1277906873364001
test metrics:
R2: 0.8443099856376648
MSE: 48939.40234375
MAPE: 0.21139577682175184
MSE diff_p 77
----------
78: 0.003820370649918914
Training Epoch 78
train_metrics: 
R2: 0.9116110801696777
MSE: 25020.76171875
MAPE: 0.1475057107813801
test metrics:
R2: 0.8644355535507202
MSE: 43746.9765625
MAPE: 0.185472547172641
MSE diff_p 78
----------
79: 0.003908531274646521
Training Epoch 79
train_metrics: 
R2: 0.9138849973678589
MSE: 25598.1484375
MAPE: 0.13956494950947715
test metrics:
R2: 0.8689491152763367
MSE: 42827.734375
MAPE: 0.18591913112606281
MSE diff_p 79
----------
80: 0.00406681327149272
Training Epoch 80
train_metrics: 
R2: 0.9112220406532288
MSE: 26634.78515625
MAPE: 0.12071731792304324
test metrics:
R2: 0.8763871788978577
MSE: 40948.46875
MAPE: 0.17696401222223404
MSE diff_p 80
----------
81: 0.003955793101340532
Training Epoch 81
train_metrics: 
R2: 0.9107962250709534
MSE: 25907.681640625
MAPE: 0.14255227685493782
test metrics:
R2: 0.8662033081054688
MSE: 43767.6171875
MAPE: 0.20147596556834013
MSE diff_p 81
----------
82: 0.004418943542987108
Training Epoch 82
train_metrics: 
R2: 0.9075146317481995
MSE: 28940.9921875
MAPE: 0.13507309926056776
test metrics:
R2: 0.8813501596450806
MSE: 39676.5546875
MAPE: 0.17438771401714195
MSE diff_p 82
----------
83: 0.003505960339680314
Training Epoch 83
train_metrics: 
R2: 0.9248213171958923
MSE: 22961.58984375
MAPE: 0.12411130173444981
test metrics:
R2: 0.880441427230835
MSE: 40203.453125
MAPE: 0.1841065163905887
MSE diff_p 83
----------
84: 0.003808532143011689
Training Epoch 84
train_metrics: 
R2: 0.9158889055252075
MSE: 24943.220703125
MAPE: 0.12287954469351409
test metrics:
R2: 0.8803356885910034
MSE: 40180.19140625
MAPE: 0.18386629041730393
MSE diff_p 84
----------
85: 0.003569579916074872
Training Epoch 85
train_metrics: 
R2: 0.9216553568840027
MSE: 23378.25
MAPE: 0.129855914752999
test metrics:
R2: 0.8827258348464966
MSE: 39418.23046875
MAPE: 0.17715947047863467
MSE diff_p 85
----------
86: 0.002565308939665556
Training Epoch 86
train_metrics: 
R2: 0.9488942623138428
MSE: 16800.98046875
MAPE: 0.12210998124841664
test metrics:
R2: 0.882420003414154
MSE: 39622.90625
MAPE: 0.18191883230203404
MSE diff_p 86
----------
87: 0.003168996889144182
Training Epoch 87
train_metrics: 
R2: 0.9273989200592041
MSE: 20754.71484375
MAPE: 0.11938605913224828
test metrics:
R2: 0.8845376968383789
MSE: 39113.84375
MAPE: 0.17779570195943276
MSE diff_p 87
----------
88: 0.0027957784477621317
Training Epoch 88
train_metrics: 
R2: 0.9395024180412292
MSE: 18310.396484375
MAPE: 0.13063868275061427
test metrics:
R2: 0.8795023560523987
MSE: 40438.30078125
MAPE: 0.19044090246387763
MSE diff_p 88
----------
89: 0.002681163139641285
Training Epoch 89
train_metrics: 
R2: 0.9450535774230957
MSE: 17559.744140625
MAPE: 0.13782672308224464
test metrics:
R2: 0.893630862236023
MSE: 36691.90625
MAPE: 0.16897193303849253
MSE diff_p 89
----------
90: 0.0037015918642282486
Training Epoch 90
train_metrics: 
R2: 0.9225296974182129
MSE: 24242.8359375
MAPE: 0.1250458626210153
test metrics:
R2: 0.8883101344108582
MSE: 38381.3671875
MAPE: 0.17655909450719984
MSE diff_p 90
----------
91: 0.0026692599058151245
Training Epoch 91
train_metrics: 
R2: 0.9403848052024841
MSE: 17481.78515625
MAPE: 0.1093246211333333
test metrics:
R2: 0.8931487202644348
MSE: 36808.23828125
MAPE: 0.17235371704197022
MSE diff_p 91
----------
92: 0.0036195190623402596
Training Epoch 92
train_metrics: 
R2: 0.9307520389556885
MSE: 23705.322265625
MAPE: 0.12847537870217834
test metrics:
R2: 0.8892450928688049
MSE: 38120.5078125
MAPE: 0.18320591664590738
MSE diff_p 92
----------
93: 0.003302372992038727
Training Epoch 93
train_metrics: 
R2: 0.9339665174484253
MSE: 21628.232421875
MAPE: 0.12209346068031932
test metrics:
R2: 0.9007812738418579
MSE: 34774.98828125
MAPE: 0.16630391136156822
MSE diff_p 93
----------
94: 0.0033983909524977207
Training Epoch 94
train_metrics: 
R2: 0.9291566610336304
MSE: 22257.0859375
MAPE: 0.13339062834465443
test metrics:
R2: 0.8840857148170471
MSE: 39754.19921875
MAPE: 0.19662642395827593
MSE diff_p 94
----------
95: 0.0033852041233330965
Training Epoch 95
train_metrics: 
R2: 0.9317336082458496
MSE: 22170.71875
MAPE: 0.13868395923868113
test metrics:
R2: 0.9005956649780273
MSE: 34760.97265625
MAPE: 0.16587782678035495
MSE diff_p 95
----------
96: 0.003264649771153927
Training Epoch 96
train_metrics: 
R2: 0.9360532760620117
MSE: 21381.173828125
MAPE: 0.1341427272973489
test metrics:
R2: 0.8804404139518738
MSE: 41208.1171875
MAPE: 0.20447624910171475
MSE diff_p 96
----------
97: 0.003428261261433363
Training Epoch 97
train_metrics: 
R2: 0.9355000257492065
MSE: 22452.71484375
MAPE: 0.13381964105238242
test metrics:
R2: 0.9042820930480957
MSE: 33915.1015625
MAPE: 0.1640051743127411
MSE diff_p 97
----------
98: 0.0035274962428957224
Training Epoch 98
train_metrics: 
R2: 0.9281679391860962
MSE: 23102.6328125
MAPE: 0.12327469631588406
test metrics:
R2: 0.881853461265564
MSE: 40963.56640625
MAPE: 0.20438129966187715
MSE diff_p 98
----------
99: 0.002880751620978117
Training Epoch 99
train_metrics: 
R2: 0.9395886659622192
MSE: 18866.91015625
MAPE: 0.1366113228077424
test metrics:
R2: 0.9067012071609497
MSE: 33226.09375
MAPE: 0.165258123979121
MSE diff_p 99
----------
100: 0.003342677606269717
Training Epoch 100
train_metrics: 
R2: 0.9368901252746582
MSE: 21892.1953125
MAPE: 0.14245549319711576
test metrics:
R2: 0.8836628198623657
MSE: 40447.61328125
MAPE: 0.20333244579107648
MSE diff_p 100
----------
101: 0.0033335427287966013
Training Epoch 101
train_metrics: 
R2: 0.9308288097381592
MSE: 21832.375
MAPE: 0.13945503197189296
test metrics:
R2: 0.9075559973716736
MSE: 33151.98828125
MAPE: 0.16161564933188008
MSE diff_p 101
----------
102: 0.0030224043875932693
Training Epoch 102
train_metrics: 
R2: 0.9356001019477844
MSE: 19794.634765625
MAPE: 0.13306922984778655
test metrics:
R2: 0.8815045356750488
MSE: 41195.2734375
MAPE: 0.2072697712077194
MSE diff_p 102
----------
103: 0.003957745153456926
Training Epoch 103
train_metrics: 
R2: 0.9224884510040283
MSE: 25920.46484375
MAPE: 0.16613775188339513
test metrics:
R2: 0.9075456857681274
MSE: 33150.83203125
MAPE: 0.16366563460561034
MSE diff_p 103
----------
104: 0.0034662424586713314
Training Epoch 104
train_metrics: 
R2: 0.9326423406600952
MSE: 22701.46484375
MAPE: 0.13168590397175844
test metrics:
R2: 0.8817755579948425
MSE: 41283.33203125
MAPE: 0.20752325920143347
MSE diff_p 104
----------
105: 0.0035187958274036646
Training Epoch 105
train_metrics: 
R2: 0.9286836385726929
MSE: 23045.6484375
MAPE: 0.157748057619045
test metrics:
R2: 0.910973072052002
MSE: 32058.556640625
MAPE: 0.16146477907689183
MSE diff_p 105
----------
106: 0.00268168980255723
Training Epoch 106
train_metrics: 
R2: 0.9467630982398987
MSE: 17563.193359375
MAPE: 0.11516133579649875
test metrics:
R2: 0.883527398109436
MSE: 40831.21484375
MAPE: 0.20794590335053467
MSE diff_p 106
----------
107: 0.002829949837177992
Training Epoch 107
train_metrics: 
R2: 0.9446774125099182
MSE: 18534.193359375
MAPE: 0.1293692186535988
test metrics:
R2: 0.9126505255699158
MSE: 31763.232421875
MAPE: 0.16029935152299654
MSE diff_p 107
----------
108: 0.002747827675193548
Training Epoch 108
train_metrics: 
R2: 0.9454101324081421
MSE: 17996.3515625
MAPE: 0.13004583127551586
test metrics:
R2: 0.8977994322776794
MSE: 36470.0859375
MAPE: 0.18931929537334047
MSE diff_p 108
----------
109: 0.0024780856911092997
Training Epoch 109
train_metrics: 
R2: 0.9457310438156128
MSE: 16229.73046875
MAPE: 0.12025030348439178
test metrics:
R2: 0.9133023619651794
MSE: 31538.900390625
MAPE: 0.15764188662460868
MSE diff_p 109
----------
110: 0.002674906514585018
Training Epoch 110
train_metrics: 
R2: 0.9488089084625244
MSE: 17518.76953125
MAPE: 0.11176081410301372
test metrics:
R2: 0.8943783640861511
MSE: 37711.5859375
MAPE: 0.19512793020458513
MSE diff_p 110
----------
111: 0.0036318842321634293
Training Epoch 111
train_metrics: 
R2: 0.9299119114875793
MSE: 23786.30078125
MAPE: 0.14228849306164762
test metrics:
R2: 0.9177817106246948
MSE: 30342.169921875
MAPE: 0.15631748456626648
MSE diff_p 111
----------
112: 0.002901523606851697
Training Epoch 112
train_metrics: 
R2: 0.9346127510070801
MSE: 19002.951171875
MAPE: 0.14124921469025734
test metrics:
R2: 0.9026206135749817
MSE: 35226.8515625
MAPE: 0.18903270423269622
MSE diff_p 112
----------
113: 0.0031567825935781
Training Epoch 113
train_metrics: 
R2: 0.9294320344924927
MSE: 20674.71875
MAPE: 0.14481491394099213
test metrics:
R2: 0.9174501299858093
MSE: 30559.546875
MAPE: 0.15565771058511246
MSE diff_p 113
----------
114: 0.003035116009414196
Training Epoch 114
train_metrics: 
R2: 0.9359394311904907
MSE: 19877.890625
MAPE: 0.11998886767973015
test metrics:
R2: 0.8879857063293457
MSE: 39658.96484375
MAPE: 0.20375621408697872
MSE diff_p 114
----------
115: 0.0026203787419945
Training Epoch 115
train_metrics: 
R2: 0.9454894065856934
MSE: 17161.6484375
MAPE: 0.13121232532972368
test metrics:
R2: 0.9153249263763428
MSE: 30831.0625
MAPE: 0.1587664849347798
MSE diff_p 115
----------
116: 0.003274451242759824
Training Epoch 116
train_metrics: 
R2: 0.9354392290115356
MSE: 21445.3671875
MAPE: 0.12852731078833668
test metrics:
R2: 0.9012579917907715
MSE: 35451.71484375
MAPE: 0.18929221235149793
MSE diff_p 116
----------
117: 0.0026190236676484346
Training Epoch 117
train_metrics: 
R2: 0.9480732083320618
MSE: 17152.77734375
MAPE: 0.13121643505103886
test metrics:
R2: 0.920443058013916
MSE: 29543.76953125
MAPE: 0.15600167763094763
MSE diff_p 117
----------
118: 0.0019447330851107836
Training Epoch 118
train_metrics: 
R2: 0.9596424698829651
MSE: 12736.642578125
MAPE: 0.10072025691932529
test metrics:
R2: 0.9096266031265259
MSE: 33278.42578125
MAPE: 0.1806978174569071
MSE diff_p 118
----------
119: 0.0026677928399294615
Training Epoch 119
train_metrics: 
R2: 0.9450570344924927
MSE: 17472.177734375
MAPE: 0.10586330860773288
test metrics:
R2: 0.9220367074012756
MSE: 29147.009765625
MAPE: 0.15504599685068987
MSE diff_p 119
----------
120: 0.003825601190328598
Training Epoch 120
train_metrics: 
R2: 0.9197313189506531
MSE: 25055.01171875
MAPE: 0.1419649287654288
test metrics:
R2: 0.9085219502449036
MSE: 33634.07421875
MAPE: 0.18339793258320738
MSE diff_p 120
----------
121: 0.002717066090553999
Training Epoch 121
train_metrics: 
R2: 0.9436972737312317
MSE: 17794.8828125
MAPE: 0.12617692030489455
test metrics:
R2: 0.9249248504638672
MSE: 28306.845703125
MAPE: 0.15327518509981605
MSE diff_p 121
----------
122: 0.0018819214310497046
Training Epoch 122
train_metrics: 
R2: 0.9654410481452942
MSE: 12325.265625
MAPE: 0.11575726940551583
test metrics:
R2: 0.9160250425338745
MSE: 31307.0234375
MAPE: 0.1719431424837591
MSE diff_p 122
----------
123: 0.00224300823174417
Training Epoch 123
train_metrics: 
R2: 0.9552395343780518
MSE: 14690.13671875
MAPE: 0.10331059856443527
test metrics:
R2: 0.9236987829208374
MSE: 28800.203125
MAPE: 0.15393252162010895
MSE diff_p 123
----------
124: 0.0023621120490133762
Training Epoch 124
train_metrics: 
R2: 0.9510657787322998
MSE: 15470.181640625
MAPE: 0.12736091487865575
test metrics:
R2: 0.9175610542297363
MSE: 31046.287109375
MAPE: 0.17166723373414713
MSE diff_p 124
----------
125: 0.0032881249208003283
Training Epoch 125
train_metrics: 
R2: 0.9375587701797485
MSE: 21534.91796875
MAPE: 0.13735524394388443
test metrics:
R2: 0.9263915419578552
MSE: 27982.9765625
MAPE: 0.14951964481272847
MSE diff_p 125
----------
126: 0.002982695586979389
Training Epoch 126
train_metrics: 
R2: 0.9407234191894531
MSE: 19534.5703125
MAPE: 0.1420570251197065
test metrics:
R2: 0.9039983153343201
MSE: 35221.5546875
MAPE: 0.19493915848700286
MSE diff_p 126
----------
127: 0.0031004080083221197
Training Epoch 127
train_metrics: 
R2: 0.9308071136474609
MSE: 20305.50390625
MAPE: 0.1521016596535253
test metrics:
R2: 0.9224633574485779
MSE: 29111.646484375
MAPE: 0.15676269732360268
MSE diff_p 127
----------
128: 0.0030029744375497103
Training Epoch 128
train_metrics: 
R2: 0.9339637756347656
MSE: 19667.3828125
MAPE: 0.1266300829180078
test metrics:
R2: 0.8969720602035522
MSE: 37392.56640625
MAPE: 0.20019385812595827
MSE diff_p 128
----------
129: 0.002638153964653611
Training Epoch 129
train_metrics: 
R2: 0.9476085305213928
MSE: 17278.0625
MAPE: 0.12259708258481522
test metrics:
R2: 0.9255769848823547
MSE: 28015.197265625
MAPE: 0.15146320377300784
MSE diff_p 129
----------
130: 0.002468246268108487
Training Epoch 130
train_metrics: 
R2: 0.9503089785575867
MSE: 16165.287109375
MAPE: 0.11685204245076126
test metrics:
R2: 0.9053404927253723
MSE: 34776.1015625
MAPE: 0.1918572333389642
MSE diff_p 130
----------
131: 0.002779463306069374
Training Epoch 131
train_metrics: 
R2: 0.9492033123970032
MSE: 18203.54296875
MAPE: 0.13688045416994638
test metrics:
R2: 0.9258687496185303
MSE: 27973.08984375
MAPE: 0.15190612090977773
MSE diff_p 131
----------
132: 0.002517550252377987
Training Epoch 132
train_metrics: 
R2: 0.9544292092323303
MSE: 16488.193359375
MAPE: 0.11217208642972146
test metrics:
R2: 0.9257662892341614
MSE: 28232.92578125
MAPE: 0.15596829930351488
MSE diff_p 132
----------
133: 0.002001047134399414
Training Epoch 133
train_metrics: 
R2: 0.9582141637802124
MSE: 13105.458984375
MAPE: 0.10443935537531801
test metrics:
R2: 0.9264888763427734
MSE: 27937.884765625
MAPE: 0.1561155561626209
MSE diff_p 133
----------
134: 0.0021752093452960253
Training Epoch 134
train_metrics: 
R2: 0.9549024105072021
MSE: 14246.099609375
MAPE: 0.11101895885699584
test metrics:
R2: 0.9280179738998413
MSE: 27479.88671875
MAPE: 0.15324268306408736
MSE diff_p 134
----------
135: 0.0025200210511684418
Training Epoch 135
train_metrics: 
R2: 0.9471679329872131
MSE: 16504.375
MAPE: 0.1163289625490675
test metrics:
R2: 0.9227485656738281
MSE: 29423.849609375
MAPE: 0.16396896025455254
MSE diff_p 135
----------
136: 0.002303513465449214
Training Epoch 136
train_metrics: 
R2: 0.952303409576416
MSE: 15086.4013671875
MAPE: 0.1283492030814274
test metrics:
R2: 0.9309335947036743
MSE: 26441.470703125
MAPE: 0.1465315320591515
MSE diff_p 136
----------
137: 0.0023189052008092403
Training Epoch 137
train_metrics: 
R2: 0.9520081281661987
MSE: 15187.2080078125
MAPE: 0.11138595916048674
test metrics:
R2: 0.9129100441932678
MSE: 32722.552734375
MAPE: 0.18576955426457617
MSE diff_p 137
----------
138: 0.0022357117850333452
Training Epoch 138
train_metrics: 
R2: 0.9510295391082764
MSE: 14642.3486328125
MAPE: 0.13311601593628186
test metrics:
R2: 0.9301656484603882
MSE: 26774.22265625
MAPE: 0.1490599518993937
MSE diff_p 138
----------
139: 0.0027835117653012276
Training Epoch 139
train_metrics: 
R2: 0.942219078540802
MSE: 18230.056640625
MAPE: 0.12327088353436974
test metrics:
R2: 0.9091753959655762
MSE: 34069.015625
MAPE: 0.187248619267108
MSE diff_p 139
----------
140: 0.0033087474294006824
Training Epoch 140
train_metrics: 
R2: 0.9324206113815308
MSE: 21669.98046875
MAPE: 0.1502805195400452
test metrics:
R2: 0.9280581474304199
MSE: 27435.76953125
MAPE: 0.15177665795563272
MSE diff_p 140
----------
141: 0.003522268496453762
Training Epoch 141
train_metrics: 
R2: 0.9262887835502625
MSE: 23068.3984375
MAPE: 0.128893450805585
test metrics:
R2: 0.9046030044555664
MSE: 35398.3203125
MAPE: 0.19352411366076608
MSE diff_p 141
----------
142: 0.0021000076085329056
Training Epoch 142
train_metrics: 
R2: 0.9589956402778625
MSE: 13753.580078125
MAPE: 0.12424453239763496
test metrics:
R2: 0.9309169054031372
MSE: 26585.802734375
MAPE: 0.14953007442598445
MSE diff_p 142
----------
143: 0.0025928078684955835
Training Epoch 143
train_metrics: 
R2: 0.9481387138366699
MSE: 16981.07421875
MAPE: 0.12091444330949527
test metrics:
R2: 0.9224502444267273
MSE: 29804.810546875
MAPE: 0.1667243305770132
MSE diff_p 143
----------
144: 0.0019819503650069237
Training Epoch 144
train_metrics: 
R2: 0.9600481390953064
MSE: 12980.388671875
MAPE: 0.10749045912161984
test metrics:
R2: 0.9339401721954346
MSE: 25803.34375
MAPE: 0.14552568987990425
MSE diff_p 144
----------
145: 0.0028991028666496277
Training Epoch 145
train_metrics: 
R2: 0.9361109733581543
MSE: 18987.09765625
MAPE: 0.12995306810094578
test metrics:
R2: 0.9296935200691223
MSE: 27464.80078125
MAPE: 0.15554069609197352
MSE diff_p 145
----------
146: 0.002586444839835167
Training Epoch 146
train_metrics: 
R2: 0.951823353767395
MSE: 16939.404296875
MAPE: 0.12235670485241149
test metrics:
R2: 0.9367003440856934
MSE: 25063.2421875
MAPE: 0.14136794086785004
MSE diff_p 146
----------
147: 0.002107927342876792
Training Epoch 147
train_metrics: 
R2: 0.9589592218399048
MSE: 13805.451171875
MAPE: 0.10682609881885416
test metrics:
R2: 0.9316760897636414
MSE: 26557.978515625
MAPE: 0.1520855809066574
MSE diff_p 147
----------
148: 0.0019266268936917186
Training Epoch 148
train_metrics: 
R2: 0.9627580642700195
MSE: 12618.0595703125
MAPE: 0.10190516369367021
test metrics:
R2: 0.9362921714782715
MSE: 25030.33203125
MAPE: 0.14531687082113903
MSE diff_p 148
----------
149: 0.0021958102006465197
Training Epoch 149
train_metrics: 
R2: 0.9606590270996094
MSE: 14381.0205078125
MAPE: 0.12620960043399435
test metrics:
R2: 0.932327389717102
MSE: 26471.904296875
MAPE: 0.1536774402097102
MSE diff_p 149
----------
150: 0.0017510352190583944
Training Epoch 150
train_metrics: 
R2: 0.965329647064209
MSE: 11468.0546875
MAPE: 0.0996826943646447
test metrics:
R2: 0.9380130767822266
MSE: 24636.130859375
MAPE: 0.14119698268030922
MSE diff_p 150
----------
151: 0.001795504940673709
Training Epoch 151
train_metrics: 
R2: 0.9634264707565308
MSE: 11759.302734375
MAPE: 0.09445994459404983
test metrics:
R2: 0.9302645921707153
MSE: 27396.16015625
MAPE: 0.15785853908851388
MSE diff_p 151
----------
152: 0.002526497468352318
Training Epoch 152
train_metrics: 
R2: 0.9500359892845154
MSE: 16546.794921875
MAPE: 0.12074309431596054
test metrics:
R2: 0.9363082051277161
MSE: 25083.349609375
MAPE: 0.14444062748723974
MSE diff_p 152
----------
153: 0.0024275577161461115
Training Epoch 153
train_metrics: 
R2: 0.9526773691177368
MSE: 15898.8046875
MAPE: 0.11078850260697753
test metrics:
R2: 0.9235770106315613
MSE: 29645.095703125
MAPE: 0.17144120461075957
MSE diff_p 153
----------
154: 0.0025941203348338604
Training Epoch 154
train_metrics: 
R2: 0.9482473134994507
MSE: 16989.671875
MAPE: 0.11735665905733335
test metrics:
R2: 0.9360582828521729
MSE: 24984.779296875
MAPE: 0.14442356331911782
MSE diff_p 154
----------
155: 0.002214027103036642
Training Epoch 155
train_metrics: 
R2: 0.9596236348152161
MSE: 14500.328125
MAPE: 0.1103433018190568
test metrics:
R2: 0.9223810434341431
MSE: 29857.919921875
MAPE: 0.177158567879497
MSE diff_p 155
----------
156: 0.0023431386798620224
Training Epoch 156
train_metrics: 
R2: 0.9535765647888184
MSE: 15345.919921875
MAPE: 0.11678017234667842
test metrics:
R2: 0.9349576234817505
MSE: 25269.91015625
MAPE: 0.14629444988671356
MSE diff_p 156
----------
157: 0.002320883795619011
Training Epoch 157
train_metrics: 
R2: 0.9587846398353577
MSE: 15200.1650390625
MAPE: 0.12136056517561264
test metrics:
R2: 0.9275286793708801
MSE: 28077.1796875
MAPE: 0.16294259349394594
MSE diff_p 157
----------
158: 0.0020119831897318363
Training Epoch 158
train_metrics: 
R2: 0.962430477142334
MSE: 13177.0830078125
MAPE: 0.11757630596878209
test metrics:
R2: 0.935903012752533
MSE: 25223.744140625
MAPE: 0.1443950488798363
MSE diff_p 158
----------
159: 0.0022244558203965425
Training Epoch 159
train_metrics: 
R2: 0.9579275846481323
MSE: 14568.6328125
MAPE: 0.11160312584186408
test metrics:
R2: 0.9348832964897156
MSE: 25617.4296875
MAPE: 0.14793714225051882
MSE diff_p 159
----------
160: 0.0022327331826090813
Training Epoch 160
train_metrics: 
R2: 0.9600453972816467
MSE: 14622.8408203125
MAPE: 0.1061894371336332
test metrics:
R2: 0.9331374764442444
MSE: 26324.494140625
MAPE: 0.15513813241187302
MSE diff_p 160
----------
161: 0.0026970559265464544
Training Epoch 161
train_metrics: 
R2: 0.9520938992500305
MSE: 17663.828125
MAPE: 0.12109218338752992
test metrics:
R2: 0.9384035468101501
MSE: 24309.55078125
MAPE: 0.1445288948021852
MSE diff_p 161
----------
162: 0.003037414513528347
Training Epoch 162
train_metrics: 
R2: 0.940828800201416
MSE: 19892.943359375
MAPE: 0.13636517995144387
test metrics:
R2: 0.9204217791557312
MSE: 30717.8203125
MAPE: 0.18267690985380894
MSE diff_p 162
----------
163: 0.0028929992113262415
Training Epoch 163
train_metrics: 
R2: 0.9400753974914551
MSE: 18947.12109375
MAPE: 0.1503243774339088
test metrics:
R2: 0.9333525896072388
MSE: 25734.037109375
MAPE: 0.1508508440268825
MSE diff_p 163
----------
164: 0.002539923647418618
Training Epoch 164
train_metrics: 
R2: 0.9436735510826111
MSE: 16634.7265625
MAPE: 0.1363429883494367
test metrics:
R2: 0.9076458811759949
MSE: 34551.3125
MAPE: 0.19726520143243279
MSE diff_p 164
----------
165: 0.003769597504287958
Training Epoch 165
train_metrics: 
R2: 0.9246090650558472
MSE: 24688.224609375
MAPE: 0.1750648686277956
test metrics:
R2: 0.9296019077301025
MSE: 27103.75
MAPE: 0.15491547238454179
MSE diff_p 165
----------
166: 0.004494705703109503
Training Epoch 166
train_metrics: 
R2: 0.9206175804138184
MSE: 29437.17578125
MAPE: 0.16219530173644733
test metrics:
R2: 0.8885815739631653
MSE: 40668.796875
MAPE: 0.21623019343970498
MSE diff_p 166
----------
167: 0.003238359000533819
Training Epoch 167
train_metrics: 
R2: 0.93885338306427
MSE: 21208.984375
MAPE: 0.15330982902275553
test metrics:
R2: 0.9330589175224304
MSE: 25953.125
MAPE: 0.1531569934253495
MSE diff_p 167
----------
168: 0.003401641733944416
Training Epoch 168
train_metrics: 
R2: 0.9308138489723206
MSE: 22278.376953125
MAPE: 0.13569123203240624
test metrics:
R2: 0.9105915427207947
MSE: 34167.89453125
MAPE: 0.19566269257859023
MSE diff_p 168
----------
169: 0.0026675511617213488
Training Epoch 169
train_metrics: 
R2: 0.951686441898346
MSE: 17470.59375
MAPE: 0.14674005306149007
test metrics:
R2: 0.9340397119522095
MSE: 25645.783203125
MAPE: 0.14880049838158665
MSE diff_p 169
----------
170: 0.0027749782893806696
Training Epoch 170
train_metrics: 
R2: 0.9493899941444397
MSE: 18174.166015625
MAPE: 0.12777860776166913
test metrics:
R2: 0.9140175580978394
MSE: 32428.849609375
MAPE: 0.18625741235936769
MSE diff_p 170
----------
171: 0.0026495535857975483
Training Epoch 171
train_metrics: 
R2: 0.9513262510299683
MSE: 17352.72265625
MAPE: 0.12729977807270618
test metrics:
R2: 0.9399146437644958
MSE: 23896.666015625
MAPE: 0.14553244238876975
MSE diff_p 171
----------
172: 0.0021741800010204315
Training Epoch 172
train_metrics: 
R2: 0.9543167352676392
MSE: 14239.3583984375
MAPE: 0.10476421378476775
test metrics:
R2: 0.9289989471435547
MSE: 27842.619140625
MAPE: 0.16874769048365248
MSE diff_p 172
----------
173: 0.001956589287146926
Training Epoch 173
train_metrics: 
R2: 0.9630851745605469
MSE: 12814.29296875
MAPE: 0.11206836357214923
test metrics:
R2: 0.939822256565094
MSE: 23908.642578125
MAPE: 0.1447045522806922
MSE diff_p 173
----------
174: 0.002163990866392851
Training Epoch 174
train_metrics: 
R2: 0.9563990235328674
MSE: 14172.626953125
MAPE: 0.10246298102445495
test metrics:
R2: 0.9355971813201904
MSE: 25269.5546875
MAPE: 0.15230730150964092
MSE diff_p 174
----------
175: 0.0022888868115842342
Training Epoch 175
train_metrics: 
R2: 0.9540232419967651
MSE: 14990.6064453125
MAPE: 0.09276224721498837
test metrics:
R2: 0.9366478323936462
MSE: 25048.248046875
MAPE: 0.14952739579242902
MSE diff_p 175
----------
176: 0.002214294858276844
Training Epoch 176
train_metrics: 
R2: 0.9555023312568665
MSE: 14502.08203125
MAPE: 0.10832931418679786
test metrics:
R2: 0.9372574090957642
MSE: 24639.552734375
MAPE: 0.14960253618251773
MSE diff_p 176
----------
177: 0.0024619861505925655
Training Epoch 177
train_metrics: 
R2: 0.9539861083030701
MSE: 16124.2890625
MAPE: 0.11940051070334108
test metrics:
R2: 0.9378405809402466
MSE: 24541.599609375
MAPE: 0.14829938235620166
MSE diff_p 177
----------
178: 0.0024630194529891014
Training Epoch 178
train_metrics: 
R2: 0.9533777832984924
MSE: 16131.0546875
MAPE: 0.11014232785778189
test metrics:
R2: 0.937642514705658
MSE: 24666.626953125
MAPE: 0.1516301009377871
MSE diff_p 178
----------
179: 0.0018552442779764533
Training Epoch 179
train_metrics: 
R2: 0.9629960060119629
MSE: 12150.5517578125
MAPE: 0.1046092489325975
test metrics:
R2: 0.9409885406494141
MSE: 23555.830078125
MAPE: 0.14552107662762062
MSE diff_p 179
----------
180: 0.002669930225238204
Training Epoch 180
train_metrics: 
R2: 0.9470515847206116
MSE: 17486.17578125
MAPE: 0.1161117593859473
test metrics:
R2: 0.9372952580451965
MSE: 24778.33984375
MAPE: 0.1522711909756938
MSE diff_p 180
----------
181: 0.00204007001593709
Training Epoch 181
train_metrics: 
R2: 0.9643326997756958
MSE: 13361.033203125
MAPE: 0.1185394004050706
test metrics:
R2: 0.9382991194725037
MSE: 24564.27734375
MAPE: 0.14919511857692044
MSE diff_p 181
----------
182: 0.0017020178493112326
Training Epoch 182
train_metrics: 
R2: 0.9673134684562683
MSE: 11147.025390625
MAPE: 0.09526803290281928
test metrics:
R2: 0.9376528263092041
MSE: 25034.177734375
MAPE: 0.15009191262246152
MSE diff_p 182
----------
183: 0.002091303002089262
Training Epoch 183
train_metrics: 
R2: 0.9575709104537964
MSE: 13696.572265625
MAPE: 0.09449420408285633
test metrics:
R2: 0.9404998421669006
MSE: 23631.74609375
MAPE: 0.14626655375980696
MSE diff_p 183
----------
184: 0.0023104713764041662
Training Epoch 184
train_metrics: 
R2: 0.9601360559463501
MSE: 15131.97265625
MAPE: 0.12078792048333255
test metrics:
R2: 0.9321221113204956
MSE: 26864.876953125
MAPE: 0.1651165446625783
MSE diff_p 184
----------
185: 0.0033979681320488453
Training Epoch 185
train_metrics: 
R2: 0.9391211271286011
MSE: 22254.314453125
MAPE: 0.14542839734759444
test metrics:
R2: 0.9421080946922302
MSE: 23200.9140625
MAPE: 0.14339270176308896
MSE diff_p 185
----------
186: 0.002822824753820896
Training Epoch 186
train_metrics: 
R2: 0.9478847980499268
MSE: 18487.52734375
MAPE: 0.12490612442992004
test metrics:
R2: 0.9195079207420349
MSE: 31423.310546875
MAPE: 0.1865301697248096
MSE diff_p 186
----------
187: 0.0031731287017464638
Training Epoch 187
train_metrics: 
R2: 0.9409632682800293
MSE: 20781.7734375
MAPE: 0.13671543429840483
test metrics:
R2: 0.9399024248123169
MSE: 23831.06640625
MAPE: 0.14635338741846193
MSE diff_p 187
----------
188: 0.0025676051154732704
Training Epoch 188
train_metrics: 
R2: 0.9514704346656799
MSE: 16816.015625
MAPE: 0.11772631205660747
test metrics:
R2: 0.922086238861084
MSE: 30527.740234375
MAPE: 0.18312416893244485
MSE diff_p 188
----------
189: 0.002948225475847721
Training Epoch 189
train_metrics: 
R2: 0.9444946050643921
MSE: 19308.81640625
MAPE: 0.1511850597229849
test metrics:
R2: 0.9389284253120422
MSE: 24139.736328125
MAPE: 0.1502312110764343
MSE diff_p 189
----------
190: 0.002086279448121786
Training Epoch 190
train_metrics: 
R2: 0.9592221975326538
MSE: 13663.6748046875
MAPE: 0.10325836909365466
test metrics:
R2: 0.9207028746604919
MSE: 30445.08984375
MAPE: 0.18325587268663257
MSE diff_p 190
----------
191: 0.0022435332648456097
Training Epoch 191
train_metrics: 
R2: 0.9585383534431458
MSE: 14693.576171875
MAPE: 0.1188431516318568
test metrics:
R2: 0.9422398209571838
MSE: 23137.955078125
MAPE: 0.14470287131748824
MSE diff_p 191
----------
192: 0.002697292948141694
Training Epoch 192
train_metrics: 
R2: 0.9481478333473206
MSE: 17665.3828125
MAPE: 0.12760384664919483
test metrics:
R2: 0.9276828765869141
MSE: 28526.353515625
MAPE: 0.17561586594540476
MSE diff_p 192
----------
193: 0.002660205587744713
Training Epoch 193
train_metrics: 
R2: 0.9492449760437012
MSE: 17422.486328125
MAPE: 0.1381686137375842
test metrics:
R2: 0.940555214881897
MSE: 23506.39453125
MAPE: 0.14367223910328383
MSE diff_p 193
----------
194: 0.002313267905265093
Training Epoch 194
train_metrics: 
R2: 0.9496827721595764
MSE: 15150.287109375
MAPE: 0.11967904761523943
test metrics:
R2: 0.9200648665428162
MSE: 30797.23046875
MAPE: 0.18642136124412517
MSE diff_p 194
----------
195: 0.0027465878520160913
Training Epoch 195
train_metrics: 
R2: 0.9468867778778076
MSE: 17988.228515625
MAPE: 0.13192927757004946
test metrics:
R2: 0.9418736100196838
MSE: 23157.42578125
MAPE: 0.14336240537020722
MSE diff_p 195
----------
196: 0.002546613337472081
Training Epoch 196
train_metrics: 
R2: 0.9516181945800781
MSE: 16678.537109375
MAPE: 0.12689213809386707
test metrics:
R2: 0.9204391837120056
MSE: 31143.49609375
MAPE: 0.18637510661836232
MSE diff_p 196
----------
197: 0.002546750707551837
Training Epoch 197
train_metrics: 
R2: 0.9559283256530762
MSE: 16679.4375
MAPE: 0.1387345526456539
test metrics:
R2: 0.9392341375350952
MSE: 23980.330078125
MAPE: 0.14598407397842983
MSE diff_p 197
----------
198: 0.002106662141159177
Training Epoch 198
train_metrics: 
R2: 0.9607524871826172
MSE: 13797.1611328125
MAPE: 0.09462910514386606
test metrics:
R2: 0.9300013780593872
MSE: 27751.349609375
MAPE: 0.16775323052603866
MSE diff_p 198
----------
199: 0.0022841731552034616
Training Epoch 199
train_metrics: 
R2: 0.9594464898109436
MSE: 14959.734375
MAPE: 0.11015079556197782
test metrics:
R2: 0.9419668912887573
MSE: 23125.109375
MAPE: 0.14504848483482868
MSE diff_p 199
----------
