os.getpid()=74388
args.num_latent=6
args.num_trash=4

 Training Encoder...

Encoder Loss: 0.164 Iteration: 1
Encoder Loss: 0.11 Iteration: 2
Encoder Loss: 0.076 Iteration: 3
Encoder Loss: 0.07 Iteration: 4
Encoder Loss: 0.059 Iteration: 5
Encoder Loss: 0.056 Iteration: 6
Encoder Loss: 0.055 Iteration: 7
Encoder Loss: 0.056 Iteration: 8
Encoder Loss: 0.054 Iteration: 9
Encoder Loss: 0.053 Iteration: 10
Encoder Loss: 0.051 Iteration: 11
Encoder Loss: 0.052 Iteration: 12
Encoder Loss: 0.058 Iteration: 13
Encoder Loss: 0.056 Iteration: 14
Encoder Loss: 0.054 Iteration: 15
Encoder Loss: 0.059 Iteration: 16
Encoder Loss: 0.054 Iteration: 17
Encoder Loss: 0.056 Iteration: 18
Encoder Loss: 0.057 Iteration: 19
Encoder Loss: 0.054 Iteration: 20
Encoder Loss: 0.049 Iteration: 21
Encoder Loss: 0.053 Iteration: 22
Encoder Loss: 0.056 Iteration: 23
Encoder Loss: 0.049 Iteration: 24
Encoder Loss: 0.057 Iteration: 25
Encoder Loss: 0.056 Iteration: 26
Encoder Loss: 0.055 Iteration: 27
Encoder Loss: 0.049 Iteration: 28
Encoder Loss: 0.058 Iteration: 29
Encoder Loss: 0.056 Iteration: 30
Encoder Loss: 0.049 Iteration: 31
Encoder Loss: 0.051 Iteration: 32
Encoder Loss: 0.053 Iteration: 33
Encoder Loss: 0.055 Iteration: 34
Encoder Loss: 0.057 Iteration: 35
Encoder Loss: 0.051 Iteration: 36
Encoder Loss: 0.056 Iteration: 37
Encoder Loss: 0.053 Iteration: 38
Encoder Loss: 0.058 Iteration: 39
Encoder Loss: 0.058 Iteration: 40
Encoder Loss: 0.052 Iteration: 41
Encoder Loss: 0.054 Iteration: 42
Encoder Loss: 0.051 Iteration: 43
Encoder Loss: 0.049 Iteration: 44
Encoder Loss: 0.057 Iteration: 45
Encoder Loss: 0.052 Iteration: 46
Encoder Loss: 0.054 Iteration: 47
Encoder Loss: 0.051 Iteration: 48
Encoder Loss: 0.05 Iteration: 49
Encoder Loss: 0.054 Iteration: 50
Encoder Loss: 0.056 Iteration: 51
Encoder Loss: 0.056 Iteration: 52
Encoder Loss: 0.053 Iteration: 53
Encoder Loss: 0.059 Iteration: 54
Encoder Loss: 0.059 Iteration: 55
Encoder Loss: 0.052 Iteration: 56
Encoder Loss: 0.056 Iteration: 57
Encoder Loss: 0.057 Iteration: 58
Encoder Loss: 0.053 Iteration: 59
Encoder Loss: 0.052 Iteration: 60
Encoder Loss: 0.056 Iteration: 61
Encoder Loss: 0.054 Iteration: 62
Encoder Loss: 0.057 Iteration: 63
Encoder Loss: 0.055 Iteration: 64
Encoder Loss: 0.059 Iteration: 65
Encoder Loss: 0.053 Iteration: 66
Encoder Loss: 0.059 Iteration: 67
Encoder Loss: 0.057 Iteration: 68
Encoder Loss: 0.054 Iteration: 69
Encoder Loss: 0.056 Iteration: 70
Encoder Loss: 0.053 Iteration: 71
Encoder Loss: 0.055 Iteration: 72
Encoder Loss: 0.061 Iteration: 73
Encoder Loss: 0.058 Iteration: 74
Encoder Loss: 0.058 Iteration: 75
Encoder Loss: 0.052 Iteration: 76
Encoder Loss: 0.054 Iteration: 77
Encoder Loss: 0.055 Iteration: 78
Encoder Loss: 0.057 Iteration: 79
Encoder Loss: 0.053 Iteration: 80
Encoder Loss: 0.059 Iteration: 81
Encoder Loss: 0.053 Iteration: 82
Encoder Loss: 0.053 Iteration: 83
Encoder Loss: 0.058 Iteration: 84
Encoder Loss: 0.052 Iteration: 85
Encoder Loss: 0.054 Iteration: 86
Encoder Loss: 0.058 Iteration: 87
Encoder Loss: 0.061 Iteration: 88
Encoder Loss: 0.052 Iteration: 89
Encoder Loss: 0.055 Iteration: 90
Encoder Loss: 0.053 Iteration: 91
Encoder Loss: 0.052 Iteration: 92
Encoder Loss: 0.056 Iteration: 93
Encoder Loss: 0.054 Iteration: 94
Encoder Loss: 0.055 Iteration: 95
Encoder Loss: 0.055 Iteration: 96
Encoder Loss: 0.058 Iteration: 97
Encoder Loss: 0.06 Iteration: 98
Encoder Loss: 0.052 Iteration: 99
Encoder Loss: 0.052 Iteration: 100
Training Started... 
0: 0.1609550267457962
Training Epoch 0
train_metrics: 
R2: -13.285990715026855
MSE: 1054142.875
MAPE: 0.5183270326713122
test metrics:
R2: -15.639106750488281
MSE: 1163337.375
MAPE: 0.6057053165508404
before val features
MSE diff_p 0
----------
1: 0.06039359048008919
Training Epoch 1
train_metrics: 
R2: -1054.573974609375
MSE: 395535.8125
MAPE: 0.43572381403125576
test metrics:
R2: -667.5776977539062
MSE: 586043.75
MAPE: 0.5681060508795902
MSE diff_p 1
----------
2: 0.053790003061294556
Training Epoch 2
train_metrics: 
R2: -103.13198852539062
MSE: 352286.875
MAPE: 0.39293739016847506
test metrics:
R2: -169.45315551757812
MSE: 492791.375
MAPE: 0.5127748044967466
MSE diff_p 2
----------
3: 0.04909209534525871
Training Epoch 3
train_metrics: 
R2: -41.612545013427734
MSE: 321518.90625
MAPE: 0.3988888202549831
test metrics:
R2: -53.30231857299805
MSE: 430459.90625
MAPE: 0.49472802477918104
MSE diff_p 3
----------
4: 0.03418537601828575
Training Epoch 4
train_metrics: 
R2: -6.5536346435546875
MSE: 223890.296875
MAPE: 0.34965308631006564
test metrics:
R2: -7.562084197998047
MSE: 301581.5625
MAPE: 0.4461327985982509
MSE diff_p 4
----------
5: 0.03247887268662453
Training Epoch 5
train_metrics: 
R2: -3.476093292236328
MSE: 212713.9375
MAPE: 0.3420878717680498
test metrics:
R2: -3.728461742401123
MSE: 249978.984375
MAPE: 0.41473522916535843
MSE diff_p 5
----------
6: 0.023965854197740555
Training Epoch 6
train_metrics: 
R2: -2.326321601867676
MSE: 156959.578125
MAPE: 0.2878583144518964
test metrics:
R2: -3.504520893096924
MSE: 254042.71875
MAPE: 0.4204693122053293
MSE diff_p 6
----------
7: 0.023776579648256302
Training Epoch 7
train_metrics: 
R2: -0.7359287738800049
MSE: 155719.96875
MAPE: 0.3133042157468229
test metrics:
R2: -0.8088458776473999
MSE: 178628.046875
MAPE: 0.35658468833358103
MSE diff_p 7
----------
8: 0.018330873921513557
Training Epoch 8
train_metrics: 
R2: -0.42363035678863525
MSE: 120054.40625
MAPE: 0.26251982637157567
test metrics:
R2: -0.8849525451660156
MSE: 188990.03125
MAPE: 0.3747887332898428
MSE diff_p 8
----------
9: 0.019859621301293373
Training Epoch 9
train_metrics: 
R2: -0.3398371934890747
MSE: 130066.625
MAPE: 0.3233231792771382
test metrics:
R2: -0.486926794052124
MSE: 170698.546875
MAPE: 0.3484892858399018
MSE diff_p 9
----------
10: 0.02312428504228592
Training Epoch 10
train_metrics: 
R2: -0.4315265417098999
MSE: 151447.90625
MAPE: 0.29260399876700127
test metrics:
R2: -0.6582950353622437
MSE: 182606.8125
MAPE: 0.3692763398514449
MSE diff_p 10
----------
11: 0.015045157633721828
Training Epoch 11
train_metrics: 
R2: 0.1698351502418518
MSE: 98535.265625
MAPE: 0.24895280251093893
test metrics:
R2: 0.08845388889312744
MSE: 131768.875
MAPE: 0.30517017787323897
MSE diff_p 11
----------
12: 0.012516726739704609
Training Epoch 12
train_metrics: 
R2: 0.35189080238342285
MSE: 81975.8046875
MAPE: 0.24494487182376798
test metrics:
R2: 0.009913980960845947
MSE: 141975.421875
MAPE: 0.3365687558796507
MSE diff_p 12
----------
13: 0.01667298935353756
Training Epoch 13
train_metrics: 
R2: 0.2878464460372925
MSE: 109196.4140625
MAPE: 0.24846708106768062
test metrics:
R2: 0.3224647641181946
MSE: 116479.1484375
MAPE: 0.2782540298871776
MSE diff_p 13
----------
14: 0.012316416949033737
Training Epoch 14
train_metrics: 
R2: 0.34955310821533203
MSE: 80663.9296875
MAPE: 0.21747124261264153
test metrics:
R2: 0.1336999535560608
MSE: 133801.25
MAPE: 0.3288271478335316
MSE diff_p 14
----------
15: 0.012927399948239326
Training Epoch 15
train_metrics: 
R2: 0.5192434787750244
MSE: 84665.4375
MAPE: 0.21757180351058428
test metrics:
R2: 0.46673583984375
MSE: 100096.796875
MAPE: 0.26523005973588804
MSE diff_p 15
----------
16: 0.010448011569678783
Training Epoch 16
train_metrics: 
R2: 0.5783138275146484
MSE: 68427.1640625
MAPE: 0.22029639829211853
test metrics:
R2: 0.3787474036216736
MSE: 112113.3046875
MAPE: 0.30634594863507436
MSE diff_p 16
----------
17: 0.012161851860582829
Training Epoch 17
train_metrics: 
R2: 0.577006459236145
MSE: 79651.6171875
MAPE: 0.21932571035010479
test metrics:
R2: 0.5532265901565552
MSE: 92602.1015625
MAPE: 0.24959276901689548
MSE diff_p 17
----------
18: 0.010922584682703018
Training Epoch 18
train_metrics: 
R2: 0.5659931898117065
MSE: 71535.296875
MAPE: 0.2122214901095029
test metrics:
R2: 0.4212825894355774
MSE: 110991.046875
MAPE: 0.30809958581869734
MSE diff_p 18
----------
19: 0.01023279782384634
Training Epoch 19
train_metrics: 
R2: 0.6404261589050293
MSE: 67017.671875
MAPE: 0.20414170316077163
test metrics:
R2: 0.5966976881027222
MSE: 86835.0390625
MAPE: 0.2461780305601972
MSE diff_p 19
----------
20: 0.010949713177978992
Training Epoch 20
train_metrics: 
R2: 0.6382496356964111
MSE: 71712.9609375
MAPE: 0.23955721699563653
test metrics:
R2: 0.49876582622528076
MSE: 102618.90625
MAPE: 0.2993102941726303
MSE diff_p 20
----------
21: 0.009761558845639229
Training Epoch 21
train_metrics: 
R2: 0.7012641429901123
MSE: 63931.38671875
MAPE: 0.23026127146446487
test metrics:
R2: 0.6707658767700195
MSE: 77623.3125
MAPE: 0.2301801890647769
MSE diff_p 21
----------
22: 0.008503446355462074
Training Epoch 22
train_metrics: 
R2: 0.7284736037254333
MSE: 55691.625
MAPE: 0.2026826356389603
test metrics:
R2: 0.6183222532272339
MSE: 86440.6796875
MAPE: 0.27779871146738755
MSE diff_p 22
----------
23: 0.009516333229839802
Training Epoch 23
train_metrics: 
R2: 0.7354139685630798
MSE: 62325.328125
MAPE: 0.20967978154717595
test metrics:
R2: 0.7218600511550903
MSE: 70103.421875
MAPE: 0.22066181409929256
MSE diff_p 23
----------
24: 0.008859731256961823
Training Epoch 24
train_metrics: 
R2: 0.7394615411758423
MSE: 58025.046875
MAPE: 0.2230264151400983
test metrics:
R2: 0.6385893821716309
MSE: 85037.890625
MAPE: 0.2801267129990078
MSE diff_p 24
----------
25: 0.008316297084093094
Training Epoch 25
train_metrics: 
R2: 0.7569423913955688
MSE: 54465.9296875
MAPE: 0.21814288040572105
test metrics:
R2: 0.7452889680862427
MSE: 67034.3515625
MAPE: 0.21807747947449457
MSE diff_p 25
----------
26: 0.008848484605550766
Training Epoch 26
train_metrics: 
R2: 0.748239278793335
MSE: 57951.3828125
MAPE: 0.18776897140267645
test metrics:
R2: 0.691906213760376
MSE: 77174.4375
MAPE: 0.26906155435278506
MSE diff_p 26
----------
27: 0.00898217037320137
Training Epoch 27
train_metrics: 
R2: 0.7674961090087891
MSE: 58826.93359375
MAPE: 0.1863951527668679
test metrics:
R2: 0.7744277119636536
MSE: 60479.98046875
MAPE: 0.21115388902839693
MSE diff_p 27
----------
28: 0.007610126864165068
Training Epoch 28
train_metrics: 
R2: 0.7863389253616333
MSE: 49841.01171875
MAPE: 0.20174087492862836
test metrics:
R2: 0.7441359758377075
MSE: 67377.75
MAPE: 0.251744934355744
MSE diff_p 28
----------
29: 0.006903339177370071
Training Epoch 29
train_metrics: 
R2: 0.8234752416610718
MSE: 45212.04296875
MAPE: 0.16216461664052134
test metrics:
R2: 0.8081616759300232
MSE: 55084.1484375
MAPE: 0.20188934426474528
MSE diff_p 29
----------
30: 0.007180951535701752
Training Epoch 30
train_metrics: 
R2: 0.8062731027603149
MSE: 47030.21875
MAPE: 0.19061848535561585
test metrics:
R2: 0.7435996532440186
MSE: 69363.359375
MAPE: 0.2593847678482278
MSE diff_p 30
----------
31: 0.007299484685063362
Training Epoch 31
train_metrics: 
R2: 0.7949389219284058
MSE: 47806.5234375
MAPE: 0.20101546854710728
test metrics:
R2: 0.8150007724761963
MSE: 53946.98828125
MAPE: 0.20398740157130726
MSE diff_p 31
----------
32: 0.006675290875136852
Training Epoch 32
train_metrics: 
R2: 0.8206993341445923
MSE: 43718.48828125
MAPE: 0.19323009676324282
test metrics:
R2: 0.7383207678794861
MSE: 71711.546875
MAPE: 0.2660096843677712
MSE diff_p 32
----------
33: 0.0064336140640079975
Training Epoch 33
train_metrics: 
R2: 0.8289974927902222
MSE: 42135.671875
MAPE: 0.18845562128247412
test metrics:
R2: 0.8218221664428711
MSE: 52561.6796875
MAPE: 0.2030117563217223
MSE diff_p 33
----------
34: 0.0066530220210552216
Training Epoch 34
train_metrics: 
R2: 0.8365519642829895
MSE: 43572.64453125
MAPE: 0.18459774759951553
test metrics:
R2: 0.7856003046035767
MSE: 61812.8203125
MAPE: 0.2450831861224514
MSE diff_p 34
----------
35: 0.0054004136472940445
Training Epoch 35
train_metrics: 
R2: 0.872574508190155
MSE: 35368.9296875
MAPE: 0.1697194707005201
test metrics:
R2: 0.8457005023956299
MSE: 47437.3671875
MAPE: 0.1922744813184539
MSE diff_p 35
----------
36: 0.005315179005265236
Training Epoch 36
train_metrics: 
R2: 0.8652608394622803
MSE: 34810.703125
MAPE: 0.1616195512989973
test metrics:
R2: 0.8175251483917236
MSE: 55058.765625
MAPE: 0.22907357269942552
MSE diff_p 36
----------
37: 0.005130943842232227
Training Epoch 37
train_metrics: 
R2: 0.8778483271598816
MSE: 33604.09375
MAPE: 0.1615670024760103
test metrics:
R2: 0.8599364161491394
MSE: 44464.57421875
MAPE: 0.18699392110744364
MSE diff_p 37
----------
38: 0.005887917708605528
Training Epoch 38
train_metrics: 
R2: 0.8602410554885864
MSE: 38561.7421875
MAPE: 0.1681552060337167
test metrics:
R2: 0.8156964778900146
MSE: 56030.33203125
MAPE: 0.23563108413795997
MSE diff_p 38
----------
39: 0.004834810271859169
Training Epoch 39
train_metrics: 
R2: 0.886685848236084
MSE: 31664.62890625
MAPE: 0.1546531172547841
test metrics:
R2: 0.8657175302505493
MSE: 43303.29296875
MAPE: 0.18684403266448368
MSE diff_p 39
----------
40: 0.005340048111975193
Training Epoch 40
train_metrics: 
R2: 0.8777520656585693
MSE: 34973.578125
MAPE: 0.16983815784856904
test metrics:
R2: 0.8151553869247437
MSE: 57116.546875
MAPE: 0.2399698366887779
MSE diff_p 40
----------
41: 0.0045487526804208755
Training Epoch 41
train_metrics: 
R2: 0.9000397324562073
MSE: 29791.150390625
MAPE: 0.1616078255719971
test metrics:
R2: 0.8734986782073975
MSE: 41578.99609375
MAPE: 0.18390109054796167
MSE diff_p 41
----------
42: 0.005032058339565992
Training Epoch 42
train_metrics: 
R2: 0.8693228363990784
MSE: 32956.46875
MAPE: 0.15876190866710882
test metrics:
R2: 0.8317331671714783
MSE: 53410.71875
MAPE: 0.2309267458505225
MSE diff_p 42
----------
43: 0.004679740406572819
Training Epoch 43
train_metrics: 
R2: 0.8902285099029541
MSE: 30649.02734375
MAPE: 0.17126680642631156
test metrics:
R2: 0.87698894739151
MSE: 41052.9375
MAPE: 0.18612589863698514
MSE diff_p 43
----------
44: 0.004286354407668114
Training Epoch 44
train_metrics: 
R2: 0.8961014151573181
MSE: 28072.62109375
MAPE: 0.15228661978460575
test metrics:
R2: 0.8473997116088867
MSE: 49619.16796875
MAPE: 0.22105669205710687
MSE diff_p 44
----------
45: 0.004474538378417492
Training Epoch 45
train_metrics: 
R2: 0.8992550373077393
MSE: 29305.09375
MAPE: 0.17487517048843645
test metrics:
R2: 0.8857050538063049
MSE: 38993.42578125
MAPE: 0.18082758031992155
MSE diff_p 45
----------
46: 0.005186901427805424
Training Epoch 46
train_metrics: 
R2: 0.8866091966629028
MSE: 33970.58203125
MAPE: 0.17054977646726627
test metrics:
R2: 0.8345457315444946
MSE: 53679.76171875
MAPE: 0.23446662125778195
MSE diff_p 46
----------
47: 0.006078610196709633
Training Epoch 47
train_metrics: 
R2: 0.8804497122764587
MSE: 39810.6484375
MAPE: 0.18982123611690133
test metrics:
R2: 0.8816908001899719
MSE: 40168.09375
MAPE: 0.18622229658411782
MSE diff_p 47
----------
48: 0.004499840550124645
Training Epoch 48
train_metrics: 
R2: 0.8969430923461914
MSE: 29470.80859375
MAPE: 0.16262694564043034
test metrics:
R2: 0.8467258810997009
MSE: 50444.03515625
MAPE: 0.22673329961174063
MSE diff_p 48
----------
49: 0.00497733848169446
Training Epoch 49
train_metrics: 
R2: 0.8889468908309937
MSE: 32598.08203125
MAPE: 0.1746160720961786
test metrics:
R2: 0.8884331583976746
MSE: 38542.61328125
MAPE: 0.18499346344799755
MSE diff_p 49
----------
50: 0.005285542458295822
Training Epoch 50
train_metrics: 
R2: 0.8943328261375427
MSE: 34616.609375
MAPE: 0.18213379870435076
test metrics:
R2: 0.8452207446098328
MSE: 51399.0390625
MAPE: 0.2303069601839296
MSE diff_p 50
----------
51: 0.003951183520257473
Training Epoch 51
train_metrics: 
R2: 0.9173234105110168
MSE: 25877.484375
MAPE: 0.1459158968314352
test metrics:
R2: 0.8946214914321899
MSE: 36887.0390625
MAPE: 0.18017785948446577
MSE diff_p 51
----------
52: 0.003486591624096036
Training Epoch 52
train_metrics: 
R2: 0.934735894203186
MSE: 22834.73828125
MAPE: 0.14666161466062055
test metrics:
R2: 0.8757901787757874
MSE: 43050.96875
MAPE: 0.20476447520574206
MSE diff_p 52
----------
53: 0.00354337808676064
Training Epoch 53
train_metrics: 
R2: 0.9234185814857483
MSE: 23206.6484375
MAPE: 0.14952780925600107
test metrics:
R2: 0.9041748046875
MSE: 34285.046875
MAPE: 0.17021051998849362
MSE diff_p 53
----------
54: 0.003626881865784526
Training Epoch 54
train_metrics: 
R2: 0.9263047575950623
MSE: 23753.53515625
MAPE: 0.15480065372680718
test metrics:
R2: 0.8859975337982178
MSE: 40300.42578125
MAPE: 0.1947431723324019
MSE diff_p 54
----------
55: 0.004056092351675034
Training Epoch 55
train_metrics: 
R2: 0.9177557229995728
MSE: 26564.56640625
MAPE: 0.17124004694569675
test metrics:
R2: 0.9062521457672119
MSE: 33937.4765625
MAPE: 0.1690293604461539
MSE diff_p 55
----------
56: 0.0029856753535568714
Training Epoch 56
train_metrics: 
R2: 0.9407576322555542
MSE: 19554.083984375
MAPE: 0.1302701557640039
test metrics:
R2: 0.8814635872840881
MSE: 41558.234375
MAPE: 0.20034094891514556
MSE diff_p 56
----------
57: 0.002838483778759837
Training Epoch 57
train_metrics: 
R2: 0.9373157024383545
MSE: 18590.083984375
MAPE: 0.15724384656034537
test metrics:
R2: 0.9068359136581421
MSE: 33586.30078125
MAPE: 0.16881885206581054
MSE diff_p 57
----------
58: 0.003700339701026678
Training Epoch 58
train_metrics: 
R2: 0.9278002977371216
MSE: 24234.638671875
MAPE: 0.1350572497626859
test metrics:
R2: 0.8871879577636719
MSE: 39902.51953125
MAPE: 0.19310243315343584
MSE diff_p 58
----------
59: 0.0031399172730743885
Training Epoch 59
train_metrics: 
R2: 0.9313923716545105
MSE: 20564.26171875
MAPE: 0.16348783477563722
test metrics:
R2: 0.9115182161331177
MSE: 32559.52734375
MAPE: 0.16674784179069838
MSE diff_p 59
----------
60: 0.0032427406404167414
Training Epoch 60
train_metrics: 
R2: 0.9345458745956421
MSE: 21237.68359375
MAPE: 0.136157294346045
test metrics:
R2: 0.892855167388916
MSE: 38304.28125
MAPE: 0.1906013673003122
MSE diff_p 60
----------
61: 0.003188788890838623
Training Epoch 61
train_metrics: 
R2: 0.9336722493171692
MSE: 20884.33984375
MAPE: 0.1383373122687806
test metrics:
R2: 0.9123064875602722
MSE: 32280.486328125
MAPE: 0.1650376179888449
MSE diff_p 61
----------
62: 0.0036253496073186398
Training Epoch 62
train_metrics: 
R2: 0.9254938364028931
MSE: 23743.505859375
MAPE: 0.13819945064917244
test metrics:
R2: 0.8908731937408447
MSE: 39315.61328125
MAPE: 0.19596804296352355
MSE diff_p 62
----------
63: 0.003165985457599163
Training Epoch 63
train_metrics: 
R2: 0.9403557777404785
MSE: 20734.9921875
MAPE: 0.14010951141320038
test metrics:
R2: 0.9146987795829773
MSE: 31750.47265625
MAPE: 0.16460771557192572
MSE diff_p 63
----------
64: 0.003283552825450897
Training Epoch 64
train_metrics: 
R2: 0.9284271001815796
MSE: 21504.974609375
MAPE: 0.13220154251946165
test metrics:
R2: 0.9058098793029785
MSE: 34929.66796875
MAPE: 0.17940115028618497
MSE diff_p 64
----------
65: 0.0032089673914015293
Training Epoch 65
train_metrics: 
R2: 0.9364593029022217
MSE: 21016.4921875
MAPE: 0.13606371508458565
test metrics:
R2: 0.9194859862327576
MSE: 30340.453125
MAPE: 0.16295007171070233
MSE diff_p 65
----------
66: 0.0039510042406618595
Training Epoch 66
train_metrics: 
R2: 0.9198815226554871
MSE: 25876.31640625
MAPE: 0.15401492817673335
test metrics:
R2: 0.898744523525238
MSE: 37229.76171875
MAPE: 0.19075786475896336
MSE diff_p 66
----------
67: 0.004048890899866819
Training Epoch 67
train_metrics: 
R2: 0.9230338335037231
MSE: 26517.40625
MAPE: 0.14043834922066356
test metrics:
R2: 0.9195463061332703
MSE: 30424.91015625
MAPE: 0.16434617766345652
MSE diff_p 67
----------
68: 0.004195764195173979
Training Epoch 68
train_metrics: 
R2: 0.9134401082992554
MSE: 27479.3203125
MAPE: 0.15733736900431322
test metrics:
R2: 0.8849250674247742
MSE: 42220.21484375
MAPE: 0.21057298663689442
MSE diff_p 68
----------
69: 0.004071600269526243
Training Epoch 69
train_metrics: 
R2: 0.9200096726417542
MSE: 26666.1328125
MAPE: 0.17531134749712735
test metrics:
R2: 0.91508948802948
MSE: 32021.3359375
MAPE: 0.1795977813359069
MSE diff_p 69
----------
70: 0.003971519879996777
Training Epoch 70
train_metrics: 
R2: 0.9140948057174683
MSE: 26010.6796875
MAPE: 0.14562645412713365
test metrics:
R2: 0.8784937858581543
MSE: 44059.21484375
MAPE: 0.216266325583727
MSE diff_p 70
----------
71: 0.0037113300058990717
Training Epoch 71
train_metrics: 
R2: 0.9208095073699951
MSE: 24306.615234375
MAPE: 0.16482615744762177
test metrics:
R2: 0.9173336625099182
MSE: 30839.9765625
MAPE: 0.17143587952470804
MSE diff_p 71
----------
72: 0.004369930364191532
Training Epoch 72
train_metrics: 
R2: 0.9190168380737305
MSE: 28619.98828125
MAPE: 0.15174273092433505
test metrics:
R2: 0.8798460364341736
MSE: 43756.97265625
MAPE: 0.2157271871019349
MSE diff_p 72
----------
73: 0.0039736744947731495
Training Epoch 73
train_metrics: 
R2: 0.9189115166664124
MSE: 26024.7890625
MAPE: 0.1675215211686517
test metrics:
R2: 0.9195053577423096
MSE: 30202.70703125
MAPE: 0.1709868404817109
MSE diff_p 73
----------
74: 0.0035004769451916218
Training Epoch 74
train_metrics: 
R2: 0.9309175610542297
MSE: 22925.677734375
MAPE: 0.13446129874958912
test metrics:
R2: 0.887591540813446
MSE: 41455.20703125
MAPE: 0.2095455344342283
MSE diff_p 74
----------
75: 0.004088989924639463
Training Epoch 75
train_metrics: 
R2: 0.9231646060943604
MSE: 26780.025390625
MAPE: 0.13334620937785807
test metrics:
R2: 0.922246515750885
MSE: 29410.7734375
MAPE: 0.16643105779289216
MSE diff_p 75
----------
76: 0.003994402009993792
Training Epoch 76
train_metrics: 
R2: 0.9207758903503418
MSE: 26160.54296875
MAPE: 0.16153754406061216
test metrics:
R2: 0.888679563999176
MSE: 41727.203125
MAPE: 0.20988197827603414
MSE diff_p 76
----------
77: 0.003977364394813776
Training Epoch 77
train_metrics: 
R2: 0.9264747500419617
MSE: 26048.955078125
MAPE: 0.16911195833335024
test metrics:
R2: 0.9226699471473694
MSE: 29654.2265625
MAPE: 0.171831758278998
MSE diff_p 77
----------
78: 0.0032459148205816746
Training Epoch 78
train_metrics: 
R2: 0.9359907507896423
MSE: 21258.474609375
MAPE: 0.13614408607911987
test metrics:
R2: 0.9069140553474426
MSE: 35526.28125
MAPE: 0.18788302939888843
MSE diff_p 78
----------
79: 0.0030561501625925303
Training Epoch 79
train_metrics: 
R2: 0.9382981061935425
MSE: 20015.646484375
MAPE: 0.1275291204001191
test metrics:
R2: 0.927740216255188
MSE: 27923.494140625
MAPE: 0.1609058084706532
MSE diff_p 79
----------
80: 0.002371247624978423
Training Epoch 80
train_metrics: 
R2: 0.9552091360092163
MSE: 15530.013671875
MAPE: 0.11127873735026492
test metrics:
R2: 0.9186210632324219
MSE: 31342.505859375
MAPE: 0.17278806063900734
MSE diff_p 80
----------
81: 0.0026191382203251123
Training Epoch 81
train_metrics: 
R2: 0.9512295722961426
MSE: 17153.5234375
MAPE: 0.1253078928181559
test metrics:
R2: 0.9277031421661377
MSE: 28017.4609375
MAPE: 0.16019645587521963
MSE diff_p 81
----------
82: 0.002916540252044797
Training Epoch 82
train_metrics: 
R2: 0.9432961344718933
MSE: 19101.296875
MAPE: 0.13234246352012807
test metrics:
R2: 0.91497403383255
MSE: 32545.056640625
MAPE: 0.17803478681157087
MSE diff_p 82
----------
83: 0.0033589100930839777
Training Epoch 83
train_metrics: 
R2: 0.937007486820221
MSE: 21998.5078125
MAPE: 0.14334777157979114
test metrics:
R2: 0.9292065501213074
MSE: 27657.478515625
MAPE: 0.15965822468405053
MSE diff_p 83
----------
84: 0.0034178285859525204
Training Epoch 84
train_metrics: 
R2: 0.9284520745277405
MSE: 22384.38671875
MAPE: 0.14028616617932393
test metrics:
R2: 0.9074317216873169
MSE: 35253.1328125
MAPE: 0.18972557775681143
MSE diff_p 84
----------
85: 0.003365161130204797
Training Epoch 85
train_metrics: 
R2: 0.9337011575698853
MSE: 22039.451171875
MAPE: 0.15626982517896074
test metrics:
R2: 0.9283999800682068
MSE: 27715.11328125
MAPE: 0.16378440355618204
MSE diff_p 85
----------
86: 0.004596046172082424
Training Epoch 86
train_metrics: 
R2: 0.9025986790657043
MSE: 30100.888671875
MAPE: 0.15621950267067491
test metrics:
R2: 0.8988190293312073
MSE: 38613.48046875
MAPE: 0.20162937336022352
MSE diff_p 86
----------
87: 0.004047588910907507
Training Epoch 87
train_metrics: 
R2: 0.9201387763023376
MSE: 26508.87890625
MAPE: 0.1659356852863027
test metrics:
R2: 0.9264864325523376
MSE: 28663.689453125
MAPE: 0.17255294487322279
MSE diff_p 87
----------
88: 0.004539275076240301
Training Epoch 88
train_metrics: 
R2: 0.9139987826347351
MSE: 29729.078125
MAPE: 0.14975437081703552
test metrics:
R2: 0.8880361318588257
MSE: 42649.6484375
MAPE: 0.2148530911054981
MSE diff_p 88
----------
89: 0.004129902459681034
Training Epoch 89
train_metrics: 
R2: 0.9214478135108948
MSE: 27047.97265625
MAPE: 0.16845129249738974
test metrics:
R2: 0.9288420677185059
MSE: 27634.53515625
MAPE: 0.1664940283446335
MSE diff_p 89
----------
90: 0.0036078912671655416
Training Epoch 90
train_metrics: 
R2: 0.9289008975028992
MSE: 23629.1640625
MAPE: 0.14290306593324215
test metrics:
R2: 0.8963691592216492
MSE: 39786.9140625
MAPE: 0.20483844857448696
MSE diff_p 90
----------
91: 0.0036987848579883575
Training Epoch 91
train_metrics: 
R2: 0.9265853762626648
MSE: 24224.455078125
MAPE: 0.15917600638356627
test metrics:
R2: 0.9271203875541687
MSE: 28224.59375
MAPE: 0.1682595117849086
MSE diff_p 91
----------
92: 0.0030292836017906666
Training Epoch 92
train_metrics: 
R2: 0.9400972723960876
MSE: 19839.69140625
MAPE: 0.1372317151002768
test metrics:
R2: 0.896962583065033
MSE: 38915.359375
MAPE: 0.204839243759412
MSE diff_p 92
----------
93: 0.003356877714395523
Training Epoch 93
train_metrics: 
R2: 0.9352368712425232
MSE: 21985.203125
MAPE: 0.14635974936025686
test metrics:
R2: 0.9304600358009338
MSE: 27091.251953125
MAPE: 0.1590324901046966
MSE diff_p 93
----------
94: 0.0025905396323651075
Training Epoch 94
train_metrics: 
R2: 0.9475853443145752
MSE: 16966.224609375
MAPE: 0.12415029030713845
test metrics:
R2: 0.9132989645004272
MSE: 33862.375
MAPE: 0.18307434227021452
MSE diff_p 94
----------
95: 0.003213576739653945
Training Epoch 95
train_metrics: 
R2: 0.9427290558815002
MSE: 21046.6796875
MAPE: 0.1416705552284624
test metrics:
R2: 0.9326404333114624
MSE: 26619.306640625
MAPE: 0.15725367743129587
MSE diff_p 95
----------
96: 0.0033298551570624113
Training Epoch 96
train_metrics: 
R2: 0.9329721927642822
MSE: 21808.22265625
MAPE: 0.1309119504268425
test metrics:
R2: 0.9227558374404907
MSE: 30232.32421875
MAPE: 0.1712913773689243
MSE diff_p 96
----------
97: 0.0031463936902582645
Training Epoch 97
train_metrics: 
R2: 0.938999593257904
MSE: 20606.6796875
MAPE: 0.14860417477932567
test metrics:
R2: 0.933037281036377
MSE: 26555.603515625
MAPE: 0.15699885632926436
MSE diff_p 97
----------
98: 0.0026154029183089733
Training Epoch 98
train_metrics: 
R2: 0.9495924711227417
MSE: 17129.05859375
MAPE: 0.118480622194631
test metrics:
R2: 0.9278206825256348
MSE: 28627.353515625
MAPE: 0.1651577553313494
MSE diff_p 98
----------
99: 0.0023453624453395605
Training Epoch 99
train_metrics: 
R2: 0.9518762826919556
MSE: 15360.4853515625
MAPE: 0.12919006362128338
test metrics:
R2: 0.93584144115448
MSE: 25539.244140625
MAPE: 0.15423872449868833
MSE diff_p 99
----------
100: 0.0025909736286848783
Training Epoch 100
train_metrics: 
R2: 0.9461382627487183
MSE: 16969.064453125
MAPE: 0.10627324307627897
test metrics:
R2: 0.9266878366470337
MSE: 28990.140625
MAPE: 0.166673372179065
MSE diff_p 100
----------
101: 0.0029423243831843138
Training Epoch 101
train_metrics: 
R2: 0.9406735897064209
MSE: 19270.1640625
MAPE: 0.1215262120954026
test metrics:
R2: 0.9364347457885742
MSE: 25405.630859375
MAPE: 0.15407046641652414
MSE diff_p 101
----------
102: 0.002967716893181205
Training Epoch 102
train_metrics: 
R2: 0.9405911564826965
MSE: 19436.470703125
MAPE: 0.12277832418990042
test metrics:
R2: 0.9153612852096558
MSE: 33449.2890625
MAPE: 0.1837114333979403
MSE diff_p 102
----------
103: 0.0025818662252277136
Training Epoch 103
train_metrics: 
R2: 0.952081561088562
MSE: 16909.41796875
MAPE: 0.13739442286244669
test metrics:
R2: 0.9368544816970825
MSE: 25147.962890625
MAPE: 0.15577649554791578
MSE diff_p 103
----------
104: 0.003282075747847557
Training Epoch 104
train_metrics: 
R2: 0.9379146099090576
MSE: 21495.30078125
MAPE: 0.13987252098544173
test metrics:
R2: 0.9211063385009766
MSE: 31065.623046875
MAPE: 0.17602017314099463
MSE diff_p 104
----------
105: 0.0031067111995071173
Training Epoch 105
train_metrics: 
R2: 0.9414458870887756
MSE: 20346.78515625
MAPE: 0.14519210657507325
test metrics:
R2: 0.937103271484375
MSE: 25207.208984375
MAPE: 0.15700118386713927
MSE diff_p 105
----------
106: 0.0026749041862785816
Training Epoch 106
train_metrics: 
R2: 0.9452139735221863
MSE: 17518.75
MAPE: 0.11899023902917882
test metrics:
R2: 0.9168572425842285
MSE: 32652.576171875
MAPE: 0.1816123989805003
MSE diff_p 106
----------
107: 0.002899718703702092
Training Epoch 107
train_metrics: 
R2: 0.9410913586616516
MSE: 18991.130859375
MAPE: 0.15921932982728637
test metrics:
R2: 0.9353111982345581
MSE: 25535.330078125
MAPE: 0.15484236815746982
MSE diff_p 107
----------
108: 0.003073914907872677
Training Epoch 108
train_metrics: 
R2: 0.9367414116859436
MSE: 20131.99609375
MAPE: 0.129235350181107
test metrics:
R2: 0.9176559448242188
MSE: 31915.49609375
MAPE: 0.17902425300882227
MSE diff_p 108
----------
109: 0.0032545963767915964
Training Epoch 109
train_metrics: 
R2: 0.9375931620597839
MSE: 21315.326171875
MAPE: 0.14197585731589613
test metrics:
R2: 0.934741735458374
MSE: 25828.630859375
MAPE: 0.15809114760477375
MSE diff_p 109
----------
110: 0.0033456962555646896
Training Epoch 110
train_metrics: 
R2: 0.9356653690338135
MSE: 21911.97265625
MAPE: 0.13805393448749761
test metrics:
R2: 0.9127848744392395
MSE: 34175.61328125
MAPE: 0.18744611254520696
MSE diff_p 110
----------
111: 0.003456707578152418
Training Epoch 111
train_metrics: 
R2: 0.923088014125824
MSE: 22639.017578125
MAPE: 0.16187647579957556
test metrics:
R2: 0.9343243837356567
MSE: 26020.51953125
MAPE: 0.16003529159435176
MSE diff_p 111
----------
112: 0.0037162364460527897
Training Epoch 112
train_metrics: 
R2: 0.9295401573181152
MSE: 24338.75
MAPE: 0.159476875831159
test metrics:
R2: 0.8968775272369385
MSE: 39616.3671875
MAPE: 0.208485120195789
MSE diff_p 112
----------
113: 0.003861991921439767
Training Epoch 113
train_metrics: 
R2: 0.9241083264350891
MSE: 25293.34765625
MAPE: 0.16890986529966498
test metrics:
R2: 0.9288203716278076
MSE: 27434.169921875
MAPE: 0.16377886561280064
MSE diff_p 113
----------
114: 0.00275243422947824
Training Epoch 114
train_metrics: 
R2: 0.9449636936187744
MSE: 18026.517578125
MAPE: 0.11581424308915844
test metrics:
R2: 0.9089643955230713
MSE: 34945.59375
MAPE: 0.18783168792212138
MSE diff_p 114
----------
115: 0.002532322658225894
Training Epoch 115
train_metrics: 
R2: 0.9513795971870422
MSE: 16584.943359375
MAPE: 0.12557277061824795
test metrics:
R2: 0.9325742721557617
MSE: 26341.630859375
MAPE: 0.15620163346573304
MSE diff_p 115
----------
116: 0.002135871211066842
Training Epoch 116
train_metrics: 
R2: 0.9586840271949768
MSE: 13988.4609375
MAPE: 0.10751087821592534
test metrics:
R2: 0.9294080138206482
MSE: 27867.24609375
MAPE: 0.16375429887471557
MSE diff_p 116
----------
117: 0.002752569504082203
Training Epoch 117
train_metrics: 
R2: 0.9511698484420776
MSE: 18027.40625
MAPE: 0.13198956968864378
test metrics:
R2: 0.9350610971450806
MSE: 25566.86328125
MAPE: 0.15402791704876692
MSE diff_p 117
----------
118: 0.002603095956146717
Training Epoch 118
train_metrics: 
R2: 0.9500704407691956
MSE: 17048.45703125
MAPE: 0.1272893116453085
test metrics:
R2: 0.9317832589149475
MSE: 27171.697265625
MAPE: 0.1611494158442568
MSE diff_p 118
----------
119: 0.0022660158574581146
Training Epoch 119
train_metrics: 
R2: 0.9556066393852234
MSE: 14840.818359375
MAPE: 0.12736160859422668
test metrics:
R2: 0.9376881122589111
MSE: 24950.4296875
MAPE: 0.15283946614332514
MSE diff_p 119
----------
120: 0.0034657930955290794
Training Epoch 120
train_metrics: 
R2: 0.9347664713859558
MSE: 22698.51953125
MAPE: 0.13919040006914318
test metrics:
R2: 0.9260818958282471
MSE: 29277.654296875
MAPE: 0.17067038422693087
MSE diff_p 120
----------
121: 0.002850319491699338
Training Epoch 121
train_metrics: 
R2: 0.9492189884185791
MSE: 18667.6015625
MAPE: 0.13920371520100638
test metrics:
R2: 0.9404540657997131
MSE: 24085.40625
MAPE: 0.15190688717517864
MSE diff_p 121
----------
122: 0.0027682571671903133
Training Epoch 122
train_metrics: 
R2: 0.9481764435768127
MSE: 18130.1484375
MAPE: 0.12986760891021737
test metrics:
R2: 0.9281330108642578
MSE: 29014.029296875
MAPE: 0.16934139623301753
MSE diff_p 122
----------
123: 0.0028144782409071922
Training Epoch 123
train_metrics: 
R2: 0.9513334035873413
MSE: 18432.865234375
MAPE: 0.1299597790084862
test metrics:
R2: 0.9412733912467957
MSE: 23910.982421875
MAPE: 0.15288122692889042
MSE diff_p 123
----------
124: 0.003314503002911806
Training Epoch 124
train_metrics: 
R2: 0.9392551183700562
MSE: 21707.677734375
MAPE: 0.1454201388953139
test metrics:
R2: 0.9237125515937805
MSE: 30674.04296875
MAPE: 0.17655038803365822
MSE diff_p 124
----------
125: 0.002911944407969713
Training Epoch 125
train_metrics: 
R2: 0.9464473128318787
MSE: 19071.19921875
MAPE: 0.13510753925889335
test metrics:
R2: 0.9408206939697266
MSE: 23974.30078125
MAPE: 0.15506780334952083
MSE diff_p 125
----------
126: 0.00296987546607852
Training Epoch 126
train_metrics: 
R2: 0.9378568530082703
MSE: 19450.603515625
MAPE: 0.11666440251806992
test metrics:
R2: 0.9209145307540894
MSE: 31535.833984375
MAPE: 0.18173117686960644
MSE diff_p 126
----------
127: 0.0026236828416585922
Training Epoch 127
train_metrics: 
R2: 0.9531795978546143
MSE: 17183.28515625
MAPE: 0.12874386606948124
test metrics:
R2: 0.9416553974151611
MSE: 23709.419921875
MAPE: 0.15368490805250526
MSE diff_p 127
----------
128: 0.002731393091380596
Training Epoch 128
train_metrics: 
R2: 0.9455589056015015
MSE: 17888.712890625
MAPE: 0.14743858742883223
test metrics:
R2: 0.9279640913009644
MSE: 29058.7265625
MAPE: 0.17192724801430617
MSE diff_p 128
----------
129: 0.0034059672616422176
Training Epoch 129
train_metrics: 
R2: 0.9325486421585083
MSE: 22306.705078125
MAPE: 0.13658449334266884
test metrics:
R2: 0.9420991539955139
MSE: 23507.3125
MAPE: 0.154180688687661
MSE diff_p 129
----------
130: 0.0024994772393256426
Training Epoch 130
train_metrics: 
R2: 0.9546467661857605
MSE: 16369.828125
MAPE: 0.11593605177328992
test metrics:
R2: 0.9242937564849854
MSE: 30629.962890625
MAPE: 0.17448007888695577
MSE diff_p 130
----------
131: 0.002264414681121707
Training Epoch 131
train_metrics: 
R2: 0.9554631114006042
MSE: 14830.3349609375
MAPE: 0.12188313175682716
test metrics:
R2: 0.9404163956642151
MSE: 24224.5390625
MAPE: 0.15167402502225513
MSE diff_p 131
----------
132: 0.002479745075106621
Training Epoch 132
train_metrics: 
R2: 0.9530557990074158
MSE: 16240.59765625
MAPE: 0.12969133534293542
test metrics:
R2: 0.9285237789154053
MSE: 28823.689453125
MAPE: 0.17075601786632127
MSE diff_p 132
----------
133: 0.0031170675065368414
Training Epoch 133
train_metrics: 
R2: 0.944781482219696
MSE: 20414.61328125
MAPE: 0.130872136681534
test metrics:
R2: 0.9416849613189697
MSE: 23624.18359375
MAPE: 0.15152554627969397
MSE diff_p 133
----------
134: 0.0025986800901591778
Training Epoch 134
train_metrics: 
R2: 0.9495629072189331
MSE: 17019.537109375
MAPE: 0.12579067622944567
test metrics:
R2: 0.9286157488822937
MSE: 29074.9140625
MAPE: 0.17099737818660052
MSE diff_p 134
----------
135: 0.00233733793720603
Training Epoch 135
train_metrics: 
R2: 0.9544362425804138
MSE: 15307.9306640625
MAPE: 0.1274340014304643
test metrics:
R2: 0.9424958229064941
MSE: 23754.279296875
MAPE: 0.1500261544638793
MSE diff_p 135
----------
136: 0.0021268283016979694
Training Epoch 136
train_metrics: 
R2: 0.9587374329566956
MSE: 13929.2373046875
MAPE: 0.11624537234053173
test metrics:
R2: 0.9378400444984436
MSE: 25549.51171875
MAPE: 0.15709344363772879
MSE diff_p 136
----------
137: 0.003609446110203862
Training Epoch 137
train_metrics: 
R2: 0.933881938457489
MSE: 23639.3515625
MAPE: 0.15620775412797672
test metrics:
R2: 0.9453827738761902
MSE: 22578.21875
MAPE: 0.14785660597022499
MSE diff_p 137
----------
138: 0.0025086288806051016
Training Epoch 138
train_metrics: 
R2: 0.9519718885421753
MSE: 16429.763671875
MAPE: 0.11407107369349664
test metrics:
R2: 0.9360387325286865
MSE: 26115.7109375
MAPE: 0.15909732699945964
MSE diff_p 138
----------
139: 0.003217894583940506
Training Epoch 139
train_metrics: 
R2: 0.938834011554718
MSE: 21074.95703125
MAPE: 0.13596914538197702
test metrics:
R2: 0.9441516995429993
MSE: 22909.873046875
MAPE: 0.15054402463965427
MSE diff_p 139
----------
140: 0.0023216288536787033
Training Epoch 140
train_metrics: 
R2: 0.9514617919921875
MSE: 15205.0458984375
MAPE: 0.12526040573348235
test metrics:
R2: 0.9201322793960571
MSE: 32344.419921875
MAPE: 0.18571531106184502
MSE diff_p 140
----------
141: 0.003230510512366891
Training Epoch 141
train_metrics: 
R2: 0.9428247213363647
MSE: 21157.58203125
MAPE: 0.14946034202863456
test metrics:
R2: 0.943228542804718
MSE: 23444.84375
MAPE: 0.1538866342736094
MSE diff_p 141
----------
142: 0.0030202961061149836
Training Epoch 142
train_metrics: 
R2: 0.943006694316864
MSE: 19780.826171875
MAPE: 0.13555299054500095
test metrics:
R2: 0.9248101115226746
MSE: 30983.95703125
MAPE: 0.17826576451580758
MSE diff_p 142
----------
143: 0.0026237317360937595
Training Epoch 143
train_metrics: 
R2: 0.9440321922302246
MSE: 17183.609375
MAPE: 0.1464576049686782
test metrics:
R2: 0.9458085894584656
MSE: 22449.169921875
MAPE: 0.14925382015659647
MSE diff_p 143
----------
144: 0.002354250056669116
Training Epoch 144
train_metrics: 
R2: 0.9582911729812622
MSE: 15418.69140625
MAPE: 0.12333155967341752
test metrics:
R2: 0.9327256083488464
MSE: 27501.986328125
MAPE: 0.16629940714758967
MSE diff_p 144
----------
145: 0.003628314007073641
Training Epoch 145
train_metrics: 
R2: 0.926814079284668
MSE: 23762.919921875
MAPE: 0.14494066140654277
test metrics:
R2: 0.9433066248893738
MSE: 22915.716796875
MAPE: 0.1503805690848255
MSE diff_p 145
----------
146: 0.004210758022964001
Training Epoch 146
train_metrics: 
R2: 0.916621208190918
MSE: 27577.517578125
MAPE: 0.1138448871887722
test metrics:
R2: 0.9339832067489624
MSE: 26893.48046875
MAPE: 0.16231062170252425
MSE diff_p 146
----------
147: 0.002504361094906926
Training Epoch 147
train_metrics: 
R2: 0.9488446116447449
MSE: 16401.814453125
MAPE: 0.1249636528322674
test metrics:
R2: 0.9419716000556946
MSE: 23220.720703125
MAPE: 0.14893811931292988
MSE diff_p 147
----------
148: 0.0028727692551910877
Training Epoch 148
train_metrics: 
R2: 0.94698566198349
MSE: 18814.62890625
MAPE: 0.13864772121239036
test metrics:
R2: 0.9326003789901733
MSE: 27096.328125
MAPE: 0.16519886847456977
MSE diff_p 148
----------
149: 0.0028397415298968554
Training Epoch 149
train_metrics: 
R2: 0.9464569687843323
MSE: 18598.3203125
MAPE: 0.13748060713256616
test metrics:
R2: 0.9426831603050232
MSE: 23194.064453125
MAPE: 0.1507912943991515
MSE diff_p 149
----------
150: 0.0027940059080719948
Training Epoch 150
train_metrics: 
R2: 0.9506841897964478
MSE: 18298.78515625
MAPE: 0.13828567722249846
test metrics:
R2: 0.9183886647224426
MSE: 32731.626953125
MAPE: 0.1876545657852402
MSE diff_p 150
----------
151: 0.0032425790559500456
Training Epoch 151
train_metrics: 
R2: 0.9392703175544739
MSE: 21236.625
MAPE: 0.16082945700275253
test metrics:
R2: 0.9424765706062317
MSE: 23475.630859375
MAPE: 0.15466765953230593
MSE diff_p 151
----------
152: 0.0024874762166291475
Training Epoch 152
train_metrics: 
R2: 0.9524624943733215
MSE: 16291.2265625
MAPE: 0.12042650465261683
test metrics:
R2: 0.9260567426681519
MSE: 29736.3828125
MAPE: 0.17591472356949836
MSE diff_p 152
----------
153: 0.0023681141901761293
Training Epoch 153
train_metrics: 
R2: 0.9551364183425903
MSE: 15509.4921875
MAPE: 0.11850165910645236
test metrics:
R2: 0.9429545998573303
MSE: 23100.75
MAPE: 0.14929199935287915
MSE diff_p 153
----------
154: 0.0029697283171117306
Training Epoch 154
train_metrics: 
R2: 0.9510965943336487
MSE: 19449.64453125
MAPE: 0.13635187804511364
test metrics:
R2: 0.9324586987495422
MSE: 27369.2890625
MAPE: 0.16490888335862003
MSE diff_p 154
----------
155: 0.002656974596902728
Training Epoch 155
train_metrics: 
R2: 0.9511481523513794
MSE: 17401.330078125
MAPE: 0.1212676272689103
test metrics:
R2: 0.9432210922241211
MSE: 22858.79296875
MAPE: 0.1480224696836272
MSE diff_p 155
----------
156: 0.0024638690520077944
Training Epoch 156
train_metrics: 
R2: 0.9528262615203857
MSE: 16136.62109375
MAPE: 0.11633435039270983
test metrics:
R2: 0.931442141532898
MSE: 27959.6328125
MAPE: 0.16689414240306744
MSE diff_p 156
----------
157: 0.002322197426110506
Training Epoch 157
train_metrics: 
R2: 0.9557710886001587
MSE: 15208.7705078125
MAPE: 0.11382476921255438
test metrics:
R2: 0.9440028071403503
MSE: 22798.31640625
MAPE: 0.1477824394168838
MSE diff_p 157
----------
158: 0.0020672455430030823
Training Epoch 158
train_metrics: 
R2: 0.960543692111969
MSE: 13539.013671875
MAPE: 0.11525364968347071
test metrics:
R2: 0.9410673379898071
MSE: 24218.693359375
MAPE: 0.15192176582696099
MSE diff_p 158
----------
159: 0.0024996022693812847
Training Epoch 159
train_metrics: 
R2: 0.9559649229049683
MSE: 16370.6494140625
MAPE: 0.1303458141411072
test metrics:
R2: 0.9447782635688782
MSE: 22636.986328125
MAPE: 0.1469519206595331
MSE diff_p 159
----------
160: 0.002557077445089817
Training Epoch 160
train_metrics: 
R2: 0.9486923217773438
MSE: 16747.0703125
MAPE: 0.11470980148004155
test metrics:
R2: 0.9334316253662109
MSE: 27047.298828125
MAPE: 0.16580001464612007
MSE diff_p 160
----------
161: 0.0030496970284730196
Training Epoch 161
train_metrics: 
R2: 0.9411721229553223
MSE: 19973.38671875
MAPE: 0.154048593264521
test metrics:
R2: 0.9421859383583069
MSE: 23386.046875
MAPE: 0.15421363894698523
MSE diff_p 161
----------
162: 0.003314558882266283
Training Epoch 162
train_metrics: 
R2: 0.9367226362228394
MSE: 21708.041015625
MAPE: 0.13810697079733925
test metrics:
R2: 0.9225428104400635
MSE: 31049.20703125
MAPE: 0.18208350160717457
MSE diff_p 162
----------
163: 0.003795475699007511
Training Epoch 163
train_metrics: 
R2: 0.9162044525146484
MSE: 24857.7109375
MAPE: 0.14621727467182447
test metrics:
R2: 0.9380813241004944
MSE: 24740.021484375
MAPE: 0.15827562224362252
MSE diff_p 163
----------
164: 0.004009832162410021
Training Epoch 164
train_metrics: 
R2: 0.9165410995483398
MSE: 26261.59765625
MAPE: 0.1546849431758846
test metrics:
R2: 0.9023876190185547
MSE: 38171.02734375
MAPE: 0.20923065716458514
MSE diff_p 164
----------
165: 0.0042191073298454285
Training Epoch 165
train_metrics: 
R2: 0.9127692580223083
MSE: 27632.20703125
MAPE: 0.16700044509852774
test metrics:
R2: 0.9238450527191162
MSE: 28354.5859375
MAPE: 0.16595827538960364
MSE diff_p 165
----------
166: 0.0031723894644528627
Training Epoch 166
train_metrics: 
R2: 0.9279665946960449
MSE: 20776.9296875
MAPE: 0.11268434078786924
test metrics:
R2: 0.881090521812439
MSE: 39839.04296875
MAPE: 0.18280926744357795
MSE diff_p 166
----------
167: 0.002746261190623045
Training Epoch 167
train_metrics: 
R2: 0.9482727646827698
MSE: 17986.08984375
MAPE: 0.13293690924314233
test metrics:
R2: 0.9348941445350647
MSE: 26393.8359375
MAPE: 0.16170290559022432
MSE diff_p 167
----------
168: 0.0033960561268031597
Training Epoch 168
train_metrics: 
R2: 0.937537670135498
MSE: 22241.79296875
MAPE: 0.12987771384328323
test metrics:
R2: 0.9435519576072693
MSE: 23014.630859375
MAPE: 0.14999150910036899
MSE diff_p 168
----------
169: 0.002468773862347007
Training Epoch 169
train_metrics: 
R2: 0.9518923759460449
MSE: 16168.744140625
MAPE: 0.11412008057100967
test metrics:
R2: 0.9395727515220642
MSE: 25024.953125
MAPE: 0.15714081310731629
MSE diff_p 169
----------
170: 0.0020588652696460485
Training Epoch 170
train_metrics: 
R2: 0.9598421454429626
MSE: 13484.126953125
MAPE: 0.11598895199280246
test metrics:
R2: 0.9451172947883606
MSE: 22655.470703125
MAPE: 0.14970234009789088
MSE diff_p 170
----------
171: 0.0024413480423390865
Training Epoch 171
train_metrics: 
R2: 0.9493184685707092
MSE: 15989.123046875
MAPE: 0.12074633160347617
test metrics:
R2: 0.9394745826721191
MSE: 25048.767578125
MAPE: 0.1589359890281825
MSE diff_p 171
----------
172: 0.002482382347807288
Training Epoch 172
train_metrics: 
R2: 0.9568387866020203
MSE: 16257.8681640625
MAPE: 0.12687932924860282
test metrics:
R2: 0.9480754733085632
MSE: 21433.337890625
MAPE: 0.1471369421142631
MSE diff_p 172
----------
173: 0.002744245808571577
Training Epoch 173
train_metrics: 
R2: 0.9513795971870422
MSE: 17972.890625
MAPE: 0.1379929883284498
test metrics:
R2: 0.933316171169281
MSE: 27590.56640625
MAPE: 0.16943428709670216
MSE diff_p 173
----------
174: 0.0025700244586914778
Training Epoch 174
train_metrics: 
R2: 0.9492409825325012
MSE: 16831.861328125
MAPE: 0.13415330096505668
test metrics:
R2: 0.9480329751968384
MSE: 21543.193359375
MAPE: 0.1492326060311215
MSE diff_p 174
----------
175: 0.0020421065855771303
Training Epoch 175
train_metrics: 
R2: 0.9622042179107666
MSE: 13374.369140625
MAPE: 0.1142534410450196
test metrics:
R2: 0.9347336888313293
MSE: 27167.611328125
MAPE: 0.1667901941401642
MSE diff_p 175
----------
176: 0.002932826289907098
Training Epoch 176
train_metrics: 
R2: 0.9450145363807678
MSE: 19207.9609375
MAPE: 0.13160875136153435
test metrics:
R2: 0.9477971196174622
MSE: 21621.658203125
MAPE: 0.1478021421908826
MSE diff_p 176
----------
177: 0.0027706704568117857
Training Epoch 177
train_metrics: 
R2: 0.948899507522583
MSE: 18145.953125
MAPE: 0.12629801699645254
test metrics:
R2: 0.9393011331558228
MSE: 25013.484375
MAPE: 0.15939601371706089
MSE diff_p 177
----------
178: 0.003061861265450716
Training Epoch 178
train_metrics: 
R2: 0.9450476765632629
MSE: 20053.05078125
MAPE: 0.13504149637565585
test metrics:
R2: 0.9484620690345764
MSE: 21389.349609375
MAPE: 0.14520838402551625
MSE diff_p 178
----------
179: 0.0027803487610071898
Training Epoch 179
train_metrics: 
R2: 0.9480380415916443
MSE: 18209.33984375
MAPE: 0.10724384916516502
test metrics:
R2: 0.942384660243988
MSE: 23945.900390625
MAPE: 0.1538706527593588
MSE diff_p 179
----------
180: 0.0019288129406049848
Training Epoch 180
train_metrics: 
R2: 0.9611494541168213
MSE: 12632.375
MAPE: 0.11071504222020861
test metrics:
R2: 0.9497776627540588
MSE: 20941.61328125
MAPE: 0.14428552512677542
MSE diff_p 180
----------
181: 0.0020124095026403666
Training Epoch 181
train_metrics: 
R2: 0.9651606678962708
MSE: 13179.8740234375
MAPE: 0.11465601295043883
test metrics:
R2: 0.9452537894248962
MSE: 22889.046875
MAPE: 0.15070744136233952
MSE diff_p 181
----------
182: 0.0023135042283684015
Training Epoch 182
train_metrics: 
R2: 0.9602240920066833
MSE: 15151.833984375
MAPE: 0.09801671574380595
test metrics:
R2: 0.94927579164505
MSE: 21206.021484375
MAPE: 0.1436486026824052
MSE diff_p 182
----------
183: 0.003116150153800845
Training Epoch 183
train_metrics: 
R2: 0.9467169046401978
MSE: 20408.60546875
MAPE: 0.12731800908309882
test metrics:
R2: 0.9392980337142944
MSE: 25543.005859375
MAPE: 0.16048844667201356
MSE diff_p 183
----------
184: 0.002391115529462695
Training Epoch 184
train_metrics: 
R2: 0.9519126415252686
MSE: 15660.1357421875
MAPE: 0.12556664477498194
test metrics:
R2: 0.9490401744842529
MSE: 21150.408203125
MAPE: 0.1483051202269748
MSE diff_p 184
----------
185: 0.002765093930065632
Training Epoch 185
train_metrics: 
R2: 0.9442251324653625
MSE: 18109.43359375
MAPE: 0.12634142035260987
test metrics:
R2: 0.9375385046005249
MSE: 25841.671875
MAPE: 0.1643605926649561
MSE diff_p 185
----------
186: 0.0023222421295940876
Training Epoch 186
train_metrics: 
R2: 0.9571703672409058
MSE: 15209.0625
MAPE: 0.13520763981464
test metrics:
R2: 0.9485956430435181
MSE: 21368.013671875
MAPE: 0.14880745628239908
MSE diff_p 186
----------
187: 0.002257207641378045
Training Epoch 187
train_metrics: 
R2: 0.9591134190559387
MSE: 14783.1318359375
MAPE: 0.12328353828064628
test metrics:
R2: 0.9388362169265747
MSE: 25964.677734375
MAPE: 0.1606263664649378
MSE diff_p 187
----------
188: 0.0020614375825971365
Training Epoch 188
train_metrics: 
R2: 0.9606800079345703
MSE: 13500.974609375
MAPE: 0.1236379040369541
test metrics:
R2: 0.9522842764854431
MSE: 20391.986328125
MAPE: 0.1434338583589125
MSE diff_p 188
----------
189: 0.0024273048620671034
Training Epoch 189
train_metrics: 
R2: 0.9498091340065002
MSE: 15897.1474609375
MAPE: 0.11343983306224073
test metrics:
R2: 0.9463299512863159
MSE: 22802.005859375
MAPE: 0.14905535026180083
MSE diff_p 189
----------
190: 0.0024434642400592566
Training Epoch 190
train_metrics: 
R2: 0.9510461688041687
MSE: 16002.982421875
MAPE: 0.12233083246362057
test metrics:
R2: 0.9523962736129761
MSE: 20149.8671875
MAPE: 0.14109879712777587
MSE diff_p 190
----------
191: 0.0022210266906768084
Training Epoch 191
train_metrics: 
R2: 0.9590864777565002
MSE: 14546.171875
MAPE: 0.1113935107004036
test metrics:
R2: 0.9427443146705627
MSE: 24144.23046875
MAPE: 0.15505251934964406
MSE diff_p 191
----------
192: 0.002444196492433548
Training Epoch 192
train_metrics: 
R2: 0.9613512754440308
MSE: 16007.7744140625
MAPE: 0.13501104371604175
test metrics:
R2: 0.9531199932098389
MSE: 20016.3828125
MAPE: 0.14337080979901254
MSE diff_p 192
----------
193: 0.0024920625146478415
Training Epoch 193
train_metrics: 
R2: 0.9522233605384827
MSE: 16321.267578125
MAPE: 0.13337910401646605
test metrics:
R2: 0.9455255270004272
MSE: 23258.134765625
MAPE: 0.15210495255371523
MSE diff_p 193
----------
194: 0.0023355851881206036
Training Epoch 194
train_metrics: 
R2: 0.9546554684638977
MSE: 15296.44921875
MAPE: 0.14258569753414146
test metrics:
R2: 0.9519069194793701
MSE: 20209.919921875
MAPE: 0.14399809510340583
MSE diff_p 194
----------
195: 0.0029980032704770565
Training Epoch 195
train_metrics: 
R2: 0.9481236934661865
MSE: 19634.82421875
MAPE: 0.12004992204824019
test metrics:
R2: 0.9304970502853394
MSE: 29063.17578125
MAPE: 0.17577423941120096
MSE diff_p 195
----------
196: 0.0028268678579479456
Training Epoch 196
train_metrics: 
R2: 0.9449382424354553
MSE: 18514.0078125
MAPE: 0.12731751507808997
test metrics:
R2: 0.9477798938751221
MSE: 21541.23046875
MAPE: 0.14978422411399456
MSE diff_p 196
----------
197: 0.002950814552605152
Training Epoch 197
train_metrics: 
R2: 0.9476482272148132
MSE: 19325.771484375
MAPE: 0.13736022635377187
test metrics:
R2: 0.9337143301963806
MSE: 27508.69921875
MAPE: 0.170898107232791
MSE diff_p 197
----------
198: 0.003058664035052061
Training Epoch 198
train_metrics: 
R2: 0.9442797899246216
MSE: 20032.109375
MAPE: 0.13406094583548472
test metrics:
R2: 0.9474315047264099
MSE: 21717.5078125
MAPE: 0.15174064025726813
MSE diff_p 198
----------
199: 0.0034259872045367956
Training Epoch 199
train_metrics: 
R2: 0.9289466738700867
MSE: 22437.8203125
MAPE: 0.14722503506505452
test metrics:
R2: 0.9290506839752197
MSE: 29327.48046875
MAPE: 0.17914204832138153
MSE diff_p 199
----------
