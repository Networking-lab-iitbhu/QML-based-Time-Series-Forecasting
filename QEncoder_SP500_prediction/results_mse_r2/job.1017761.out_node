==========================================
SLURM_CLUSTER_NAME = param-shivay
SLURM_JOB_ACCOUNT = comp_sci_engg
SLURM_JOB_ID = 1017761
SLURM_JOB_NAME = printjob
SLURM_JOB_NODELIST = cn001
SLURM_JOB_USER = soumyadeep.das.cse21.itbhu
SLURM_JOB_UID = 5621
SLURM_JOB_PARTITION = cpu
SLURM_TASK_PID = 40326
SLURM_SUBMIT_DIR = /home/soumyadeep.das.cse21.itbhu/quantum-ml/LexiQL
SLURM_CPUS_ON_NODE = 1
SLURM_NTASKS = 
SLURM_TASK_PID = 40326
==========================================
hello world
module loaded
env loaded
python is running
number of stocks: 506

 Training Encoder...

Encoder Loss: 0.029 Iteration: 20
Encoder Loss: 0.032 Iteration: 40
Encoder Loss: 0.031 Iteration: 60
Encoder Loss: 0.03 Iteration: 80
Encoder Loss: 0.03 Iteration: 100
Encoder Loss: 0.028 Iteration: 120
Encoder Loss: 0.029 Iteration: 140
Encoder Loss: 0.03 Iteration: 160
Encoder Loss: 0.03 Iteration: 180
Encoder Loss: 0.029 Iteration: 200
Encoder Loss: 0.03 Iteration: 220
Encoder Loss: 0.032 Iteration: 240
Encoder Loss: 0.027 Iteration: 260
Encoder Loss: 0.031 Iteration: 280
Encoder Loss: 0.029 Iteration: 300
Training Started... 
0: 0.18099871277809143
Training Epoch 0
train_metrics: 
R2: -6.7951979637146
MSE: 1185415.0
test metrics:
R2: -9.718741416931152
MSE: 1399336.125
before val features
MSE diff_p 0
----------
1: 0.08459185063838959
Training Epoch 1
train_metrics: 
R2: -23.018356323242188
MSE: 554017.5
test metrics:
R2: -30.107818603515625
MSE: 847101.6875
MSE diff_p 1
----------
2: 0.07047194242477417
Training Epoch 2
train_metrics: 
R2: -25.92229461669922
MSE: 461541.9375
test metrics:
R2: -36.701744079589844
MSE: 597415.4375
MSE diff_p 2
----------
3: 0.04695955291390419
Training Epoch 3
train_metrics: 
R2: -10.730701446533203
MSE: 307552.25
test metrics:
R2: -14.602965354919434
MSE: 430293.09375
MSE diff_p 3
----------
4: 0.0349312461912632
Training Epoch 4
train_metrics: 
R2: -2.0346875190734863
MSE: 228775.21875
test metrics:
R2: -7.808079719543457
MSE: 399405.8125
MSE diff_p 4
----------
5: 0.020697515457868576
Training Epoch 5
train_metrics: 
R2: 0.2675156593322754
MSE: 135554.25
test metrics:
R2: -0.7617343664169312
MSE: 235509.78125
MSE diff_p 5
----------
6: 0.0713920071721077
Training Epoch 6
train_metrics: 
R2: -2.328439712524414
MSE: 467567.71875
test metrics:
R2: -3.5592570304870605
MSE: 508765.65625
MSE diff_p 6
----------
7: 0.021100599318742752
Training Epoch 7
train_metrics: 
R2: -0.24762392044067383
MSE: 138194.1875
test metrics:
R2: -0.07647264003753662
MSE: 161371.078125
MSE diff_p 7
----------
8: 0.01627986505627632
Training Epoch 8
train_metrics: 
R2: 0.6722229719161987
MSE: 106621.7265625
test metrics:
R2: 0.7292805910110474
MSE: 90969.9765625
MSE diff_p 8
----------
9: 0.01625843346118927
Training Epoch 9
train_metrics: 
R2: 0.6414101123809814
MSE: 106481.3671875
test metrics:
R2: 0.5499755144119263
MSE: 109248.6796875
MSE diff_p 9
----------
10: 0.02217353880405426
Training Epoch 10
train_metrics: 
R2: 0.4212162494659424
MSE: 145221.171875
test metrics:
R2: 0.09838122129440308
MSE: 201748.59375
MSE diff_p 10
----------
11: 0.012482688762247562
Training Epoch 11
train_metrics: 
R2: 0.6233494281768799
MSE: 81752.8828125
test metrics:
R2: 0.6181055307388306
MSE: 101716.171875
MSE diff_p 11
----------
12: 0.007916748523712158
Training Epoch 12
train_metrics: 
R2: 0.8529711961746216
MSE: 51849.1640625
test metrics:
R2: 0.8718611001968384
MSE: 45547.70703125
MSE diff_p 12
----------
13: 0.013240068219602108
Training Epoch 13
train_metrics: 
R2: 0.7981867790222168
MSE: 86713.1875
test metrics:
R2: 0.8141170740127563
MSE: 78634.8828125
MSE diff_p 13
----------
14: 0.010678669437766075
Training Epoch 14
train_metrics: 
R2: 0.7562187910079956
MSE: 69937.8203125
test metrics:
R2: 0.6893035173416138
MSE: 84113.1171875
MSE diff_p 14
----------
15: 0.00930953212082386
Training Epoch 15
train_metrics: 
R2: 0.869840145111084
MSE: 60970.921875
test metrics:
R2: 0.8310889601707458
MSE: 68536.28125
MSE diff_p 15
----------
16: 0.005232402589172125
Training Epoch 16
train_metrics: 
R2: 0.8811039328575134
MSE: 34268.578125
test metrics:
R2: 0.809831976890564
MSE: 57274.140625
MSE diff_p 16
----------
17: 0.0046288371086120605
Training Epoch 17
train_metrics: 
R2: 0.9276100397109985
MSE: 30315.646484375
test metrics:
R2: 0.9090788960456848
MSE: 40204.6171875
MSE diff_p 17
----------
18: 0.0023036326747387648
Training Epoch 18
train_metrics: 
R2: 0.9561219215393066
MSE: 15087.18359375
test metrics:
R2: 0.9210188388824463
MSE: 30745.654296875
MSE diff_p 18
----------
19: 0.0026832404546439648
Training Epoch 19
train_metrics: 
R2: 0.9535725116729736
MSE: 17573.349609375
test metrics:
R2: 0.9107683897018433
MSE: 33865.9140625
MSE diff_p 19
----------
20: 0.0019232610939070582
Training Epoch 20
train_metrics: 
R2: 0.9681888222694397
MSE: 12596.0166015625
test metrics:
R2: 0.9380414485931396
MSE: 26036.517578125
MSE diff_p 20
----------
21: 0.0023011425510048866
Training Epoch 21
train_metrics: 
R2: 0.9596405625343323
MSE: 15070.8759765625
test metrics:
R2: 0.9317009449005127
MSE: 27157.576171875
MSE diff_p 21
----------
22: 0.002173877786844969
Training Epoch 22
train_metrics: 
R2: 0.9653128981590271
MSE: 14237.37890625
test metrics:
R2: 0.9314103722572327
MSE: 27358.828125
MSE diff_p 22
----------
23: 0.002004496054723859
Training Epoch 23
train_metrics: 
R2: 0.9680125117301941
MSE: 13128.046875
test metrics:
R2: 0.9391851425170898
MSE: 25270.591796875
MSE diff_p 23
----------
24: 0.001857999013736844
Training Epoch 24
train_metrics: 
R2: 0.9632040858268738
MSE: 12168.59375
test metrics:
R2: 0.9360003471374512
MSE: 25590.056640625
MSE diff_p 24
----------
25: 0.001759071135893464
Training Epoch 25
train_metrics: 
R2: 0.9705430865287781
MSE: 11520.685546875
test metrics:
R2: 0.9421289563179016
MSE: 24090.51953125
MSE diff_p 25
----------
26: 0.0012838217662647367
Training Epoch 26
train_metrics: 
R2: 0.9772943258285522
MSE: 8408.134765625
test metrics:
R2: 0.9380334615707397
MSE: 24930.080078125
MSE diff_p 26
----------
27: 0.0019259947584941983
Training Epoch 27
train_metrics: 
R2: 0.9636138081550598
MSE: 12613.91796875
test metrics:
R2: 0.9432602524757385
MSE: 23333.494140625
MSE diff_p 27
----------
28: 0.0015076937852427363
Training Epoch 28
train_metrics: 
R2: 0.9738909006118774
MSE: 9874.33984375
test metrics:
R2: 0.9416157603263855
MSE: 24050.21484375
MSE diff_p 28
----------
29: 0.0015934417024254799
Training Epoch 29
train_metrics: 
R2: 0.9719149470329285
MSE: 10435.9296875
test metrics:
R2: 0.9445632696151733
MSE: 22566.91796875
MSE diff_p 29
----------
30: 0.001747559173963964
Training Epoch 30
train_metrics: 
R2: 0.9708206653594971
MSE: 11445.2919921875
test metrics:
R2: 0.9470940232276917
MSE: 22633.5703125
MSE diff_p 30
----------
31: 0.0016527833649888635
Training Epoch 31
train_metrics: 
R2: 0.9683931469917297
MSE: 10824.57421875
test metrics:
R2: 0.9417268633842468
MSE: 23115.080078125
MSE diff_p 31
----------
32: 0.0016365032643079758
Training Epoch 32
train_metrics: 
R2: 0.9703671932220459
MSE: 10717.951171875
test metrics:
R2: 0.9429956078529358
MSE: 23940.564453125
MSE diff_p 32
----------
33: 0.0017545325681567192
Training Epoch 33
train_metrics: 
R2: 0.9698931574821472
MSE: 11490.9609375
test metrics:
R2: 0.9444299340248108
MSE: 22367.650390625
MSE diff_p 33
----------
34: 0.001981263980269432
Training Epoch 34
train_metrics: 
R2: 0.9660556316375732
MSE: 12975.8935546875
test metrics:
R2: 0.939863920211792
MSE: 24623.486328125
MSE diff_p 34
----------
35: 0.002087119733914733
Training Epoch 35
train_metrics: 
R2: 0.9628149271011353
MSE: 13669.17578125
test metrics:
R2: 0.9531593918800354
MSE: 19911.857421875
MSE diff_p 35
----------
36: 0.0019367296481505036
Training Epoch 36
train_metrics: 
R2: 0.9664337635040283
MSE: 12684.2236328125
test metrics:
R2: 0.9453786611557007
MSE: 23225.35546875
MSE diff_p 36
----------
37: 0.0018052582163363695
Training Epoch 37
train_metrics: 
R2: 0.971829354763031
MSE: 11823.1787109375
test metrics:
R2: 0.9522994756698608
MSE: 20096.11328125
MSE diff_p 37
----------
38: 0.0021855169907212257
Training Epoch 38
train_metrics: 
R2: 0.963482141494751
MSE: 14313.609375
test metrics:
R2: 0.9443988800048828
MSE: 23444.357421875
MSE diff_p 38
----------
39: 0.0018341345712542534
Training Epoch 39
train_metrics: 
R2: 0.9680684208869934
MSE: 12012.298828125
test metrics:
R2: 0.955841600894928
MSE: 19074.87109375
MSE diff_p 39
----------
40: 0.0024365801364183426
Training Epoch 40
train_metrics: 
R2: 0.9551554322242737
MSE: 15957.8955078125
test metrics:
R2: 0.9376468062400818
MSE: 25790.98046875
MSE diff_p 40
----------
41: 0.002292799996212125
Training Epoch 41
train_metrics: 
R2: 0.9624386429786682
MSE: 15016.23828125
test metrics:
R2: 0.9566702842712402
MSE: 19409.48046875
MSE diff_p 41
----------
42: 0.0028074048459529877
Training Epoch 42
train_metrics: 
R2: 0.950039267539978
MSE: 18386.5390625
test metrics:
R2: 0.9378551244735718
MSE: 26969.119140625
MSE diff_p 42
----------
43: 0.0029722414910793304
Training Epoch 43
train_metrics: 
R2: 0.945881724357605
MSE: 19466.10546875
test metrics:
R2: 0.9534677863121033
MSE: 20153.65234375
MSE diff_p 43
----------
44: 0.0032211944926530123
Training Epoch 44
train_metrics: 
R2: 0.9403860569000244
MSE: 21096.57421875
test metrics:
R2: 0.9322712421417236
MSE: 28393.00390625
MSE diff_p 44
----------
45: 0.00262353103607893
Training Epoch 45
train_metrics: 
R2: 0.9537875652313232
MSE: 17182.294921875
test metrics:
R2: 0.9568659067153931
MSE: 19181.498046875
MSE diff_p 45
----------
46: 0.0020473292097449303
Training Epoch 46
train_metrics: 
R2: 0.9636468291282654
MSE: 13408.57421875
test metrics:
R2: 0.9363369941711426
MSE: 26001.232421875
MSE diff_p 46
----------
47: 0.0014154963428154588
Training Epoch 47
train_metrics: 
R2: 0.975827693939209
MSE: 9270.51171875
test metrics:
R2: 0.960199236869812
MSE: 17483.103515625
MSE diff_p 47
----------
48: 0.0014814049936830997
Training Epoch 48
train_metrics: 
R2: 0.9715251326560974
MSE: 9702.166015625
test metrics:
R2: 0.954150915145874
MSE: 19374.86328125
MSE diff_p 48
----------
49: 0.0013494124868884683
Training Epoch 49
train_metrics: 
R2: 0.9749760031700134
MSE: 8837.7080078125
test metrics:
R2: 0.9598433971405029
MSE: 17353.3203125
MSE diff_p 49
----------
50: 0.0014481579419225454
Training Epoch 50
train_metrics: 
R2: 0.9739864468574524
MSE: 9484.421875
test metrics:
R2: 0.9531142115592957
MSE: 19550.654296875
MSE diff_p 50
----------
51: 0.0015374659560620785
Training Epoch 51
train_metrics: 
R2: 0.9723211526870728
MSE: 10069.326171875
test metrics:
R2: 0.962583601474762
MSE: 16524.744140625
MSE diff_p 51
----------
52: 0.0015647265827283263
Training Epoch 52
train_metrics: 
R2: 0.9742770195007324
MSE: 10247.8642578125
test metrics:
R2: 0.9517730474472046
MSE: 19847.458984375
MSE diff_p 52
----------
53: 0.0023021462839096785
Training Epoch 53
train_metrics: 
R2: 0.9636109471321106
MSE: 15077.44921875
test metrics:
R2: 0.9624464511871338
MSE: 16418.5078125
MSE diff_p 53
----------
54: 0.0014246858190745115
Training Epoch 54
train_metrics: 
R2: 0.9750188589096069
MSE: 9330.6962890625
test metrics:
R2: 0.9522120952606201
MSE: 20394.880859375
MSE diff_p 54
----------
55: 0.0014602631563320756
Training Epoch 55
train_metrics: 
R2: 0.9753004312515259
MSE: 9563.701171875
test metrics:
R2: 0.9596099853515625
MSE: 17227.0859375
MSE diff_p 55
----------
56: 0.0016219798708334565
Training Epoch 56
train_metrics: 
R2: 0.9722626805305481
MSE: 10622.833984375
test metrics:
R2: 0.9608643651008606
MSE: 17819.41015625
MSE diff_p 56
----------
57: 0.002005538670346141
Training Epoch 57
train_metrics: 
R2: 0.9639342427253723
MSE: 13134.875
test metrics:
R2: 0.9548670649528503
MSE: 18663.91015625
MSE diff_p 57
----------
58: 0.0019175976049154997
Training Epoch 58
train_metrics: 
R2: 0.9690877199172974
MSE: 12558.921875
test metrics:
R2: 0.9552409648895264
MSE: 19616.126953125
MSE diff_p 58
----------
59: 0.002185999881476164
Training Epoch 59
train_metrics: 
R2: 0.9607622027397156
MSE: 14316.76953125
test metrics:
R2: 0.9570028185844421
MSE: 17975.0625
MSE diff_p 59
----------
60: 0.00413042027503252
Training Epoch 60
train_metrics: 
R2: 0.9377256035804749
MSE: 27051.36328125
test metrics:
R2: 0.9533827900886536
MSE: 20976.900390625
MSE diff_p 60
----------
61: 0.001448908937163651
Training Epoch 61
train_metrics: 
R2: 0.9766668677330017
MSE: 9489.3388671875
test metrics:
R2: 0.9594328999519348
MSE: 17080.34765625
MSE diff_p 61
----------
62: 0.0018111716490238905
Training Epoch 62
train_metrics: 
R2: 0.9679827094078064
MSE: 11861.9091796875
test metrics:
R2: 0.9488162994384766
MSE: 21219.30078125
MSE diff_p 62
----------
63: 0.002001177752390504
Training Epoch 63
train_metrics: 
R2: 0.9677110910415649
MSE: 13106.3125
test metrics:
R2: 0.9653469324111938
MSE: 15894.4765625
MSE diff_p 63
----------
64: 0.0019594854675233364
Training Epoch 64
train_metrics: 
R2: 0.9597644209861755
MSE: 12833.2607421875
test metrics:
R2: 0.9444231390953064
MSE: 22793.677734375
MSE diff_p 64
----------
65: 0.0022413255646824837
Training Epoch 65
train_metrics: 
R2: 0.9645272493362427
MSE: 14679.115234375
test metrics:
R2: 0.9654449820518494
MSE: 15817.86328125
MSE diff_p 65
----------
66: 0.001884331926703453
Training Epoch 66
train_metrics: 
R2: 0.9643762707710266
MSE: 12341.0546875
test metrics:
R2: 0.9499831199645996
MSE: 21463.98828125
MSE diff_p 66
----------
67: 0.001729120616801083
Training Epoch 67
train_metrics: 
R2: 0.9735860824584961
MSE: 11324.529296875
test metrics:
R2: 0.9676513075828552
MSE: 14708.873046875
MSE diff_p 67
----------
68: 0.0014522678684443235
Training Epoch 68
train_metrics: 
R2: 0.9754046201705933
MSE: 9511.3388671875
test metrics:
R2: 0.95224529504776
MSE: 19948.166015625
MSE diff_p 68
----------
69: 0.0012155239237472415
Training Epoch 69
train_metrics: 
R2: 0.9799712896347046
MSE: 7960.83203125
test metrics:
R2: 0.9687439799308777
MSE: 14248.5498046875
MSE diff_p 69
----------
70: 0.0015039800200611353
Training Epoch 70
train_metrics: 
R2: 0.9742444753646851
MSE: 9850.0185546875
test metrics:
R2: 0.9643155932426453
MSE: 15855.84375
MSE diff_p 70
----------
71: 0.0010260591516271234
Training Epoch 71
train_metrics: 
R2: 0.9831950068473816
MSE: 6719.97021484375
test metrics:
R2: 0.9634994268417358
MSE: 15543.16796875
MSE diff_p 71
----------
72: 0.0011906959116458893
Training Epoch 72
train_metrics: 
R2: 0.9817330837249756
MSE: 7798.2265625
test metrics:
R2: 0.9675161242485046
MSE: 14677.775390625
MSE diff_p 72
----------
73: 0.001471092808060348
Training Epoch 73
train_metrics: 
R2: 0.9712340235710144
MSE: 9634.6298828125
test metrics:
R2: 0.9679966568946838
MSE: 14122.638671875
MSE diff_p 73
----------
74: 0.001318944850936532
Training Epoch 74
train_metrics: 
R2: 0.9727658629417419
MSE: 8638.166015625
test metrics:
R2: 0.9604084491729736
MSE: 16689.7109375
MSE diff_p 74
----------
75: 0.0018040994182229042
Training Epoch 75
train_metrics: 
R2: 0.9711586833000183
MSE: 11815.58984375
test metrics:
R2: 0.9715946912765503
MSE: 13414.3544921875
MSE diff_p 75
----------
76: 0.0019165147095918655
Training Epoch 76
train_metrics: 
R2: 0.9665283560752869
MSE: 12551.8291015625
test metrics:
R2: 0.953018307685852
MSE: 20334.275390625
MSE diff_p 76
----------
77: 0.002074104268103838
Training Epoch 77
train_metrics: 
R2: 0.9669090509414673
MSE: 13583.9326171875
test metrics:
R2: 0.9703546166419983
MSE: 14054.4130859375
MSE diff_p 77
----------
78: 0.0018891154322773218
Training Epoch 78
train_metrics: 
R2: 0.9674813747406006
MSE: 12372.384765625
test metrics:
R2: 0.96109539270401
MSE: 17581.134765625
MSE diff_p 78
----------
79: 0.001838155323639512
Training Epoch 79
train_metrics: 
R2: 0.9661381840705872
MSE: 12038.630859375
test metrics:
R2: 0.965314507484436
MSE: 15083.7451171875
MSE diff_p 79
----------
80: 0.001745163113810122
Training Epoch 80
train_metrics: 
R2: 0.9734386205673218
MSE: 11429.59765625
test metrics:
R2: 0.9579522609710693
MSE: 19234.3671875
MSE diff_p 80
----------
81: 0.001639061258174479
Training Epoch 81
train_metrics: 
R2: 0.9715483784675598
MSE: 10734.705078125
test metrics:
R2: 0.9681630730628967
MSE: 14264.55859375
MSE diff_p 81
----------
82: 0.0018152210395783186
Training Epoch 82
train_metrics: 
R2: 0.9699956178665161
MSE: 11888.427734375
test metrics:
R2: 0.9605584144592285
MSE: 17965.904296875
MSE diff_p 82
----------
83: 0.0015151930274441838
Training Epoch 83
train_metrics: 
R2: 0.9721580147743225
MSE: 9923.455078125
test metrics:
R2: 0.9671326279640198
MSE: 14449.0283203125
MSE diff_p 83
----------
84: 0.0019151499727740884
Training Epoch 84
train_metrics: 
R2: 0.9682059288024902
MSE: 12542.89453125
test metrics:
R2: 0.9608164429664612
MSE: 17675.94140625
MSE diff_p 84
----------
85: 0.0014973640209063888
Training Epoch 85
train_metrics: 
R2: 0.9728959202766418
MSE: 9806.6865234375
test metrics:
R2: 0.9642019867897034
MSE: 15357.33984375
MSE diff_p 85
----------
86: 0.001392496400512755
Training Epoch 86
train_metrics: 
R2: 0.9779133796691895
MSE: 9119.8779296875
test metrics:
R2: 0.9665363430976868
MSE: 15477.4736328125
MSE diff_p 86
----------
87: 0.0013073707232251763
Training Epoch 87
train_metrics: 
R2: 0.976800799369812
MSE: 8562.36328125
test metrics:
R2: 0.9694787263870239
MSE: 13676.484375
MSE diff_p 87
----------
88: 0.0016098024789243937
Training Epoch 88
train_metrics: 
R2: 0.9710507988929749
MSE: 10543.0830078125
test metrics:
R2: 0.963839590549469
MSE: 16050.25
MSE diff_p 88
----------
89: 0.00161686260253191
Training Epoch 89
train_metrics: 
R2: 0.974011242389679
MSE: 10589.3193359375
test metrics:
R2: 0.9725055694580078
MSE: 12754.2724609375
MSE diff_p 89
----------
90: 0.0015255329199135303
Training Epoch 90
train_metrics: 
R2: 0.9739169478416443
MSE: 9991.173828125
test metrics:
R2: 0.9638190269470215
MSE: 15783.044921875
MSE diff_p 90
----------
91: 0.0013862403575330973
Training Epoch 91
train_metrics: 
R2: 0.9777805805206299
MSE: 9078.904296875
test metrics:
R2: 0.9721526503562927
MSE: 12939.06640625
MSE diff_p 91
----------
92: 0.0011791548458859324
Training Epoch 92
train_metrics: 
R2: 0.9783955216407776
MSE: 7722.6396484375
test metrics:
R2: 0.9661529660224915
MSE: 14941.4052734375
MSE diff_p 92
----------
93: 0.0016159770311787724
Training Epoch 93
train_metrics: 
R2: 0.9732545614242554
MSE: 10583.5205078125
test metrics:
R2: 0.9710195064544678
MSE: 13426.400390625
MSE diff_p 93
----------
94: 0.002270359778776765
Training Epoch 94
train_metrics: 
R2: 0.9613258242607117
MSE: 14869.26953125
test metrics:
R2: 0.9552400708198547
MSE: 19308.880859375
MSE diff_p 94
----------
95: 0.0023643451277166605
Training Epoch 95
train_metrics: 
R2: 0.9641433358192444
MSE: 15484.80859375
test metrics:
R2: 0.9639641046524048
MSE: 16717.4296875
MSE diff_p 95
----------
96: 0.0024099128786474466
Training Epoch 96
train_metrics: 
R2: 0.9532618522644043
MSE: 15783.2431640625
test metrics:
R2: 0.9493533372879028
MSE: 21110.6640625
MSE diff_p 96
----------
97: 0.0024322709068655968
Training Epoch 97
train_metrics: 
R2: 0.9523540139198303
MSE: 15929.673828125
test metrics:
R2: 0.9646261930465698
MSE: 16296.1962890625
MSE diff_p 97
----------
98: 0.003406642470508814
Training Epoch 98
train_metrics: 
R2: 0.9389932155609131
MSE: 22311.12890625
test metrics:
R2: 0.9497590065002441
MSE: 21484.083984375
MSE diff_p 98
----------
99: 0.0020546317100524902
Training Epoch 99
train_metrics: 
R2: 0.9640322923660278
MSE: 13456.400390625
test metrics:
R2: 0.959157407283783
MSE: 17626.5390625
MSE diff_p 99
----------
100: 0.001992408186197281
Training Epoch 100
train_metrics: 
R2: 0.9650043249130249
MSE: 13048.8798828125
test metrics:
R2: 0.963510274887085
MSE: 17007.197265625
MSE diff_p 100
----------
101: 0.0016193848568946123
Training Epoch 101
train_metrics: 
R2: 0.973112165927887
MSE: 10605.83984375
test metrics:
R2: 0.9550020694732666
MSE: 18452.693359375
MSE diff_p 101
----------
102: 0.0016471792478114367
Training Epoch 102
train_metrics: 
R2: 0.9730736613273621
MSE: 10787.8720703125
test metrics:
R2: 0.9670829772949219
MSE: 15130.955078125
MSE diff_p 102
----------
103: 0.0012849787017330527
Training Epoch 103
train_metrics: 
R2: 0.9804571866989136
MSE: 8415.7119140625
test metrics:
R2: 0.9684856534004211
MSE: 14074.337890625
MSE diff_p 103
----------
104: 0.001573005341924727
Training Epoch 104
train_metrics: 
R2: 0.9725316166877747
MSE: 10302.083984375
test metrics:
R2: 0.9550963044166565
MSE: 18310.1875
MSE diff_p 104
----------
105: 0.0018622606294229627
Training Epoch 105
train_metrics: 
R2: 0.9717575907707214
MSE: 12196.505859375
test metrics:
R2: 0.9726004600524902
MSE: 13228.376953125
MSE diff_p 105
----------
106: 0.0011611436493694782
Training Epoch 106
train_metrics: 
R2: 0.9789677262306213
MSE: 7604.68017578125
test metrics:
R2: 0.9622422456741333
MSE: 15731.962890625
MSE diff_p 106
----------
107: 0.0013205624418333173
Training Epoch 107
train_metrics: 
R2: 0.9792101383209229
MSE: 8648.759765625
test metrics:
R2: 0.972733736038208
MSE: 12498.08203125
MSE diff_p 107
----------
108: 0.001313469954766333
Training Epoch 108
train_metrics: 
R2: 0.9794528484344482
MSE: 8602.310546875
test metrics:
R2: 0.960559606552124
MSE: 16191.1162109375
MSE diff_p 108
----------
109: 0.0013589449226856232
Training Epoch 109
train_metrics: 
R2: 0.9800719618797302
MSE: 8900.138671875
test metrics:
R2: 0.9740203022956848
MSE: 12640.1064453125
MSE diff_p 109
----------
110: 0.0013842250918969512
Training Epoch 110
train_metrics: 
R2: 0.9744521975517273
MSE: 9065.70703125
test metrics:
R2: 0.9611004590988159
MSE: 15939.1103515625
MSE diff_p 110
----------
111: 0.0009273618343286216
Training Epoch 111
train_metrics: 
R2: 0.9844505190849304
MSE: 6073.5712890625
test metrics:
R2: 0.9754855036735535
MSE: 11807.79296875
MSE diff_p 111
----------
112: 0.001060818089172244
Training Epoch 112
train_metrics: 
R2: 0.9796865582466125
MSE: 6947.6162109375
test metrics:
R2: 0.9615795016288757
MSE: 15730.39453125
MSE diff_p 112
----------
113: 0.0016815143171697855
Training Epoch 113
train_metrics: 
R2: 0.9750328660011292
MSE: 11012.7421875
test metrics:
R2: 0.9743102788925171
MSE: 12061.861328125
MSE diff_p 113
----------
114: 0.0010513650486245751
Training Epoch 114
train_metrics: 
R2: 0.9805279970169067
MSE: 6885.70458984375
test metrics:
R2: 0.9719648361206055
MSE: 12465.1630859375
MSE diff_p 114
----------
115: 0.0009633066365495324
Training Epoch 115
train_metrics: 
R2: 0.9835578799247742
MSE: 6308.984375
test metrics:
R2: 0.9709619283676147
MSE: 12770.4404296875
MSE diff_p 115
----------
116: 0.0013217107625678182
Training Epoch 116
train_metrics: 
R2: 0.9773659110069275
MSE: 8656.2802734375
test metrics:
R2: 0.9712496399879456
MSE: 12893.623046875
MSE diff_p 116
----------
117: 0.001735782832838595
Training Epoch 117
train_metrics: 
R2: 0.9705531001091003
MSE: 11368.1640625
test metrics:
R2: 0.9641852974891663
MSE: 15674.7666015625
MSE diff_p 117
----------
118: 0.0029543444979935884
Training Epoch 118
train_metrics: 
R2: 0.9473242163658142
MSE: 19348.890625
test metrics:
R2: 0.9560422301292419
MSE: 19840.75
MSE diff_p 118
----------
119: 0.004943806678056717
Training Epoch 119
train_metrics: 
R2: 0.9136157035827637
MSE: 32378.47265625
test metrics:
R2: 0.9186700582504272
MSE: 32638.66015625
MSE diff_p 119
----------
120: 0.003207902889698744
Training Epoch 120
train_metrics: 
R2: 0.9451555013656616
MSE: 21009.51953125
test metrics:
R2: 0.9641081690788269
MSE: 17155.923828125
MSE diff_p 120
----------
121: 0.0026018244680017233
Training Epoch 121
train_metrics: 
R2: 0.952521800994873
MSE: 17040.12890625
test metrics:
R2: 0.9603424668312073
MSE: 17823.390625
MSE diff_p 121
----------
122: 0.0020028171129524708
Training Epoch 122
train_metrics: 
R2: 0.9591169953346252
MSE: 13117.052734375
test metrics:
R2: 0.9531498551368713
MSE: 18726.857421875
MSE diff_p 122
----------
123: 0.00206399941816926
Training Epoch 123
train_metrics: 
R2: 0.9706792235374451
MSE: 13517.75390625
test metrics:
R2: 0.9714215397834778
MSE: 14174.599609375
MSE diff_p 123
----------
124: 0.0014079605462029576
Training Epoch 124
train_metrics: 
R2: 0.9754093885421753
MSE: 9221.15625
test metrics:
R2: 0.957237720489502
MSE: 17252.669921875
MSE diff_p 124
----------
125: 0.0014749803813174367
Training Epoch 125
train_metrics: 
R2: 0.9785516262054443
MSE: 9660.08984375
test metrics:
R2: 0.9731289744377136
MSE: 13070.33984375
MSE diff_p 125
----------
126: 0.001283156336285174
Training Epoch 126
train_metrics: 
R2: 0.9742962121963501
MSE: 8403.7763671875
test metrics:
R2: 0.9627300500869751
MSE: 15374.5166015625
MSE diff_p 126
----------
127: 0.0008750297129154205
Training Epoch 127
train_metrics: 
R2: 0.9859874844551086
MSE: 5730.83349609375
test metrics:
R2: 0.9731023907661438
MSE: 12277.8076171875
MSE diff_p 127
----------
128: 0.0009677485213615
Training Epoch 128
train_metrics: 
R2: 0.9824755191802979
MSE: 6338.07666015625
test metrics:
R2: 0.9689489603042603
MSE: 13416.3798828125
MSE diff_p 128
----------
129: 0.0010131357703357935
Training Epoch 129
train_metrics: 
R2: 0.9826991558074951
MSE: 6635.33154296875
test metrics:
R2: 0.9703847765922546
MSE: 12904.7373046875
MSE diff_p 129
----------
130: 0.001079570152796805
Training Epoch 130
train_metrics: 
R2: 0.9820392727851868
MSE: 7070.42919921875
test metrics:
R2: 0.9743041396141052
MSE: 11859.634765625
MSE diff_p 130
----------
131: 0.001087690470740199
Training Epoch 131
train_metrics: 
R2: 0.9791036248207092
MSE: 7123.61279296875
test metrics:
R2: 0.9636321067810059
MSE: 14998.75
MSE diff_p 131
----------
132: 0.0010706004686653614
Training Epoch 132
train_metrics: 
R2: 0.981954038143158
MSE: 7011.68408203125
test metrics:
R2: 0.9719938039779663
MSE: 12810.8779296875
MSE diff_p 132
----------
133: 0.0010693148942664266
Training Epoch 133
train_metrics: 
R2: 0.9806490540504456
MSE: 7003.263671875
test metrics:
R2: 0.9674972891807556
MSE: 14258.3037109375
MSE diff_p 133
----------
134: 0.0014549269108101726
Training Epoch 134
train_metrics: 
R2: 0.9734547138214111
MSE: 9528.75390625
test metrics:
R2: 0.9684346318244934
MSE: 14099.0966796875
MSE diff_p 134
----------
135: 0.0019071630667895079
Training Epoch 135
train_metrics: 
R2: 0.9660288095474243
MSE: 12490.5849609375
test metrics:
R2: 0.9575099945068359
MSE: 17890.953125
MSE diff_p 135
----------
136: 0.002202675212174654
Training Epoch 136
train_metrics: 
R2: 0.9661429524421692
MSE: 14425.982421875
test metrics:
R2: 0.9697376489639282
MSE: 14526.3564453125
MSE diff_p 136
----------
137: 0.002441258868202567
Training Epoch 137
train_metrics: 
R2: 0.9532912969589233
MSE: 15988.537109375
test metrics:
R2: 0.951261043548584
MSE: 20026.0859375
MSE diff_p 137
----------
138: 0.0020206181798130274
Training Epoch 138
train_metrics: 
R2: 0.9653044939041138
MSE: 13233.6357421875
test metrics:
R2: 0.9659279584884644
MSE: 15582.1630859375
MSE diff_p 138
----------
139: 0.001988505944609642
Training Epoch 139
train_metrics: 
R2: 0.965742826461792
MSE: 13023.322265625
test metrics:
R2: 0.967341423034668
MSE: 14668.8447265625
MSE diff_p 139
----------
140: 0.0016836316790431738
Training Epoch 140
train_metrics: 
R2: 0.9680005311965942
MSE: 11026.6103515625
test metrics:
R2: 0.9485241174697876
MSE: 20535.162109375
MSE diff_p 140
----------
141: 0.0015787719748914242
Training Epoch 141
train_metrics: 
R2: 0.9779866933822632
MSE: 10339.8525390625
test metrics:
R2: 0.9728319644927979
MSE: 13217.646484375
MSE diff_p 141
----------
142: 0.0012142180930823088
Training Epoch 142
train_metrics: 
R2: 0.976478636264801
MSE: 7952.279296875
test metrics:
R2: 0.9554309844970703
MSE: 17798.98046875
MSE diff_p 142
----------
143: 0.0012774302158504725
Training Epoch 143
train_metrics: 
R2: 0.9801942110061646
MSE: 8366.2734375
test metrics:
R2: 0.9736887216567993
MSE: 12517.45703125
MSE diff_p 143
----------
144: 0.0013386390637606382
Training Epoch 144
train_metrics: 
R2: 0.9747549891471863
MSE: 8767.1494140625
test metrics:
R2: 0.9538640975952148
MSE: 18614.458984375
MSE diff_p 144
----------
145: 0.0016280311392620206
Training Epoch 145
train_metrics: 
R2: 0.9726086258888245
MSE: 10662.4658203125
test metrics:
R2: 0.9725561141967773
MSE: 13059.7236328125
MSE diff_p 145
----------
146: 0.0012551808031275868
Training Epoch 146
train_metrics: 
R2: 0.9751797318458557
MSE: 8220.556640625
test metrics:
R2: 0.9476796388626099
MSE: 19989.00390625
MSE diff_p 146
----------
147: 0.001661186572164297
Training Epoch 147
train_metrics: 
R2: 0.9759079217910767
MSE: 10879.6103515625
test metrics:
R2: 0.9734894633293152
MSE: 12737.599609375
MSE diff_p 147
----------
148: 0.0015832067001610994
Training Epoch 148
train_metrics: 
R2: 0.9695768356323242
MSE: 10368.89453125
test metrics:
R2: 0.9403620958328247
MSE: 21826.337890625
MSE diff_p 148
----------
149: 0.0016387667274102569
Training Epoch 149
train_metrics: 
R2: 0.9774096012115479
MSE: 10732.775390625
test metrics:
R2: 0.9722450375556946
MSE: 14155.0986328125
MSE diff_p 149
----------
150: 0.001265853294171393
Training Epoch 150
train_metrics: 
R2: 0.9750296473503113
MSE: 8290.453125
test metrics:
R2: 0.9589635133743286
MSE: 16422.6796875
MSE diff_p 150
----------
151: 0.0014287680387496948
Training Epoch 151
train_metrics: 
R2: 0.9767330288887024
MSE: 9357.431640625
test metrics:
R2: 0.9747743606567383
MSE: 11711.771484375
MSE diff_p 151
----------
152: 0.0009566579828970134
Training Epoch 152
train_metrics: 
R2: 0.9828574061393738
MSE: 6265.4404296875
test metrics:
R2: 0.9676925539970398
MSE: 13556.8759765625
MSE diff_p 152
----------
153: 0.0012324076378718019
Training Epoch 153
train_metrics: 
R2: 0.9789295792579651
MSE: 8071.408203125
test metrics:
R2: 0.9732541441917419
MSE: 12195.7529296875
MSE diff_p 153
----------
154: 0.0012842866126447916
Training Epoch 154
train_metrics: 
R2: 0.9765430688858032
MSE: 8411.1787109375
test metrics:
R2: 0.9659847021102905
MSE: 14313.8017578125
MSE diff_p 154
----------
155: 0.002721653552725911
Training Epoch 155
train_metrics: 
R2: 0.953782320022583
MSE: 17824.927734375
test metrics:
R2: 0.9537862539291382
MSE: 20553.962890625
MSE diff_p 155
----------
156: 0.00506926653906703
Training Epoch 156
train_metrics: 
R2: 0.9110714197158813
MSE: 33200.15234375
test metrics:
R2: 0.9360885620117188
MSE: 26622.095703125
MSE diff_p 156
----------
157: 0.0054674213752150536
Training Epoch 157
train_metrics: 
R2: 0.9141441583633423
MSE: 35807.7890625
test metrics:
R2: 0.9455091953277588
MSE: 27002.142578125
MSE diff_p 157
----------
158: 0.003549559973180294
Training Epoch 158
train_metrics: 
R2: 0.9288552403450012
MSE: 23247.130859375
test metrics:
R2: 0.9297290444374084
MSE: 27646.767578125
MSE diff_p 158
----------
159: 0.0016666940646246076
Training Epoch 159
train_metrics: 
R2: 0.9719298481941223
MSE: 10915.681640625
test metrics:
R2: 0.9701696634292603
MSE: 14131.2451171875
MSE diff_p 159
----------
160: 0.0013055683812126517
Training Epoch 160
train_metrics: 
R2: 0.9755182862281799
MSE: 8550.560546875
test metrics:
R2: 0.9701429009437561
MSE: 13217.2412109375
MSE diff_p 160
----------
161: 0.0011082991259172559
Training Epoch 161
train_metrics: 
R2: 0.9806296825408936
MSE: 7258.583984375
test metrics:
R2: 0.9761958122253418
MSE: 10998.142578125
MSE diff_p 161
----------
162: 0.0014610205544158816
Training Epoch 162
train_metrics: 
R2: 0.9759919047355652
MSE: 9568.6630859375
test metrics:
R2: 0.9763503074645996
MSE: 10920.3095703125
MSE diff_p 162
----------
163: 0.0015766629949212074
Training Epoch 163
train_metrics: 
R2: 0.9695918560028076
MSE: 10326.0400390625
test metrics:
R2: 0.9771520495414734
MSE: 10456.0888671875
MSE diff_p 163
----------
164: 0.0009968080557882786
Training Epoch 164
train_metrics: 
R2: 0.9833295345306396
MSE: 6528.3955078125
test metrics:
R2: 0.9779669046401978
MSE: 10538.326171875
MSE diff_p 164
----------
165: 0.0009469956276006997
Training Epoch 165
train_metrics: 
R2: 0.9837085008621216
MSE: 6202.1591796875
test metrics:
R2: 0.9738698601722717
MSE: 11589.1650390625
MSE diff_p 165
----------
166: 0.0014154320815578103
Training Epoch 166
train_metrics: 
R2: 0.9761379361152649
MSE: 9270.091796875
test metrics:
R2: 0.9768618941307068
MSE: 11637.240234375
MSE diff_p 166
----------
167: 0.0013974772300571203
Training Epoch 167
train_metrics: 
R2: 0.975918710231781
MSE: 9152.4970703125
test metrics:
R2: 0.968090832233429
MSE: 13875.2412109375
MSE diff_p 167
----------
168: 0.0015039469581097364
Training Epoch 168
train_metrics: 
R2: 0.9770947098731995
MSE: 9849.802734375
test metrics:
R2: 0.9746522307395935
MSE: 12713.3681640625
MSE diff_p 168
----------
169: 0.0011315300362184644
Training Epoch 169
train_metrics: 
R2: 0.9770371317863464
MSE: 7410.7314453125
test metrics:
R2: 0.9545910954475403
MSE: 18123.21484375
MSE diff_p 169
----------
170: 0.0017093028873205185
Training Epoch 170
train_metrics: 
R2: 0.9742642641067505
MSE: 11194.7373046875
test metrics:
R2: 0.9756864905357361
MSE: 12407.365234375
MSE diff_p 170
----------
171: 0.0015516129788011312
Training Epoch 171
train_metrics: 
R2: 0.9671351313591003
MSE: 10161.978515625
test metrics:
R2: 0.9479899406433105
MSE: 20458.22265625
MSE diff_p 171
----------
172: 0.002254264196380973
Training Epoch 172
train_metrics: 
R2: 0.9660702347755432
MSE: 14763.85546875
test metrics:
R2: 0.9730303287506104
MSE: 13194.9208984375
MSE diff_p 172
----------
173: 0.0017208990175276995
Training Epoch 173
train_metrics: 
R2: 0.9653235673904419
MSE: 11270.685546875
test metrics:
R2: 0.9420723915100098
MSE: 21913.189453125
MSE diff_p 173
----------
174: 0.0015452206134796143
Training Epoch 174
train_metrics: 
R2: 0.976943850517273
MSE: 10120.115234375
test metrics:
R2: 0.9744343757629395
MSE: 12594.5048828125
MSE diff_p 174
----------
175: 0.0013510952703654766
Training Epoch 175
train_metrics: 
R2: 0.9721669554710388
MSE: 8848.7294921875
test metrics:
R2: 0.9460200667381287
MSE: 20349.376953125
MSE diff_p 175
----------
176: 0.001570004504173994
Training Epoch 176
train_metrics: 
R2: 0.9749147891998291
MSE: 10282.4326171875
test metrics:
R2: 0.9724057912826538
MSE: 13246.939453125
MSE diff_p 176
----------
177: 0.0018724482506513596
Training Epoch 177
train_metrics: 
R2: 0.9617829918861389
MSE: 12263.2265625
test metrics:
R2: 0.9419663548469543
MSE: 21386.5390625
MSE diff_p 177
----------
178: 0.0018575484864413738
Training Epoch 178
train_metrics: 
R2: 0.9733067154884338
MSE: 12165.64453125
test metrics:
R2: 0.9685185551643372
MSE: 15844.150390625
MSE diff_p 178
----------
179: 0.001615813816897571
Training Epoch 179
train_metrics: 
R2: 0.9683297872543335
MSE: 10582.4501953125
test metrics:
R2: 0.9587323665618896
MSE: 16648.4140625
MSE diff_p 179
----------
180: 0.0026096913497895002
Training Epoch 180
train_metrics: 
R2: 0.9562073349952698
MSE: 17091.65234375
test metrics:
R2: 0.952846348285675
MSE: 21406.404296875
MSE diff_p 180
----------
181: 0.0038288990035653114
Training Epoch 181
train_metrics: 
R2: 0.9283992052078247
MSE: 25076.609375
test metrics:
R2: 0.9445914030075073
MSE: 23584.287109375
MSE diff_p 181
----------
182: 0.0027455436065793037
Training Epoch 182
train_metrics: 
R2: 0.9492409229278564
MSE: 17981.390625
test metrics:
R2: 0.9443930983543396
MSE: 23495.515625
MSE diff_p 182
----------
183: 0.001920738024637103
Training Epoch 183
train_metrics: 
R2: 0.9699887633323669
MSE: 12579.4921875
test metrics:
R2: 0.9676011800765991
MSE: 14757.6728515625
MSE diff_p 183
----------
184: 0.0015198001638054848
Training Epoch 184
train_metrics: 
R2: 0.970084547996521
MSE: 9953.62890625
test metrics:
R2: 0.9637554883956909
MSE: 15879.28125
MSE diff_p 184
----------
185: 0.0021232059225440025
Training Epoch 185
train_metrics: 
R2: 0.9649191498756409
MSE: 13905.5146484375
test metrics:
R2: 0.9674566388130188
MSE: 15147.43359375
MSE diff_p 185
----------
186: 0.0014866736019030213
Training Epoch 186
train_metrics: 
R2: 0.9742516279220581
MSE: 9736.673828125
test metrics:
R2: 0.9580540657043457
MSE: 17830.966796875
MSE diff_p 186
----------
187: 0.0009826235473155975
Training Epoch 187
train_metrics: 
R2: 0.9821068048477173
MSE: 6435.4970703125
test metrics:
R2: 0.9719948172569275
MSE: 12544.33984375
MSE diff_p 187
----------
188: 0.0013049743138253689
Training Epoch 188
train_metrics: 
R2: 0.9779053926467896
MSE: 8546.6689453125
test metrics:
R2: 0.9698556661605835
MSE: 13485.39453125
MSE diff_p 188
----------
189: 0.001346184522844851
Training Epoch 189
train_metrics: 
R2: 0.9789491891860962
MSE: 8816.5673828125
test metrics:
R2: 0.9745231866836548
MSE: 11676.20703125
MSE diff_p 189
----------
190: 0.0012348666787147522
Training Epoch 190
train_metrics: 
R2: 0.9767094254493713
MSE: 8087.513671875
test metrics:
R2: 0.9650793075561523
MSE: 14905.275390625
MSE diff_p 190
----------
191: 0.0011902638943865895
Training Epoch 191
train_metrics: 
R2: 0.9813258647918701
MSE: 7795.39501953125
test metrics:
R2: 0.9748011827468872
MSE: 11538.4052734375
MSE diff_p 191
----------
192: 0.0009615016751922667
Training Epoch 192
train_metrics: 
R2: 0.9842382073402405
MSE: 6297.16259765625
test metrics:
R2: 0.9671013355255127
MSE: 14039.396484375
MSE diff_p 192
----------
193: 0.0009208184201270342
Training Epoch 193
train_metrics: 
R2: 0.9865869283676147
MSE: 6030.716796875
test metrics:
R2: 0.9770544767379761
MSE: 11042.3017578125
MSE diff_p 193
----------
194: 0.0013749714707955718
Training Epoch 194
train_metrics: 
R2: 0.9726611971855164
MSE: 9005.1015625
test metrics:
R2: 0.9631346464157104
MSE: 14925.2685546875
MSE diff_p 194
----------
195: 0.0012993658892810345
Training Epoch 195
train_metrics: 
R2: 0.9792865514755249
MSE: 8509.939453125
test metrics:
R2: 0.9780873656272888
MSE: 10944.796875
MSE diff_p 195
----------
196: 0.0013183041010051966
Training Epoch 196
train_metrics: 
R2: 0.976551353931427
MSE: 8633.9697265625
test metrics:
R2: 0.960334837436676
MSE: 15792.1904296875
MSE diff_p 196
----------
197: 0.0019701297860592604
Training Epoch 197
train_metrics: 
R2: 0.9738269448280334
MSE: 12902.970703125
test metrics:
R2: 0.9759618639945984
MSE: 12565.0009765625
MSE diff_p 197
----------
198: 0.002016115700826049
Training Epoch 198
train_metrics: 
R2: 0.9577091336250305
MSE: 13204.150390625
test metrics:
R2: 0.95009845495224
MSE: 19600.595703125
MSE diff_p 198
----------
199: 0.0012541459873318672
Training Epoch 199
train_metrics: 
R2: 0.9831937551498413
MSE: 8213.779296875
test metrics:
R2: 0.9754852652549744
MSE: 12332.5087890625
MSE diff_p 199
----------
