==========================================
SLURM_CLUSTER_NAME = param-shivay
SLURM_JOB_ACCOUNT = comp_sci_engg
SLURM_JOB_ID = 1018351
SLURM_JOB_NAME = printjob
SLURM_JOB_NODELIST = cn167
SLURM_JOB_USER = soumyadeep.das.cse21.itbhu
SLURM_JOB_UID = 5621
SLURM_JOB_PARTITION = cpu
SLURM_TASK_PID = 37623
SLURM_SUBMIT_DIR = /home/soumyadeep.das.cse21.itbhu/quantum-ml/LexiQL
SLURM_CPUS_ON_NODE = 1
SLURM_NTASKS = 
SLURM_TASK_PID = 37623
==========================================
hello world
module loaded
env loaded
python is running
number of stocks: 506
args.num_latent=5
args.num_trash=5

 Training Encoder...

Encoder Loss: 0.057 Iteration: 20
Encoder Loss: 0.056 Iteration: 40
Encoder Loss: 0.057 Iteration: 60
Encoder Loss: 0.059 Iteration: 80
Encoder Loss: 0.06 Iteration: 100
Encoder Loss: 0.056 Iteration: 120
Encoder Loss: 0.057 Iteration: 140
Encoder Loss: 0.059 Iteration: 160
Encoder Loss: 0.052 Iteration: 180
Encoder Loss: 0.054 Iteration: 200
Encoder Loss: 0.051 Iteration: 220
Encoder Loss: 0.057 Iteration: 240
Encoder Loss: 0.055 Iteration: 260
Encoder Loss: 0.051 Iteration: 280
Encoder Loss: 0.057 Iteration: 300
Training Started... 
0: 0.1311461180448532
Training Epoch 0
train_metrics: 
R2: -9.775501251220703
MSE: 858915.25
MAPE: 0.5181278586387634
test metrics:
R2: -14.49368667602539
MSE: 1112145.875
MAPE: 0.6234121918678284
before val features
MSE diff_p 0
----------
1: 0.07003077864646912
Training Epoch 1
train_metrics: 
R2: -639.5411376953125
MSE: 458652.625
MAPE: 0.45637208223342896
test metrics:
R2: -856.752685546875
MSE: 590309.75
MAPE: 0.5509592890739441
MSE diff_p 1
----------
2: 0.047650352120399475
Training Epoch 2
train_metrics: 
R2: -57.1578483581543
MSE: 312076.46875
MAPE: 0.3817335069179535
test metrics:
R2: -94.29790496826172
MSE: 469199.90625
MAPE: 0.5054975152015686
MSE diff_p 2
----------
3: 0.04342574626207352
Training Epoch 3
train_metrics: 
R2: -23.069225311279297
MSE: 284408.25
MAPE: 0.353831946849823
test metrics:
R2: -30.9152889251709
MSE: 411298.65625
MAPE: 0.4746205508708954
MSE diff_p 3
----------
4: 0.05074317753314972
Training Epoch 4
train_metrics: 
R2: -43.524375915527344
MSE: 332332.34375
MAPE: 0.39053022861480713
test metrics:
R2: -92.84449005126953
MSE: 475044.96875
MAPE: 0.5034721493721008
MSE diff_p 4
----------
5: 0.04664171487092972
Training Epoch 5
train_metrics: 
R2: -53.12822341918945
MSE: 305470.5625
MAPE: 0.3837195634841919
test metrics:
R2: -39.73503875732422
MSE: 420511.15625
MAPE: 0.48736336827278137
MSE diff_p 5
----------
6: 0.042521294206380844
Training Epoch 6
train_metrics: 
R2: -11.34175968170166
MSE: 278484.78125
MAPE: 0.3565104603767395
test metrics:
R2: -17.18915367126465
MSE: 371189.3125
MAPE: 0.4593278467655182
MSE diff_p 6
----------
7: 0.033774007111787796
Training Epoch 7
train_metrics: 
R2: -5.965214729309082
MSE: 221196.09375
MAPE: 0.33869072794914246
test metrics:
R2: -7.729978561401367
MSE: 310949.5
MAPE: 0.43327027559280396
MSE diff_p 7
----------
8: 0.033469561487436295
Training Epoch 8
train_metrics: 
R2: -4.009159088134766
MSE: 219202.21875
MAPE: 0.326457142829895
test metrics:
R2: -6.463679313659668
MSE: 301751.28125
MAPE: 0.42456185817718506
MSE diff_p 8
----------
9: 0.026778824627399445
Training Epoch 9
train_metrics: 
R2: -2.6268138885498047
MSE: 175382.5625
MAPE: 0.2954263985157013
test metrics:
R2: -3.601840019226074
MSE: 261687.546875
MAPE: 0.4029153287410736
MSE diff_p 9
----------
10: 0.025377346202731133
Training Epoch 10
train_metrics: 
R2: -1.9139184951782227
MSE: 166203.875
MAPE: 0.29099902510643005
test metrics:
R2: -3.2463150024414062
MSE: 256084.3125
MAPE: 0.39692384004592896
MSE diff_p 10
----------
11: 0.022438475862145424
Training Epoch 11
train_metrics: 
R2: -1.0934839248657227
MSE: 146956.34375
MAPE: 0.2742411494255066
test metrics:
R2: -2.120490550994873
MSE: 230826.078125
MAPE: 0.38290277123451233
MSE diff_p 11
----------
12: 0.02155507355928421
Training Epoch 12
train_metrics: 
R2: -0.8932487964630127
MSE: 141170.65625
MAPE: 0.26517170667648315
test metrics:
R2: -1.9113168716430664
MSE: 226409.40625
MAPE: 0.37679582834243774
MSE diff_p 12
----------
13: 0.025241438299417496
Training Epoch 13
train_metrics: 
R2: -0.8305294513702393
MSE: 165313.75
MAPE: 0.2882033586502075
test metrics:
R2: -1.3913607597351074
MSE: 212290.90625
MAPE: 0.3696967363357544
MSE diff_p 13
----------
14: 0.019293025135993958
Training Epoch 14
train_metrics: 
R2: -0.44344401359558105
MSE: 126355.8203125
MAPE: 0.25136521458625793
test metrics:
R2: -1.1693317890167236
MSE: 203887.125
MAPE: 0.35806629061698914
MSE diff_p 14
----------
15: 0.017896851524710655
Training Epoch 15
train_metrics: 
R2: -0.15135598182678223
MSE: 117211.859375
MAPE: 0.2446851134300232
test metrics:
R2: -0.8133971691131592
MSE: 194410.9375
MAPE: 0.35570743680000305
MSE diff_p 15
----------
16: 0.023651080206036568
Training Epoch 16
train_metrics: 
R2: -0.5470482110977173
MSE: 154898.03125
MAPE: 0.2794433534145355
test metrics:
R2: -0.8592324256896973
MSE: 191915.59375
MAPE: 0.34815311431884766
MSE diff_p 16
----------
17: 0.01671024225652218
Training Epoch 17
train_metrics: 
R2: -0.004700779914855957
MSE: 109440.3984375
MAPE: 0.24873071908950806
test metrics:
R2: -0.47762274742126465
MSE: 181506.640625
MAPE: 0.34997451305389404
MSE diff_p 17
----------
18: 0.016466272994875908
Training Epoch 18
train_metrics: 
R2: 0.014289021492004395
MSE: 107842.578125
MAPE: 0.22171643376350403
test metrics:
R2: -0.6976531744003296
MSE: 184502.9375
MAPE: 0.34300586581230164
MSE diff_p 18
----------
19: 0.015540031716227531
Training Epoch 19
train_metrics: 
R2: 0.1466391682624817
MSE: 101776.3515625
MAPE: 0.23048549890518188
test metrics:
R2: -0.13397228717803955
MSE: 162419.5
MAPE: 0.3310733735561371
MSE diff_p 19
----------
20: 0.012428191490471363
Training Epoch 20
train_metrics: 
R2: 0.3278217315673828
MSE: 81395.953125
MAPE: 0.20111465454101562
test metrics:
R2: -0.14661288261413574
MSE: 155473.15625
MAPE: 0.3194260597229004
MSE diff_p 20
----------
21: 0.016048330813646317
Training Epoch 21
train_metrics: 
R2: 0.30424487590789795
MSE: 105105.3515625
MAPE: 0.24711526930332184
test metrics:
R2: 0.12271344661712646
MSE: 142423.109375
MAPE: 0.3130573630332947
MSE diff_p 21
----------
22: 0.013262935914099216
Training Epoch 22
train_metrics: 
R2: 0.39364421367645264
MSE: 86862.9609375
MAPE: 0.21048182249069214
test metrics:
R2: 0.12173408269882202
MSE: 136325.28125
MAPE: 0.30265888571739197
MSE diff_p 22
----------
23: 0.013738837093114853
Training Epoch 23
train_metrics: 
R2: 0.47093528509140015
MSE: 89979.78125
MAPE: 0.22874341905117035
test metrics:
R2: 0.2686154246330261
MSE: 132892.78125
MAPE: 0.3097030520439148
MSE diff_p 23
----------
24: 0.012511205859482288
Training Epoch 24
train_metrics: 
R2: 0.4243737459182739
MSE: 81939.65625
MAPE: 0.20549529790878296
test metrics:
R2: 0.257185161113739
MSE: 124224.0546875
MAPE: 0.2927035391330719
MSE diff_p 24
----------
25: 0.010799473151564598
Training Epoch 25
train_metrics: 
R2: 0.6053862571716309
MSE: 70729.0
MAPE: 0.20095741748809814
test metrics:
R2: 0.38663434982299805
MSE: 120745.7578125
MAPE: 0.3009401559829712
MSE diff_p 25
----------
26: 0.010400963947176933
Training Epoch 26
train_metrics: 
R2: 0.5850481390953064
MSE: 68119.046875
MAPE: 0.1982564926147461
test metrics:
R2: 0.36835718154907227
MSE: 113221.0234375
MAPE: 0.2820787727832794
MSE diff_p 26
----------
27: 0.010885780677199364
Training Epoch 27
train_metrics: 
R2: 0.6071776151657104
MSE: 71294.25
MAPE: 0.19799482822418213
test metrics:
R2: 0.4846675395965576
MSE: 108039.5234375
MAPE: 0.28568902611732483
MSE diff_p 27
----------
28: 0.012851403094828129
Training Epoch 28
train_metrics: 
R2: 0.4775187373161316
MSE: 84167.703125
MAPE: 0.23596647381782532
test metrics:
R2: 0.4548768997192383
MSE: 105005.4453125
MAPE: 0.2752727270126343
MSE diff_p 28
----------
29: 0.012636611238121986
Training Epoch 29
train_metrics: 
R2: 0.5696389079093933
MSE: 82760.96875
MAPE: 0.23699375987052917
test metrics:
R2: 0.5020471811294556
MSE: 108776.109375
MAPE: 0.29598045349121094
MSE diff_p 29
----------
30: 0.014236774295568466
Training Epoch 30
train_metrics: 
R2: 0.44172555208206177
MSE: 93240.90625
MAPE: 0.2591371536254883
test metrics:
R2: 0.39154553413391113
MSE: 110976.03125
MAPE: 0.2863563299179077
MSE diff_p 30
----------
31: 0.012565933167934418
Training Epoch 31
train_metrics: 
R2: 0.5875481367111206
MSE: 82298.078125
MAPE: 0.24411073327064514
test metrics:
R2: 0.5086007118225098
MSE: 108959.0703125
MAPE: 0.2957151234149933
MSE diff_p 31
----------
32: 0.011060846969485283
Training Epoch 32
train_metrics: 
R2: 0.6239657402038574
MSE: 72440.8125
MAPE: 0.2219221293926239
test metrics:
R2: 0.529719889163971
MSE: 96082.5234375
MAPE: 0.26427826285362244
MSE diff_p 32
----------
33: 0.008910379372537136
Training Epoch 33
train_metrics: 
R2: 0.7197995781898499
MSE: 58356.75390625
MAPE: 0.19052299857139587
test metrics:
R2: 0.6467272043228149
MSE: 85409.0234375
MAPE: 0.25768059492111206
MSE diff_p 33
----------
34: 0.008698261342942715
Training Epoch 34
train_metrics: 
R2: 0.7134774923324585
MSE: 56967.53515625
MAPE: 0.20015017688274384
test metrics:
R2: 0.6509453058242798
MSE: 80545.3359375
MAPE: 0.24396738409996033
MSE diff_p 34
----------
35: 0.008653481490910053
Training Epoch 35
train_metrics: 
R2: 0.7465550899505615
MSE: 56674.2578125
MAPE: 0.1967683881521225
test metrics:
R2: 0.6858764290809631
MSE: 79287.2109375
MAPE: 0.25139063596725464
MSE diff_p 35
----------
36: 0.009279713965952396
Training Epoch 36
train_metrics: 
R2: 0.736026406288147
MSE: 60775.6328125
MAPE: 0.19906938076019287
test metrics:
R2: 0.674382209777832
MSE: 77451.90625
MAPE: 0.2402534931898117
MSE diff_p 36
----------
37: 0.008814320899546146
Training Epoch 37
train_metrics: 
R2: 0.7449825406074524
MSE: 57727.63671875
MAPE: 0.1821221113204956
test metrics:
R2: 0.6960475444793701
MSE: 80104.4296875
MAPE: 0.257526159286499
MSE diff_p 37
----------
38: 0.008402694948017597
Training Epoch 38
train_metrics: 
R2: 0.7502022385597229
MSE: 55031.7734375
MAPE: 0.20675987005233765
test metrics:
R2: 0.6758286356925964
MSE: 78320.5234375
MAPE: 0.2487039417028427
MSE diff_p 38
----------
39: 0.009355006739497185
Training Epoch 39
train_metrics: 
R2: 0.739672839641571
MSE: 61268.75
MAPE: 0.20005086064338684
test metrics:
R2: 0.7243127822875977
MSE: 74789.1171875
MAPE: 0.25018423795700073
MSE diff_p 39
----------
40: 0.008038721047341824
Training Epoch 40
train_metrics: 
R2: 0.7490252256393433
MSE: 52647.99609375
MAPE: 0.1976439654827118
test metrics:
R2: 0.6840260624885559
MSE: 76566.1328125
MAPE: 0.24375919997692108
MSE diff_p 40
----------
41: 0.006624660454690456
Training Epoch 41
train_metrics: 
R2: 0.8309580087661743
MSE: 43386.89453125
MAPE: 0.16339071094989777
test metrics:
R2: 0.752531886100769
MSE: 68705.0
MAPE: 0.23853756487369537
MSE diff_p 41
----------
42: 0.006271478720009327
Training Epoch 42
train_metrics: 
R2: 0.8109670877456665
MSE: 41073.80078125
MAPE: 0.16649922728538513
test metrics:
R2: 0.7564222812652588
MSE: 64735.5078125
MAPE: 0.2237991839647293
MSE diff_p 42
----------
43: 0.006648689974099398
Training Epoch 43
train_metrics: 
R2: 0.8221169710159302
MSE: 43544.2734375
MAPE: 0.17878326773643494
test metrics:
R2: 0.7839524149894714
MSE: 61368.4921875
MAPE: 0.2202659547328949
MSE diff_p 43
----------
44: 0.005857355892658234
Training Epoch 44
train_metrics: 
R2: 0.8337392210960388
MSE: 38361.5859375
MAPE: 0.16630885004997253
test metrics:
R2: 0.7897759079933167
MSE: 58980.3125
MAPE: 0.21353037655353546
MSE diff_p 44
----------
45: 0.006390369962900877
Training Epoch 45
train_metrics: 
R2: 0.8385099172592163
MSE: 41852.453125
MAPE: 0.1507178544998169
test metrics:
R2: 0.7919712662696838
MSE: 61108.93359375
MAPE: 0.2244240790605545
MSE diff_p 45
----------
46: 0.006594402249902487
Training Epoch 46
train_metrics: 
R2: 0.831681489944458
MSE: 43188.72265625
MAPE: 0.18756084144115448
test metrics:
R2: 0.7839126586914062
MSE: 60139.6875
MAPE: 0.21973663568496704
MSE diff_p 46
----------
47: 0.007080168928951025
Training Epoch 47
train_metrics: 
R2: 0.8388830423355103
MSE: 46370.15625
MAPE: 0.17302219569683075
test metrics:
R2: 0.8120148777961731
MSE: 57093.12109375
MAPE: 0.21974019706249237
MSE diff_p 47
----------
48: 0.006249428726732731
Training Epoch 48
train_metrics: 
R2: 0.851273775100708
MSE: 40929.38671875
MAPE: 0.16902881860733032
test metrics:
R2: 0.8098064661026001
MSE: 54996.78515625
MAPE: 0.21113327145576477
MSE diff_p 48
----------
49: 0.006101471371948719
Training Epoch 49
train_metrics: 
R2: 0.8457152843475342
MSE: 39960.375
MAPE: 0.1903030276298523
test metrics:
R2: 0.8302947282791138
MSE: 54004.83984375
MAPE: 0.21768127381801605
MSE diff_p 49
----------
50: 0.005809847731143236
Training Epoch 50
train_metrics: 
R2: 0.8519579768180847
MSE: 38050.44140625
MAPE: 0.16611555218696594
test metrics:
R2: 0.814021646976471
MSE: 54343.640625
MAPE: 0.2093188762664795
MSE diff_p 50
----------
51: 0.0058617861941456795
Training Epoch 51
train_metrics: 
R2: 0.8716340661048889
MSE: 38390.6015625
MAPE: 0.16971689462661743
test metrics:
R2: 0.8384048938751221
MSE: 52550.27734375
MAPE: 0.216136634349823
MSE diff_p 51
----------
52: 0.0049371314235031605
Training Epoch 52
train_metrics: 
R2: 0.8868256211280823
MSE: 32334.7578125
MAPE: 0.15499450266361237
test metrics:
R2: 0.8389084339141846
MSE: 49169.36328125
MAPE: 0.2011919915676117
MSE diff_p 52
----------
53: 0.005161490757018328
Training Epoch 53
train_metrics: 
R2: 0.8867684006690979
MSE: 33804.15234375
MAPE: 0.1577119678258896
test metrics:
R2: 0.852100670337677
MSE: 49246.07421875
MAPE: 0.2098546326160431
MSE diff_p 53
----------
54: 0.005504019092768431
Training Epoch 54
train_metrics: 
R2: 0.8581089377403259
MSE: 36047.47265625
MAPE: 0.1522587537765503
test metrics:
R2: 0.8344641327857971
MSE: 49950.44140625
MAPE: 0.2057134211063385
MSE diff_p 54
----------
55: 0.004646863788366318
Training Epoch 55
train_metrics: 
R2: 0.8973535895347595
MSE: 30433.70703125
MAPE: 0.14459210634231567
test metrics:
R2: 0.8613871335983276
MSE: 47030.52734375
MAPE: 0.2082051783800125
MSE diff_p 55
----------
56: 0.0041514006443321705
Training Epoch 56
train_metrics: 
R2: 0.9084436893463135
MSE: 27188.76953125
MAPE: 0.14555661380290985
test metrics:
R2: 0.8719654083251953
MSE: 42424.80859375
MAPE: 0.1922118067741394
MSE diff_p 56
----------
57: 0.0043279919773340225
Training Epoch 57
train_metrics: 
R2: 0.9049111008644104
MSE: 28345.3203125
MAPE: 0.14643874764442444
test metrics:
R2: 0.884514570236206
MSE: 39933.96484375
MAPE: 0.1877998560667038
MSE diff_p 57
----------
58: 0.004325584042817354
Training Epoch 58
train_metrics: 
R2: 0.9039314985275269
MSE: 28329.55078125
MAPE: 0.15524160861968994
test metrics:
R2: 0.8859381079673767
MSE: 38773.34375
MAPE: 0.1835700422525406
MSE diff_p 58
----------
59: 0.004381600301712751
Training Epoch 59
train_metrics: 
R2: 0.9086281061172485
MSE: 28696.41796875
MAPE: 0.13756680488586426
test metrics:
R2: 0.8863548040390015
MSE: 40149.375
MAPE: 0.18987402319908142
MSE diff_p 59
----------
60: 0.003897720016539097
Training Epoch 60
train_metrics: 
R2: 0.9084373712539673
MSE: 25527.33984375
MAPE: 0.14276383817195892
test metrics:
R2: 0.8945502042770386
MSE: 36380.89453125
MAPE: 0.1795172393321991
MSE diff_p 60
----------
61: 0.004651517607271671
Training Epoch 61
train_metrics: 
R2: 0.9036102890968323
MSE: 30464.19140625
MAPE: 0.1600382924079895
test metrics:
R2: 0.8983364701271057
MSE: 36460.6484375
MAPE: 0.18177969753742218
MSE diff_p 61
----------
62: 0.003471477422863245
Training Epoch 62
train_metrics: 
R2: 0.9253427982330322
MSE: 22735.75
MAPE: 0.13389410078525543
test metrics:
R2: 0.8954220414161682
MSE: 35987.76171875
MAPE: 0.17544078826904297
MSE diff_p 62
----------
63: 0.004073076881468296
Training Epoch 63
train_metrics: 
R2: 0.9207761883735657
MSE: 26675.80859375
MAPE: 0.13442865014076233
test metrics:
R2: 0.9020100235939026
MSE: 36278.80078125
MAPE: 0.1833375096321106
MSE diff_p 63
----------
64: 0.003984632436186075
Training Epoch 64
train_metrics: 
R2: 0.9152724146842957
MSE: 26096.55859375
MAPE: 0.14379748702049255
test metrics:
R2: 0.9067433476448059
MSE: 33163.55859375
MAPE: 0.17438071966171265
MSE diff_p 64
----------
65: 0.003393352497369051
Training Epoch 65
train_metrics: 
R2: 0.9301396608352661
MSE: 22224.0859375
MAPE: 0.12105843424797058
test metrics:
R2: 0.9096614718437195
MSE: 33445.67578125
MAPE: 0.1755496710538864
MSE diff_p 65
----------
66: 0.004091635812073946
Training Epoch 66
train_metrics: 
R2: 0.9154139161109924
MSE: 26797.35546875
MAPE: 0.1691301465034485
test metrics:
R2: 0.9019986987113953
MSE: 34190.80859375
MAPE: 0.17622952163219452
MSE diff_p 66
----------
67: 0.0036509837955236435
Training Epoch 67
train_metrics: 
R2: 0.9228712916374207
MSE: 23911.390625
MAPE: 0.1462322175502777
test metrics:
R2: 0.9034597277641296
MSE: 35836.02734375
MAPE: 0.18831230700016022
MSE diff_p 67
----------
68: 0.003730101976543665
Training Epoch 68
train_metrics: 
R2: 0.9164357781410217
MSE: 24429.560546875
MAPE: 0.13760584592819214
test metrics:
R2: 0.9122341275215149
MSE: 31911.1640625
MAPE: 0.17274010181427002
MSE diff_p 68
----------
69: 0.003478657454252243
Training Epoch 69
train_metrics: 
R2: 0.9235714673995972
MSE: 22782.7734375
MAPE: 0.13445992767810822
test metrics:
R2: 0.9093340635299683
MSE: 34203.62109375
MAPE: 0.18302688002586365
MSE diff_p 69
----------
70: 0.00370360491797328
Training Epoch 70
train_metrics: 
R2: 0.9284540414810181
MSE: 24256.021484375
MAPE: 0.14796139299869537
test metrics:
R2: 0.920723557472229
MSE: 29624.396484375
MAPE: 0.16630220413208008
MSE diff_p 70
----------
71: 0.004330293275415897
Training Epoch 71
train_metrics: 
R2: 0.916100025177002
MSE: 28360.390625
MAPE: 0.13103891909122467
test metrics:
R2: 0.9162395596504211
MSE: 32280.517578125
MAPE: 0.17346316576004028
MSE diff_p 71
----------
72: 0.004193739965558052
Training Epoch 72
train_metrics: 
R2: 0.917436420917511
MSE: 27466.0625
MAPE: 0.16018864512443542
test metrics:
R2: 0.9144223928451538
MSE: 31046.404296875
MAPE: 0.1712784618139267
MSE diff_p 72
----------
73: 0.0042017740197479725
Training Epoch 73
train_metrics: 
R2: 0.9203521013259888
MSE: 27518.6796875
MAPE: 0.16217748820781708
test metrics:
R2: 0.9096581935882568
MSE: 34789.23828125
MAPE: 0.19008256494998932
MSE diff_p 73
----------
74: 0.00364970276132226
Training Epoch 74
train_metrics: 
R2: 0.9255768060684204
MSE: 23903.0
MAPE: 0.15670527517795563
test metrics:
R2: 0.9116735458374023
MSE: 31895.880859375
MAPE: 0.1726156622171402
MSE diff_p 74
----------
75: 0.0030581748578697443
Training Epoch 75
train_metrics: 
R2: 0.9400100708007812
MSE: 20028.90625
MAPE: 0.1068410873413086
test metrics:
R2: 0.9257538914680481
MSE: 28601.833984375
MAPE: 0.16253305971622467
MSE diff_p 75
----------
76: 0.003487860318273306
Training Epoch 76
train_metrics: 
R2: 0.9280176758766174
MSE: 22843.04296875
MAPE: 0.1361609548330307
test metrics:
R2: 0.9307962656021118
MSE: 26709.1640625
MAPE: 0.16012604534626007
MSE diff_p 76
----------
77: 0.003847189713269472
Training Epoch 77
train_metrics: 
R2: 0.9289183616638184
MSE: 25196.40234375
MAPE: 0.1374255120754242
test metrics:
R2: 0.9266397953033447
MSE: 28431.267578125
MAPE: 0.16163963079452515
MSE diff_p 77
----------
78: 0.00308388564735651
Training Epoch 78
train_metrics: 
R2: 0.9413281083106995
MSE: 20197.29296875
MAPE: 0.12782739102840424
test metrics:
R2: 0.9293595552444458
MSE: 27259.123046875
MAPE: 0.1560325026512146
MSE diff_p 78
----------
79: 0.003891260363161564
Training Epoch 79
train_metrics: 
R2: 0.9307737946510315
MSE: 25485.033203125
MAPE: 0.1307898908853531
test metrics:
R2: 0.9323158264160156
MSE: 26292.357421875
MAPE: 0.15688613057136536
MSE diff_p 79
----------
80: 0.0026123118586838245
Training Epoch 80
train_metrics: 
R2: 0.9474076628684998
MSE: 17108.81640625
MAPE: 0.13138046860694885
test metrics:
R2: 0.9328811764717102
MSE: 26834.9375
MAPE: 0.16034375131130219
MSE diff_p 80
----------
81: 0.003647853620350361
Training Epoch 81
train_metrics: 
R2: 0.9316805005073547
MSE: 23890.890625
MAPE: 0.14686840772628784
test metrics:
R2: 0.930978000164032
MSE: 26605.505859375
MAPE: 0.1594478189945221
MSE diff_p 81
----------
82: 0.002718013245612383
Training Epoch 82
train_metrics: 
R2: 0.9508658647537231
MSE: 17801.083984375
MAPE: 0.12005849182605743
test metrics:
R2: 0.9276135563850403
MSE: 28086.939453125
MAPE: 0.1644185185432434
MSE diff_p 82
----------
83: 0.0030313420575112104
Training Epoch 83
train_metrics: 
R2: 0.9432697892189026
MSE: 19853.169921875
MAPE: 0.12816059589385986
test metrics:
R2: 0.9325020909309387
MSE: 26193.1875
MAPE: 0.15953445434570312
MSE diff_p 83
----------
84: 0.002936008619144559
Training Epoch 84
train_metrics: 
R2: 0.9490182995796204
MSE: 19228.8046875
MAPE: 0.12011973559856415
test metrics:
R2: 0.9298937320709229
MSE: 27911.1796875
MAPE: 0.16310548782348633
MSE diff_p 84
----------
85: 0.002649551723152399
Training Epoch 85
train_metrics: 
R2: 0.9476817846298218
MSE: 17352.712890625
MAPE: 0.12328240275382996
test metrics:
R2: 0.9335681796073914
MSE: 25918.908203125
MAPE: 0.15576720237731934
MSE diff_p 85
----------
86: 0.0022658193483948708
Training Epoch 86
train_metrics: 
R2: 0.9530520439147949
MSE: 14839.533203125
MAPE: 0.117653027176857
test metrics:
R2: 0.9318112730979919
MSE: 27156.353515625
MAPE: 0.1609923243522644
MSE diff_p 86
----------
87: 0.0029485905542969704
Training Epoch 87
train_metrics: 
R2: 0.9421142339706421
MSE: 19311.203125
MAPE: 0.13163423538208008
test metrics:
R2: 0.9374111890792847
MSE: 24699.75
MAPE: 0.15335290133953094
MSE diff_p 87
----------
88: 0.0029322949703782797
Training Epoch 88
train_metrics: 
R2: 0.9491440653800964
MSE: 19204.48046875
MAPE: 0.1356825828552246
test metrics:
R2: 0.934386670589447
MSE: 26666.02734375
MAPE: 0.15594951808452606
MSE diff_p 88
----------
89: 0.0027789860032498837
Training Epoch 89
train_metrics: 
R2: 0.9434660077095032
MSE: 18200.416015625
MAPE: 0.12126854062080383
test metrics:
R2: 0.9345584511756897
MSE: 25553.91015625
MAPE: 0.15375447273254395
MSE diff_p 89
----------
90: 0.0024554282426834106
Training Epoch 90
train_metrics: 
R2: 0.943900465965271
MSE: 16081.33984375
MAPE: 0.0954338014125824
test metrics:
R2: 0.9348373413085938
MSE: 25829.220703125
MAPE: 0.15431445837020874
MSE diff_p 90
----------
91: 0.0026572684291750193
Training Epoch 91
train_metrics: 
R2: 0.9472343325614929
MSE: 17403.25
MAPE: 0.13924503326416016
test metrics:
R2: 0.9377030730247498
MSE: 24559.92578125
MAPE: 0.15321584045886993
MSE diff_p 91
----------
92: 0.0024002213031053543
Training Epoch 92
train_metrics: 
R2: 0.9503300786018372
MSE: 15719.771484375
MAPE: 0.10027290880680084
test metrics:
R2: 0.9352353811264038
MSE: 25292.966796875
MAPE: 0.15278300642967224
MSE diff_p 92
----------
93: 0.00270712748169899
Training Epoch 93
train_metrics: 
R2: 0.9456309676170349
MSE: 17729.791015625
MAPE: 0.12809710204601288
test metrics:
R2: 0.9392289519309998
MSE: 24240.55078125
MAPE: 0.15191709995269775
MSE diff_p 93
----------
94: 0.0032056334894150496
Training Epoch 94
train_metrics: 
R2: 0.9437595009803772
MSE: 20994.66015625
MAPE: 0.12361358106136322
test metrics:
R2: 0.9397203922271729
MSE: 24345.181640625
MAPE: 0.15100878477096558
MSE diff_p 94
----------
95: 0.002994103590026498
Training Epoch 95
train_metrics: 
R2: 0.9435964226722717
MSE: 19609.28125
MAPE: 0.13708429038524628
test metrics:
R2: 0.9404280781745911
MSE: 24017.529296875
MAPE: 0.15212036669254303
MSE diff_p 95
----------
96: 0.002897708211094141
Training Epoch 96
train_metrics: 
R2: 0.9441699981689453
MSE: 18977.9609375
MAPE: 0.11343088746070862
test metrics:
R2: 0.9379154443740845
MSE: 24257.556640625
MAPE: 0.14882025122642517
MSE diff_p 96
----------
97: 0.0030748583376407623
Training Epoch 97
train_metrics: 
R2: 0.9385696649551392
MSE: 20138.171875
MAPE: 0.1318291425704956
test metrics:
R2: 0.932397723197937
MSE: 27307.4140625
MAPE: 0.16541095077991486
MSE diff_p 97
----------
98: 0.002983519807457924
Training Epoch 98
train_metrics: 
R2: 0.9432936906814575
MSE: 19539.966796875
MAPE: 0.1315893679857254
test metrics:
R2: 0.9370352029800415
MSE: 24904.291015625
MAPE: 0.15792155265808105
MSE diff_p 98
----------
99: 0.0028264708817005157
Training Epoch 99
train_metrics: 
R2: 0.9474518299102783
MSE: 18511.40625
MAPE: 0.12484163790941238
test metrics:
R2: 0.9345191121101379
MSE: 26557.423828125
MAPE: 0.16035407781600952
MSE diff_p 99
----------
100: 0.002560114022344351
Training Epoch 100
train_metrics: 
R2: 0.9508923888206482
MSE: 16766.955078125
MAPE: 0.12922701239585876
test metrics:
R2: 0.940729558467865
MSE: 23833.759765625
MAPE: 0.15739533305168152
MSE diff_p 100
----------
101: 0.0028731112834066153
Training Epoch 101
train_metrics: 
R2: 0.9372329711914062
MSE: 18816.87109375
MAPE: 0.13856613636016846
test metrics:
R2: 0.9329105615615845
MSE: 26524.255859375
MAPE: 0.1636347770690918
MSE diff_p 101
----------
102: 0.0027250065468251705
Training Epoch 102
train_metrics: 
R2: 0.9470211863517761
MSE: 17846.890625
MAPE: 0.12063878029584885
test metrics:
R2: 0.9390953183174133
MSE: 24105.7109375
MAPE: 0.15532562136650085
MSE diff_p 102
----------
103: 0.0028008529916405678
Training Epoch 103
train_metrics: 
R2: 0.9475855827331543
MSE: 18343.625
MAPE: 0.113626629114151
test metrics:
R2: 0.9305986762046814
MSE: 28133.283203125
MAPE: 0.1681903898715973
MSE diff_p 103
----------
104: 0.0041135079227387905
Training Epoch 104
train_metrics: 
R2: 0.9170065522193909
MSE: 26940.599609375
MAPE: 0.16211426258087158
test metrics:
R2: 0.9336768984794617
MSE: 25623.169921875
MAPE: 0.16091452538967133
MSE diff_p 104
----------
105: 0.0034804800525307655
Training Epoch 105
train_metrics: 
R2: 0.9271013736724854
MSE: 22794.7109375
MAPE: 0.1308615803718567
test metrics:
R2: 0.9261178374290466
MSE: 29866.1796875
MAPE: 0.1798163205385208
MSE diff_p 105
----------
106: 0.003653694875538349
Training Epoch 106
train_metrics: 
R2: 0.9309861063957214
MSE: 23929.14453125
MAPE: 0.1474410891532898
test metrics:
R2: 0.9406029582023621
MSE: 23847.333984375
MAPE: 0.15964724123477936
MSE diff_p 106
----------
107: 0.003088622121140361
Training Epoch 107
train_metrics: 
R2: 0.93683922290802
MSE: 20228.31640625
MAPE: 0.1316763460636139
test metrics:
R2: 0.9273747205734253
MSE: 29342.7265625
MAPE: 0.17739932239055634
MSE diff_p 107
----------
108: 0.0035700728185474873
Training Epoch 108
train_metrics: 
R2: 0.9332495331764221
MSE: 23381.478515625
MAPE: 0.14948409795761108
test metrics:
R2: 0.9375873804092407
MSE: 24526.396484375
MAPE: 0.15967337787151337
MSE diff_p 108
----------
109: 0.0027289739809930325
Training Epoch 109
train_metrics: 
R2: 0.9507849216461182
MSE: 17872.873046875
MAPE: 0.11496245115995407
test metrics:
R2: 0.9314415454864502
MSE: 27799.189453125
MAPE: 0.16887407004833221
MSE diff_p 109
----------
110: 0.0022993050515651703
Training Epoch 110
train_metrics: 
R2: 0.9505898356437683
MSE: 15058.841796875
MAPE: 0.10430817306041718
test metrics:
R2: 0.9419776797294617
MSE: 23288.95703125
MAPE: 0.15144160389900208
MSE diff_p 110
----------
111: 0.00288873678073287
Training Epoch 111
train_metrics: 
R2: 0.9459130167961121
MSE: 18919.203125
MAPE: 0.11723338067531586
test metrics:
R2: 0.9371132850646973
MSE: 25865.787109375
MAPE: 0.1585431545972824
MSE diff_p 111
----------
112: 0.0029281340539455414
Training Epoch 112
train_metrics: 
R2: 0.9466016888618469
MSE: 19177.23046875
MAPE: 0.1253589689731598
test metrics:
R2: 0.9446320533752441
MSE: 22457.97265625
MAPE: 0.15065807104110718
MSE diff_p 112
----------
113: 0.003019757568836212
Training Epoch 113
train_metrics: 
R2: 0.9425687193870544
MSE: 19777.30078125
MAPE: 0.14740191400051117
test metrics:
R2: 0.9386864304542542
MSE: 25479.619140625
MAPE: 0.15911880135536194
MSE diff_p 113
----------
114: 0.002574177458882332
Training Epoch 114
train_metrics: 
R2: 0.9481170177459717
MSE: 16859.0625
MAPE: 0.12877994775772095
test metrics:
R2: 0.9426536560058594
MSE: 23319.529296875
MAPE: 0.15074589848518372
MSE diff_p 114
----------
115: 0.002412941539660096
Training Epoch 115
train_metrics: 
R2: 0.9487108588218689
MSE: 15803.078125
MAPE: 0.10067005455493927
test metrics:
R2: 0.9413444399833679
MSE: 23771.779296875
MAPE: 0.14842428267002106
MSE diff_p 115
----------
116: 0.002614637603983283
Training Epoch 116
train_metrics: 
R2: 0.947595477104187
MSE: 17124.046875
MAPE: 0.11338981986045837
test metrics:
R2: 0.9460940957069397
MSE: 21865.046875
MAPE: 0.14596734941005707
MSE diff_p 116
----------
117: 0.002663131570443511
Training Epoch 117
train_metrics: 
R2: 0.9480147361755371
MSE: 17441.6484375
MAPE: 0.1190837100148201
test metrics:
R2: 0.9390856623649597
MSE: 24527.28125
MAPE: 0.15404166281223297
MSE diff_p 117
----------
118: 0.0024798645172268152
Training Epoch 118
train_metrics: 
R2: 0.9568467140197754
MSE: 16241.37890625
MAPE: 0.131769597530365
test metrics:
R2: 0.9499210119247437
MSE: 21028.5234375
MAPE: 0.14445827901363373
MSE diff_p 118
----------
119: 0.002854411955922842
Training Epoch 119
train_metrics: 
R2: 0.9514350891113281
MSE: 18694.40234375
MAPE: 0.1177767664194107
test metrics:
R2: 0.9495718479156494
MSE: 21113.169921875
MAPE: 0.1424187272787094
MSE diff_p 119
----------
120: 0.0022912942804396152
Training Epoch 120
train_metrics: 
R2: 0.9579579830169678
MSE: 15006.3759765625
MAPE: 0.1102595180273056
test metrics:
R2: 0.9485238194465637
MSE: 21487.373046875
MAPE: 0.1430707424879074
MSE diff_p 120
----------
121: 0.0032460219226777554
Training Epoch 121
train_metrics: 
R2: 0.9379028677940369
MSE: 21259.171875
MAPE: 0.14668908715248108
test metrics:
R2: 0.9493622183799744
MSE: 21152.328125
MAPE: 0.14515294134616852
MSE diff_p 121
----------
122: 0.0024692791048437357
Training Epoch 122
train_metrics: 
R2: 0.9489781856536865
MSE: 16172.052734375
MAPE: 0.10830539464950562
test metrics:
R2: 0.9457632303237915
MSE: 22365.607421875
MAPE: 0.14746567606925964
MSE diff_p 122
----------
123: 0.002746962709352374
Training Epoch 123
train_metrics: 
R2: 0.9454835057258606
MSE: 17990.68359375
MAPE: 0.15443408489227295
test metrics:
R2: 0.951123833656311
MSE: 20280.392578125
MAPE: 0.14837776124477386
MSE diff_p 123
----------
124: 0.003655392210930586
Training Epoch 124
train_metrics: 
R2: 0.932722270488739
MSE: 23940.263671875
MAPE: 0.1333630234003067
test metrics:
R2: 0.9437891840934753
MSE: 23072.693359375
MAPE: 0.14720387756824493
MSE diff_p 124
----------
125: 0.002295225393027067
Training Epoch 125
train_metrics: 
R2: 0.9606159925460815
MSE: 15032.125
MAPE: 0.12796959280967712
test metrics:
R2: 0.9470407962799072
MSE: 21543.95703125
MAPE: 0.14747174084186554
MSE diff_p 125
----------
126: 0.0030413975473493338
Training Epoch 126
train_metrics: 
R2: 0.9446007609367371
MSE: 19919.0234375
MAPE: 0.13482579588890076
test metrics:
R2: 0.9420027136802673
MSE: 23859.44921875
MAPE: 0.1520942747592926
MSE diff_p 126
----------
127: 0.0029230325017124414
Training Epoch 127
train_metrics: 
R2: 0.94190913438797
MSE: 19143.8203125
MAPE: 0.1422559767961502
test metrics:
R2: 0.9513881802558899
MSE: 20454.701171875
MAPE: 0.1448846310377121
MSE diff_p 127
----------
128: 0.002782048424705863
Training Epoch 128
train_metrics: 
R2: 0.9436630606651306
MSE: 18220.470703125
MAPE: 0.13418257236480713
test metrics:
R2: 0.9480526447296143
MSE: 21409.583984375
MAPE: 0.13987576961517334
MSE diff_p 128
----------
129: 0.002480797003954649
Training Epoch 129
train_metrics: 
R2: 0.9544971585273743
MSE: 16247.484375
MAPE: 0.13899782299995422
test metrics:
R2: 0.9525834918022156
MSE: 20044.126953125
MAPE: 0.13919708132743835
MSE diff_p 129
----------
130: 0.0023584256414324045
Training Epoch 130
train_metrics: 
R2: 0.9529340267181396
MSE: 15446.0380859375
MAPE: 0.1032426506280899
test metrics:
R2: 0.9476402401924133
MSE: 21384.396484375
MAPE: 0.13825072348117828
MSE diff_p 130
----------
131: 0.0024558810982853174
Training Epoch 131
train_metrics: 
R2: 0.9540647268295288
MSE: 16084.3046875
MAPE: 0.11789710819721222
test metrics:
R2: 0.9511412382125854
MSE: 20497.048828125
MAPE: 0.14053212106227875
MSE diff_p 131
----------
132: 0.002147541381418705
Training Epoch 132
train_metrics: 
R2: 0.9552580118179321
MSE: 14064.89453125
MAPE: 0.1118418276309967
test metrics:
R2: 0.948250949382782
MSE: 21166.767578125
MAPE: 0.14142371714115143
MSE diff_p 132
----------
133: 0.003096221014857292
Training Epoch 133
train_metrics: 
R2: 0.9422910213470459
MSE: 20278.0859375
MAPE: 0.12290168553590775
test metrics:
R2: 0.948836624622345
MSE: 21117.162109375
MAPE: 0.13957756757736206
MSE diff_p 133
----------
134: 0.0020846384577453136
Training Epoch 134
train_metrics: 
R2: 0.9614620804786682
MSE: 13652.921875
MAPE: 0.114757239818573
test metrics:
R2: 0.9436482191085815
MSE: 22301.05859375
MAPE: 0.14103172719478607
MSE diff_p 134
----------
135: 0.0025198713410645723
Training Epoch 135
train_metrics: 
R2: 0.9550525546073914
MSE: 16503.396484375
MAPE: 0.12146194279193878
test metrics:
R2: 0.9501358270645142
MSE: 20919.376953125
MAPE: 0.14063917100429535
MSE diff_p 135
----------
136: 0.002287468407303095
Training Epoch 136
train_metrics: 
R2: 0.9568448066711426
MSE: 14981.318359375
MAPE: 0.1183982864022255
test metrics:
R2: 0.9510109424591064
MSE: 20282.345703125
MAPE: 0.14292030036449432
MSE diff_p 136
----------
137: 0.0025648067239671946
Training Epoch 137
train_metrics: 
R2: 0.9525273442268372
MSE: 16797.69140625
MAPE: 0.13299527764320374
test metrics:
R2: 0.9385470747947693
MSE: 24878.7265625
MAPE: 0.16424468159675598
MSE diff_p 137
----------
138: 0.0029028095304965973
Training Epoch 138
train_metrics: 
R2: 0.9467985033988953
MSE: 19011.373046875
MAPE: 0.1564493179321289
test metrics:
R2: 0.9398117661476135
MSE: 23959.63671875
MAPE: 0.15801334381103516
MSE diff_p 138
----------
139: 0.0033113681711256504
Training Epoch 139
train_metrics: 
R2: 0.9380819201469421
MSE: 21687.1484375
MAPE: 0.1430286318063736
test metrics:
R2: 0.9219138622283936
MSE: 31552.4609375
MAPE: 0.18912172317504883
MSE diff_p 139
----------
140: 0.0032847223337739706
Training Epoch 140
train_metrics: 
R2: 0.9334592223167419
MSE: 21512.63671875
MAPE: 0.16782206296920776
test metrics:
R2: 0.9388517141342163
MSE: 24871.248046875
MAPE: 0.17512066662311554
MSE diff_p 140
----------
141: 0.0040174853056669235
Training Epoch 141
train_metrics: 
R2: 0.9233675599098206
MSE: 26311.71875
MAPE: 0.15086627006530762
test metrics:
R2: 0.925399124622345
MSE: 29279.80078125
MAPE: 0.18459422886371613
MSE diff_p 141
----------
142: 0.0027653544675558805
Training Epoch 142
train_metrics: 
R2: 0.9505655765533447
MSE: 18111.138671875
MAPE: 0.15147024393081665
test metrics:
R2: 0.9441720247268677
MSE: 22760.83203125
MAPE: 0.15944938361644745
MSE diff_p 142
----------
143: 0.002755762543529272
Training Epoch 143
train_metrics: 
R2: 0.9510826468467712
MSE: 18048.318359375
MAPE: 0.11570185422897339
test metrics:
R2: 0.9372799396514893
MSE: 25832.00390625
MAPE: 0.15798340737819672
MSE diff_p 143
----------
144: 0.002648204332217574
Training Epoch 144
train_metrics: 
R2: 0.9551842212677002
MSE: 17343.88671875
MAPE: 0.1331954002380371
test metrics:
R2: 0.9515693783760071
MSE: 20099.216796875
MAPE: 0.1435294896364212
MSE diff_p 144
----------
145: 0.002117700409144163
Training Epoch 145
train_metrics: 
R2: 0.9603215456008911
MSE: 13869.4560546875
MAPE: 0.10710284113883972
test metrics:
R2: 0.9473299980163574
MSE: 22104.029296875
MAPE: 0.14708055555820465
MSE diff_p 145
----------
146: 0.002638493664562702
Training Epoch 146
train_metrics: 
R2: 0.9536333680152893
MSE: 17280.28515625
MAPE: 0.1292068064212799
test metrics:
R2: 0.9523538947105408
MSE: 20011.259765625
MAPE: 0.14046889543533325
MSE diff_p 146
----------
147: 0.002703330712392926
Training Epoch 147
train_metrics: 
R2: 0.9504927396774292
MSE: 17704.92578125
MAPE: 0.12207387387752533
test metrics:
R2: 0.9504488110542297
MSE: 21265.81640625
MAPE: 0.14206047356128693
MSE diff_p 147
----------
148: 0.0023469431325793266
Training Epoch 148
train_metrics: 
R2: 0.9563326835632324
MSE: 15370.8369140625
MAPE: 0.12161700427532196
test metrics:
R2: 0.9545343518257141
MSE: 19184.412109375
MAPE: 0.14347907900810242
MSE diff_p 148
----------
149: 0.002663387916982174
Training Epoch 149
train_metrics: 
R2: 0.945807158946991
MSE: 17443.328125
MAPE: 0.11116696894168854
test metrics:
R2: 0.9456957578659058
MSE: 23084.5078125
MAPE: 0.152391254901886
MSE diff_p 149
----------
150: 0.003318524220958352
Training Epoch 150
train_metrics: 
R2: 0.9346621632575989
MSE: 21734.015625
MAPE: 0.12364280968904495
test metrics:
R2: 0.9517197608947754
MSE: 19794.240234375
MAPE: 0.14546407759189606
MSE diff_p 150
----------
151: 0.0027634757570922375
Training Epoch 151
train_metrics: 
R2: 0.9453988075256348
MSE: 18098.833984375
MAPE: 0.12111692875623703
test metrics:
R2: 0.9328255653381348
MSE: 28156.103515625
MAPE: 0.17814555764198303
MSE diff_p 151
----------
152: 0.0027728877030313015
Training Epoch 152
train_metrics: 
R2: 0.9393720030784607
MSE: 18160.4765625
MAPE: 0.1367906928062439
test metrics:
R2: 0.9518123865127563
MSE: 20191.509765625
MAPE: 0.15164929628372192
MSE diff_p 152
----------
153: 0.002759300172328949
Training Epoch 153
train_metrics: 
R2: 0.9419171214103699
MSE: 18071.484375
MAPE: 0.11707784980535507
test metrics:
R2: 0.937743067741394
MSE: 25510.2265625
MAPE: 0.16596922278404236
MSE diff_p 153
----------
154: 0.0026114280335605145
Training Epoch 154
train_metrics: 
R2: 0.9546446204185486
MSE: 17103.025390625
MAPE: 0.13462936878204346
test metrics:
R2: 0.9520297646522522
MSE: 20289.779296875
MAPE: 0.15418888628482819
MSE diff_p 154
----------
155: 0.0027891178615391254
Training Epoch 155
train_metrics: 
R2: 0.9504396915435791
MSE: 18266.7734375
MAPE: 0.1314822882413864
test metrics:
R2: 0.9412113428115845
MSE: 24374.798828125
MAPE: 0.16019313037395477
MSE diff_p 155
----------
156: 0.003017281647771597
Training Epoch 156
train_metrics: 
R2: 0.9451954364776611
MSE: 19761.0859375
MAPE: 0.15941625833511353
test metrics:
R2: 0.9417312145233154
MSE: 23194.63671875
MAPE: 0.1537279188632965
MSE diff_p 156
----------
157: 0.002366775181144476
Training Epoch 157
train_metrics: 
R2: 0.9479592442512512
MSE: 15500.720703125
MAPE: 0.11718128621578217
test metrics:
R2: 0.9273520708084106
MSE: 28652.74609375
MAPE: 0.1781412661075592
MSE diff_p 157
----------
158: 0.002730571199208498
Training Epoch 158
train_metrics: 
R2: 0.9518730640411377
MSE: 17883.33203125
MAPE: 0.1347811371088028
test metrics:
R2: 0.9506750106811523
MSE: 20516.271484375
MAPE: 0.14871938526630402
MSE diff_p 158
----------
159: 0.0022717404644936323
Training Epoch 159
train_metrics: 
R2: 0.9617770314216614
MSE: 14878.3125
MAPE: 0.11375142633914948
test metrics:
R2: 0.9470787048339844
MSE: 21750.626953125
MAPE: 0.14196564257144928
MSE diff_p 159
----------
160: 0.00226952088996768
Training Epoch 160
train_metrics: 
R2: 0.9605558514595032
MSE: 14863.7734375
MAPE: 0.12329267710447311
test metrics:
R2: 0.9525123238563538
MSE: 19950.44921875
MAPE: 0.13888953626155853
MSE diff_p 160
----------
161: 0.001927730394527316
Training Epoch 161
train_metrics: 
R2: 0.9663293361663818
MSE: 12625.287109375
MAPE: 0.12109659612178802
test metrics:
R2: 0.9537538290023804
MSE: 19919.46875
MAPE: 0.13700737059116364
MSE diff_p 161
----------
162: 0.0022293422371149063
Training Epoch 162
train_metrics: 
R2: 0.9597638845443726
MSE: 14600.6328125
MAPE: 0.1075315922498703
test metrics:
R2: 0.952509343624115
MSE: 20041.74609375
MAPE: 0.13720889389514923
MSE diff_p 162
----------
163: 0.002659060060977936
Training Epoch 163
train_metrics: 
R2: 0.9516551494598389
MSE: 17414.982421875
MAPE: 0.12329455465078354
test metrics:
R2: 0.9532046318054199
MSE: 19279.783203125
MAPE: 0.13689163327217102
MSE diff_p 163
----------
164: 0.002169742714613676
Training Epoch 164
train_metrics: 
R2: 0.9570621848106384
MSE: 14210.298828125
MAPE: 0.1100364476442337
test metrics:
R2: 0.9538742303848267
MSE: 19652.107421875
MAPE: 0.1367531269788742
MSE diff_p 164
----------
165: 0.0020334389992058277
Training Epoch 165
train_metrics: 
R2: 0.9601978063583374
MSE: 13317.6015625
MAPE: 0.09982660412788391
test metrics:
R2: 0.955370306968689
MSE: 18713.31640625
MAPE: 0.13558591902256012
MSE diff_p 165
----------
166: 0.00198066933080554
Training Epoch 166
train_metrics: 
R2: 0.9625816345214844
MSE: 12971.9970703125
MAPE: 0.10694961249828339
test metrics:
R2: 0.9538595676422119
MSE: 19961.45703125
MAPE: 0.13748647272586823
MSE diff_p 166
----------
167: 0.0023564535658806562
Training Epoch 167
train_metrics: 
R2: 0.9578042030334473
MSE: 15433.123046875
MAPE: 0.13030293583869934
test metrics:
R2: 0.9547626376152039
MSE: 19037.3671875
MAPE: 0.1383974403142929
MSE diff_p 167
----------
168: 0.00218117143958807
Training Epoch 168
train_metrics: 
R2: 0.955162525177002
MSE: 14285.1474609375
MAPE: 0.10436710715293884
test metrics:
R2: 0.9449765086174011
MSE: 22502.943359375
MAPE: 0.1505730152130127
MSE diff_p 168
----------
169: 0.0016982955858111382
Training Epoch 169
train_metrics: 
R2: 0.9691713452339172
MSE: 11122.6484375
MAPE: 0.09622161835432053
test metrics:
R2: 0.9568588733673096
MSE: 18206.267578125
MAPE: 0.1359029859304428
MSE diff_p 169
----------
170: 0.002102455124258995
Training Epoch 170
train_metrics: 
R2: 0.9585297703742981
MSE: 13769.611328125
MAPE: 0.11140982806682587
test metrics:
R2: 0.9515652060508728
MSE: 20601.833984375
MAPE: 0.1420375257730484
MSE diff_p 170
----------
171: 0.00221069878898561
Training Epoch 171
train_metrics: 
R2: 0.9590200781822205
MSE: 14478.53125
MAPE: 0.11212337017059326
test metrics:
R2: 0.9571970105171204
MSE: 18353.015625
MAPE: 0.1370982974767685
MSE diff_p 171
----------
172: 0.0024543097242712975
Training Epoch 172
train_metrics: 
R2: 0.9549087285995483
MSE: 16074.01171875
MAPE: 0.11595999449491501
test metrics:
R2: 0.9547725915908813
MSE: 19819.16796875
MAPE: 0.1396489441394806
MSE diff_p 172
----------
173: 0.0021527265198528767
Training Epoch 173
train_metrics: 
R2: 0.958898663520813
MSE: 14098.853515625
MAPE: 0.11362771689891815
test metrics:
R2: 0.9569423198699951
MSE: 18048.1875
MAPE: 0.13657180964946747
MSE diff_p 173
----------
174: 0.0035954180639237165
Training Epoch 174
train_metrics: 
R2: 0.9321708679199219
MSE: 23547.478515625
MAPE: 0.12691763043403625
test metrics:
R2: 0.9527608752250671
MSE: 20059.0859375
MAPE: 0.1401364654302597
MSE diff_p 174
----------
175: 0.002886994043365121
Training Epoch 175
train_metrics: 
R2: 0.944856584072113
MSE: 18907.791015625
MAPE: 0.14614419639110565
test metrics:
R2: 0.9502894282341003
MSE: 20263.994140625
MAPE: 0.143344447016716
MSE diff_p 175
----------
176: 0.003008271101862192
Training Epoch 176
train_metrics: 
R2: 0.9444431662559509
MSE: 19702.072265625
MAPE: 0.14387942850589752
test metrics:
R2: 0.9364769458770752
MSE: 25843.853515625
MAPE: 0.17300572991371155
MSE diff_p 176
----------
177: 0.0031352329533547163
Training Epoch 177
train_metrics: 
R2: 0.9478407502174377
MSE: 20533.58203125
MAPE: 0.16329103708267212
test metrics:
R2: 0.9513086676597595
MSE: 20694.921875
MAPE: 0.16040097177028656
MSE diff_p 177
----------
178: 0.002969043795019388
Training Epoch 178
train_metrics: 
R2: 0.9384468793869019
MSE: 19445.162109375
MAPE: 0.12393724173307419
test metrics:
R2: 0.9336859583854675
MSE: 26866.263671875
MAPE: 0.17606915533542633
MSE diff_p 178
----------
179: 0.002587383147329092
Training Epoch 179
train_metrics: 
R2: 0.9450753927230835
MSE: 16945.548828125
MAPE: 0.1329585760831833
test metrics:
R2: 0.9460489749908447
MSE: 21575.63671875
MAPE: 0.14971746504306793
MSE diff_p 179
----------
180: 0.0031614189501851797
Training Epoch 180
train_metrics: 
R2: 0.9389868974685669
MSE: 20705.08203125
MAPE: 0.12164892256259918
test metrics:
R2: 0.9286489486694336
MSE: 28122.013671875
MAPE: 0.1763935089111328
MSE diff_p 180
----------
181: 0.0029251195956021547
Training Epoch 181
train_metrics: 
R2: 0.9418869018554688
MSE: 19157.486328125
MAPE: 0.12529662251472473
test metrics:
R2: 0.9476092457771301
MSE: 20911.392578125
MAPE: 0.1483173817396164
MSE diff_p 181
----------
182: 0.0027203382924199104
Training Epoch 182
train_metrics: 
R2: 0.9484500885009766
MSE: 17816.3125
MAPE: 0.1069861426949501
test metrics:
R2: 0.9537351131439209
MSE: 20202.755859375
MAPE: 0.13562370836734772
MSE diff_p 182
----------
183: 0.0026732224505394697
Training Epoch 183
train_metrics: 
R2: 0.9504926204681396
MSE: 17507.736328125
MAPE: 0.11641566455364227
test metrics:
R2: 0.9558944702148438
MSE: 18516.310546875
MAPE: 0.13286709785461426
MSE diff_p 183
----------
184: 0.0021415234077721834
Training Epoch 184
train_metrics: 
R2: 0.9589242935180664
MSE: 14025.482421875
MAPE: 0.11404240131378174
test metrics:
R2: 0.9416601657867432
MSE: 23370.765625
MAPE: 0.1565742939710617
MSE diff_p 184
----------
185: 0.0023714513517916203
Training Epoch 185
train_metrics: 
R2: 0.9562751650810242
MSE: 15531.34765625
MAPE: 0.12602266669273376
test metrics:
R2: 0.9534229040145874
MSE: 19450.36328125
MAPE: 0.14106598496437073
MSE diff_p 185
----------
186: 0.0032064616680145264
Training Epoch 186
train_metrics: 
R2: 0.9405989646911621
MSE: 21000.08203125
MAPE: 0.11337590217590332
test metrics:
R2: 0.9318176507949829
MSE: 26897.73046875
MAPE: 0.1730659157037735
MSE diff_p 186
----------
187: 0.0023665877524763346
Training Epoch 187
train_metrics: 
R2: 0.9577234983444214
MSE: 15499.4951171875
MAPE: 0.13202165067195892
test metrics:
R2: 0.955560564994812
MSE: 18773.48046875
MAPE: 0.1446801722049713
MSE diff_p 187
----------
188: 0.002917993115261197
Training Epoch 188
train_metrics: 
R2: 0.9454278945922852
MSE: 19110.814453125
MAPE: 0.14715763926506042
test metrics:
R2: 0.9358984231948853
MSE: 25635.013671875
MAPE: 0.17228630185127258
MSE diff_p 188
----------
189: 0.006865112576633692
Training Epoch 189
train_metrics: 
R2: 0.800631582736969
MSE: 44961.69140625
MAPE: 0.17622950673103333
test metrics:
R2: 0.6477334499359131
MSE: 82700.2265625
MAPE: 0.2746064364910126
MSE diff_p 189
----------
190: 0.03477482497692108
Training Epoch 190
train_metrics: 
R2: -1.49169921875
MSE: 227750.75
MAPE: 0.2914855480194092
test metrics:
R2: -1.8669049739837646
MSE: 318050.625
MAPE: 0.3704177737236023
MSE diff_p 190
----------
191: 0.01815919578075409
Training Epoch 191
train_metrics: 
R2: -0.26298797130584717
MSE: 118930.03125
MAPE: 0.27775347232818604
test metrics:
R2: -0.577905535697937
MSE: 187248.796875
MAPE: 0.3507898449897766
MSE diff_p 191
----------
192: 0.0039642322808504105
Training Epoch 192
train_metrics: 
R2: 0.9257799983024597
MSE: 25962.9453125
MAPE: 0.14843535423278809
test metrics:
R2: 0.9039559364318848
MSE: 34681.484375
MAPE: 0.17657959461212158
MSE diff_p 192
----------
193: 0.0051096039824187756
Training Epoch 193
train_metrics: 
R2: 0.9085485935211182
MSE: 33464.3359375
MAPE: 0.15205350518226624
test metrics:
R2: 0.9071752429008484
MSE: 39123.2109375
MAPE: 0.19440370798110962
MSE diff_p 193
----------
194: 0.007643119432032108
Training Epoch 194
train_metrics: 
R2: 0.8457590341567993
MSE: 50057.0859375
MAPE: 0.2479638159275055
test metrics:
R2: 0.8800684809684753
MSE: 42872.16015625
MAPE: 0.22475135326385498
MSE diff_p 194
----------
195: 0.0067153917625546455
Training Epoch 195
train_metrics: 
R2: 0.8507757186889648
MSE: 43981.125
MAPE: 0.18600031733512878
test metrics:
R2: 0.8317704200744629
MSE: 57574.83203125
MAPE: 0.2513596713542938
MSE diff_p 195
----------
196: 0.004668532870709896
Training Epoch 196
train_metrics: 
R2: 0.9093677997589111
MSE: 30575.626953125
MAPE: 0.20122753083705902
test metrics:
R2: 0.9291810989379883
MSE: 27984.3671875
MAPE: 0.1845701038837433
MSE diff_p 196
----------
197: 0.0031040366739034653
Training Epoch 197
train_metrics: 
R2: 0.9369633197784424
MSE: 20329.26953125
MAPE: 0.11905372142791748
test metrics:
R2: 0.9194114804267883
MSE: 31288.083984375
MAPE: 0.18305741250514984
MSE diff_p 197
----------
198: 0.002664284547790885
Training Epoch 198
train_metrics: 
R2: 0.9488985538482666
MSE: 17449.19921875
MAPE: 0.12253586947917938
test metrics:
R2: 0.9512926936149597
MSE: 20524.166015625
MAPE: 0.1458415538072586
MSE diff_p 198
----------
199: 0.002343628089874983
Training Epoch 199
train_metrics: 
R2: 0.9546633958816528
MSE: 15349.1240234375
MAPE: 0.1171530932188034
test metrics:
R2: 0.9418222904205322
MSE: 23395.17578125
MAPE: 0.1484595537185669
MSE diff_p 199
----------
